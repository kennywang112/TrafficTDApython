{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69a96d94-ab14-4996-ab85-73eae934a135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from tdamapper.core import MapperAlgorithm\n",
    "from tdamapper.cover import CubicalCover\n",
    "from tdamapper.plot import MapperLayoutInteractive, MapperLayoutStatic\n",
    "from tdamapper.clustering import FailSafeClustering\n",
    "from sklearn import metrics\n",
    "\n",
    "from functions import *\n",
    "from chi import *\n",
    "from regressionP import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b571ed9-5bfb-40f3-a864-f2029cb50332",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"./Data/NPA_TMA2_1.csv\", low_memory=False)[:-2]\n",
    "data2 = pd.read_csv(\"./Data/NPA_TMA2_2.csv\", low_memory=False)[:-2]\n",
    "data3 = pd.read_csv(\"./Data/NPA_TMA2_3.csv\", low_memory=False)[:-2]\n",
    "data4 = pd.read_csv(\"./Data/NPA_TMA2_4.csv\", low_memory=False)[:-2]\n",
    "dataA2 = pd.concat([data1, data2, data3, data4], ignore_index=True)\n",
    "\n",
    "dataA1 = pd.read_csv(\"./Data/NPA_TMA1.csv\")[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "939ce82b-c766-4042-a34f-b4780ac3335e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>天候名稱</th>\n",
       "      <th>路面狀況-路面狀態名稱</th>\n",
       "      <th>肇因研判大類別名稱-主要</th>\n",
       "      <th>當事者屬-性-別名稱</th>\n",
       "      <th>當事者事故發生時年齡</th>\n",
       "      <th>車輛撞擊部位大類別名稱-最初</th>\n",
       "      <th>光線名稱</th>\n",
       "      <th>道路類別-第1當事者-名稱</th>\n",
       "      <th>速限-第1當事者</th>\n",
       "      <th>道路障礙-視距品質名稱</th>\n",
       "      <th>...</th>\n",
       "      <th>道路型態子類別名稱</th>\n",
       "      <th>事故位置子類別名稱</th>\n",
       "      <th>車道劃分設施-分向設施子類別名稱</th>\n",
       "      <th>事故類型及型態子類別名稱</th>\n",
       "      <th>當事者行動狀態子類別名稱</th>\n",
       "      <th>車輛撞擊部位子類別名稱-最初</th>\n",
       "      <th>車輛撞擊部位子類別名稱-其他</th>\n",
       "      <th>肇因研判子類別名稱-個別</th>\n",
       "      <th>死亡</th>\n",
       "      <th>受傷</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.447747</td>\n",
       "      <td>-0.331183</td>\n",
       "      <td>0.509425</td>\n",
       "      <td>0.739901</td>\n",
       "      <td>-1.261265</td>\n",
       "      <td>-0.372169</td>\n",
       "      <td>0.146102</td>\n",
       "      <td>2.120706</td>\n",
       "      <td>-0.146069</td>\n",
       "      <td>0.118545</td>\n",
       "      <td>...</td>\n",
       "      <td>1.251063</td>\n",
       "      <td>1.179717</td>\n",
       "      <td>1.100187</td>\n",
       "      <td>0.650132</td>\n",
       "      <td>-0.485845</td>\n",
       "      <td>0.751944</td>\n",
       "      <td>-0.275732</td>\n",
       "      <td>-0.529094</td>\n",
       "      <td>13.660843</td>\n",
       "      <td>-2.803204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.447747</td>\n",
       "      <td>-0.331183</td>\n",
       "      <td>0.509425</td>\n",
       "      <td>0.739901</td>\n",
       "      <td>0.778508</td>\n",
       "      <td>1.175119</td>\n",
       "      <td>1.465217</td>\n",
       "      <td>-0.251720</td>\n",
       "      <td>-0.146069</td>\n",
       "      <td>0.118545</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.164027</td>\n",
       "      <td>-0.178330</td>\n",
       "      <td>-1.238620</td>\n",
       "      <td>1.355625</td>\n",
       "      <td>2.001744</td>\n",
       "      <td>1.515036</td>\n",
       "      <td>-0.275732</td>\n",
       "      <td>0.885802</td>\n",
       "      <td>13.660843</td>\n",
       "      <td>-0.620846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.201000</td>\n",
       "      <td>-0.331183</td>\n",
       "      <td>0.509425</td>\n",
       "      <td>0.739901</td>\n",
       "      <td>1.100577</td>\n",
       "      <td>-0.372169</td>\n",
       "      <td>-1.173013</td>\n",
       "      <td>2.911514</td>\n",
       "      <td>-0.146069</td>\n",
       "      <td>0.118545</td>\n",
       "      <td>...</td>\n",
       "      <td>1.251063</td>\n",
       "      <td>4.348494</td>\n",
       "      <td>2.659391</td>\n",
       "      <td>0.297386</td>\n",
       "      <td>-1.867838</td>\n",
       "      <td>-0.774241</td>\n",
       "      <td>-0.275732</td>\n",
       "      <td>2.053092</td>\n",
       "      <td>13.660843</td>\n",
       "      <td>-2.803204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.447747</td>\n",
       "      <td>-0.331183</td>\n",
       "      <td>0.509425</td>\n",
       "      <td>0.739901</td>\n",
       "      <td>-0.563448</td>\n",
       "      <td>-0.372169</td>\n",
       "      <td>-1.173013</td>\n",
       "      <td>-0.251720</td>\n",
       "      <td>-0.146069</td>\n",
       "      <td>0.118545</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.606699</td>\n",
       "      <td>-0.178330</td>\n",
       "      <td>-0.459018</td>\n",
       "      <td>1.355625</td>\n",
       "      <td>-0.485845</td>\n",
       "      <td>0.751944</td>\n",
       "      <td>-0.275732</td>\n",
       "      <td>1.946975</td>\n",
       "      <td>13.660843</td>\n",
       "      <td>-0.620846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.201000</td>\n",
       "      <td>-0.331183</td>\n",
       "      <td>0.509425</td>\n",
       "      <td>0.739901</td>\n",
       "      <td>-1.046552</td>\n",
       "      <td>-0.372169</td>\n",
       "      <td>1.465217</td>\n",
       "      <td>2.120706</td>\n",
       "      <td>-0.146069</td>\n",
       "      <td>0.118545</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507959</td>\n",
       "      <td>4.348494</td>\n",
       "      <td>0.320584</td>\n",
       "      <td>1.091065</td>\n",
       "      <td>0.619750</td>\n",
       "      <td>-0.392695</td>\n",
       "      <td>3.667023</td>\n",
       "      <td>-0.564467</td>\n",
       "      <td>13.660843</td>\n",
       "      <td>-2.803204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       天候名稱  路面狀況-路面狀態名稱  肇因研判大類別名稱-主要  當事者屬-性-別名稱  當事者事故發生時年齡  \\\n",
       "0 -0.447747    -0.331183      0.509425    0.739901   -1.261265   \n",
       "1 -0.447747    -0.331183      0.509425    0.739901    0.778508   \n",
       "2  1.201000    -0.331183      0.509425    0.739901    1.100577   \n",
       "3 -0.447747    -0.331183      0.509425    0.739901   -0.563448   \n",
       "4  1.201000    -0.331183      0.509425    0.739901   -1.046552   \n",
       "\n",
       "   車輛撞擊部位大類別名稱-最初      光線名稱  道路類別-第1當事者-名稱  速限-第1當事者  道路障礙-視距品質名稱  ...  \\\n",
       "0       -0.372169  0.146102       2.120706 -0.146069     0.118545  ...   \n",
       "1        1.175119  1.465217      -0.251720 -0.146069     0.118545  ...   \n",
       "2       -0.372169 -1.173013       2.911514 -0.146069     0.118545  ...   \n",
       "3       -0.372169 -1.173013      -0.251720 -0.146069     0.118545  ...   \n",
       "4       -0.372169  1.465217       2.120706 -0.146069     0.118545  ...   \n",
       "\n",
       "   道路型態子類別名稱  事故位置子類別名稱  車道劃分設施-分向設施子類別名稱  事故類型及型態子類別名稱  當事者行動狀態子類別名稱  \\\n",
       "0   1.251063   1.179717          1.100187      0.650132     -0.485845   \n",
       "1  -1.164027  -0.178330         -1.238620      1.355625      2.001744   \n",
       "2   1.251063   4.348494          2.659391      0.297386     -1.867838   \n",
       "3  -0.606699  -0.178330         -0.459018      1.355625     -0.485845   \n",
       "4   0.507959   4.348494          0.320584      1.091065      0.619750   \n",
       "\n",
       "   車輛撞擊部位子類別名稱-最初  車輛撞擊部位子類別名稱-其他  肇因研判子類別名稱-個別         死亡        受傷  \n",
       "0        0.751944       -0.275732     -0.529094  13.660843 -2.803204  \n",
       "1        1.515036       -0.275732      0.885802  13.660843 -0.620846  \n",
       "2       -0.774241       -0.275732      2.053092  13.660843 -2.803204  \n",
       "3        0.751944       -0.275732      1.946975  13.660843 -0.620846  \n",
       "4       -0.392695        3.667023     -0.564467  13.660843 -2.803204  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(input_data, select_lst, sample = 592):\n",
    "    sample_data = input_data[input_data['當事者順位'] == 1].reset_index(drop=True, inplace=False)\n",
    "    dataA = sample_data[select_lst]\n",
    "    \n",
    "    death_injury_data = split_death_injury(dataA['死亡受傷人數'])\n",
    "    dist_df = pd.concat([dataA, death_injury_data], axis=1)\n",
    "    dist_df.drop(columns=['死亡受傷人數'], inplace=True)\n",
    "    \n",
    "    return dist_df, sample_data\n",
    "select_lst = [\n",
    "    '天候名稱', \n",
    "    '路面狀況-路面狀態名稱',\n",
    "    '肇因研判大類別名稱-主要', '當事者屬-性-別名稱', '當事者事故發生時年齡', \n",
    "    '車輛撞擊部位大類別名稱-最初',\n",
    "    '光線名稱',\n",
    "    '道路類別-第1當事者-名稱',\n",
    "    '速限-第1當事者', '道路障礙-視距品質名稱',\n",
    "    '道路型態大類別名稱', '事故位置大類別名稱',\n",
    "    '號誌-號誌種類名稱',\n",
    "    '車道劃分設施-分向設施大類別名稱', '車道劃分設施-分道設施-快車道或一般車道間名稱',\n",
    "    '車道劃分設施-分道設施-快慢車道間名稱', '車道劃分設施-分道設施-路面邊線名稱',\n",
    "    '事故類型及型態大類別名稱',\n",
    "    '死亡受傷人數',\n",
    "    '經度', '緯度',\n",
    "    '道路型態子類別名稱', '事故位置子類別名稱', '車道劃分設施-分向設施子類別名稱', '事故類型及型態子類別名稱', \n",
    "    '當事者行動狀態子類別名稱', '車輛撞擊部位子類別名稱-最初', '車輛撞擊部位子類別名稱-其他', '肇因研判子類別名稱-個別',\n",
    "]\n",
    "\n",
    "dist_dfA1 = preprocess(dataA1, select_lst, sample = 592)\n",
    "dist_dfA2 = preprocess(dataA2, select_lst, sample = 11840) # 120420\n",
    "\n",
    "    \n",
    "rbind_data = pd.concat([dist_dfA1[0], dist_dfA2[0]], axis=0, ignore_index=True)\n",
    "\n",
    "rbind_data.loc[rbind_data['受傷'] > 1, '受傷'] = 2\n",
    "rbind_data['速限-第1當事者'] = rbind_data['速限-第1當事者'].apply(lambda x: 1 if x > 60 else 0)\n",
    "# rbind_data = process_age(rbind_data)\n",
    "\n",
    "dist_df = process_data(rbind_data)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "full_dist = pd.DataFrame(scaler.fit_transform(dist_df), columns = dist_df.columns)\n",
    "X1 = full_dist.drop(['受傷', '死亡'], axis=1).to_numpy()\n",
    "\n",
    "full_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4261b10-f9fd-4909-809c-54a70ec93b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('CalculatedData/full.pkl', 'rb') as f:\n",
    "    mapper_graph1 = pickle.load(f)\n",
    "    \n",
    "mapper_plot1 = MapperLayoutInteractive(\n",
    "    mapper_graph1,\n",
    "    colors = dist_df[['速限-第1當事者']].to_numpy(),\n",
    "    cmap = 'jet',\n",
    "    # agg = np.nanmean,\n",
    "    agg = most_frequent_nonan,\n",
    "    dim = 3,\n",
    "    iterations = 30,\n",
    "    seed = 6,\n",
    "    width = 800,\n",
    "    height = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5985e926-dcf2-4764-b4fe-3789bca826cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vars(mapper_plot1._MapperLayoutInteractive__fig)['_data_objs'][1]['x']\n",
    "y = vars(mapper_plot1._MapperLayoutInteractive__fig)['_data_objs'][1]['y']\n",
    "z = vars(mapper_plot1._MapperLayoutInteractive__fig)['_data_objs'][1]['z']\n",
    "\n",
    "threeDimData = pd.DataFrame({'x': x, 'y': y, 'z': z})\n",
    "\n",
    "import re\n",
    "data_tuple = vars(mapper_plot1._MapperLayoutInteractive__fig)['_data_objs'][1]['text']\n",
    "\n",
    "data = []\n",
    "for item in data_tuple:\n",
    "    color = int(re.search(r'color: (-?\\d+)', item).group(1))\n",
    "    node = int(re.search(r'node: (\\d+)', item).group(1))\n",
    "    size = int(re.search(r'size: (\\d+)', item).group(1))\n",
    "    data.append({'color': color, 'node': node, 'size': size})\n",
    "component_info = pd.DataFrame(data)\n",
    "\n",
    "full_info = pd.concat([component_info, threeDimData], axis=1)\n",
    "\n",
    "mp_content_origin = vars(mapper_plot1._MapperLayoutInteractive__graph)['_node']\n",
    "\n",
    "mp_content = pd.DataFrame.from_dict(mp_content_origin, orient='index')\n",
    "mp_content.reset_index(inplace=True)\n",
    "mp_content.rename(columns={'index': 'node'}, inplace=True)\n",
    "\n",
    "full_info = pd.merge(full_info, mp_content, on=['node', 'size'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be7e62f3-7454-4853-a894-ff05756df795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calinski_data = get_calinski_from_db(full_info, 0.02)\n",
    "# labels = calinski_data[3]\n",
    "# db = calinski_data[2]\n",
    "# n_clusters_ = calinski_data[4]\n",
    "\n",
    "# unique_labels = set(labels)\n",
    "# core_samples_mask = np.zeros_like(labels, dtype=bool)\n",
    "# core_samples_mask[db.core_sample_indices_] = True\n",
    "\n",
    "# def matplotlib_to_plotly(cmap, alpha=1):\n",
    "#     \"\"\"rgba\"\"\"\n",
    "#     return f'rgba({int(cmap[0]*200)}, {int(cmap[1]*200)}, {int(cmap[2]*200)}, {alpha})'\n",
    "\n",
    "# colors = [matplotlib_to_plotly(plt.cm.Spectral(each), alpha=0.8) for each in np.linspace(0, 1, len(unique_labels))]\n",
    "# fig = go.Figure()\n",
    "\n",
    "# for k, col in zip(unique_labels, colors):\n",
    "#     if k == -1:\n",
    "#         # col = 'rgba(0,0,0,0)'\n",
    "#         col = 'rgba(0,0,0,0)'\n",
    "\n",
    "#     class_member_mask = labels == k\n",
    "\n",
    "#     core_samples = full_info.iloc[:, 3:6][class_member_mask & core_samples_mask]\n",
    "#     fig.add_trace(go.Scatter3d(\n",
    "#         x=core_samples.iloc[:, 0],\n",
    "#         y=core_samples.iloc[:, 1],\n",
    "#         z=core_samples.iloc[:, 2],\n",
    "#         mode='markers',\n",
    "#         marker=dict(\n",
    "#             size=6,\n",
    "#             color=col,\n",
    "#             opacity=0.8\n",
    "#         ),\n",
    "#         name=f'Cluster {k} Core'\n",
    "#     ))\n",
    "\n",
    "#     non_core_samples = full_info.iloc[:, 3:6][class_member_mask & ~core_samples_mask]\n",
    "#     fig.add_trace(go.Scatter3d(\n",
    "#         x=non_core_samples.iloc[:, 0],\n",
    "#         y=non_core_samples.iloc[:, 1],\n",
    "#         z=non_core_samples.iloc[:, 2],\n",
    "#         mode='markers',\n",
    "#         marker=dict(\n",
    "#             size=6,\n",
    "#             color=col,\n",
    "#             opacity=0.5\n",
    "#         ),\n",
    "#         name=f'Cluster {k} Non-Core'\n",
    "#     ))\n",
    "\n",
    "# fig.update_layout(\n",
    "#     title=f\"Estimated number of clusters: {n_clusters_}\",\n",
    "#     margin=dict(l=0, r=0, b=0, t=0)\n",
    "# )\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6353476-45f3-46ff-b616-33db90377f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, -1}\n"
     ]
    }
   ],
   "source": [
    "def get_calinski_from_db(input_data, eps): \n",
    "    X = input_data.iloc[:, 3:6]\n",
    "\n",
    "    db = DBSCAN(eps=eps, min_samples=10).fit(X)\n",
    "    labels = db.labels_\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    print(set(labels))\n",
    "\n",
    "    input_data['label'] = labels\n",
    "    \n",
    "    unique_labels = np.unique(labels)\n",
    "    colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "    if len(set(labels)) != 1:\n",
    "        score = metrics.calinski_harabasz_score(X, labels)\n",
    "        silhouette_score_value = silhouette_score(X, labels)\n",
    "    else:\n",
    "        score = -1\n",
    "        silhouette_score_value = -1\n",
    "        \n",
    "    return score, input_data, db, labels, n_clusters_, silhouette_score_value, unique_labels, colors\n",
    "\n",
    "calinski_data = get_calinski_from_db(full_info, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5560cf2a-713a-49c6-a96a-4fd21f0164b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1 -1  2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2011"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_0 = full_info[full_info['label'] == 0]\n",
    "label_1 = full_info[full_info['label'] == 1]\n",
    "label_out = full_info[(full_info['label'] != 1) & (full_info['label'] != 0)]\n",
    "\n",
    "count_0 = get_count_dict(label_0)\n",
    "count_1 = get_count_dict(label_1)\n",
    "count_out = get_count_dict(label_out)\n",
    "\n",
    "print(full_info['label'].unique())\n",
    "\n",
    "len(count_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7958c3b3-880d-432c-a6af-c06e595b0dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118484, 31) (2238, 31) (2011, 31)\n"
     ]
    }
   ],
   "source": [
    "full_0 = rbind_data.loc[count_0.keys()]\n",
    "full_1 = rbind_data.loc[count_1.keys()]\n",
    "full_out = rbind_data.loc[count_out.keys()]\n",
    "\n",
    "full_0['weight'] = full_0.index.map(count_0)\n",
    "full_1['weight'] = full_1.index.map(count_1)\n",
    "full_out['weight'] = full_out.index.map(count_out)\n",
    "\n",
    "print(full_0.shape, full_1.shape, full_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64e78bdb-763d-4935-a1ec-46d4b5caf5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1566\n",
      "2     445\n",
      "dtype: int64\n",
      "1    84458\n",
      "2    34026\n",
      "dtype: int64\n",
      "1    1525\n",
      "2     713\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "lst_logit = [\n",
    "    '天候名稱',\n",
    "    '路面狀況-路面狀態名稱',\n",
    "    '肇因研判大類別名稱-主要', '當事者屬-性-別名稱', '當事者事故發生時年齡', \n",
    "    '車輛撞擊部位大類別名稱-最初',\n",
    "    '光線名稱',\n",
    "    '道路類別-第1當事者-名稱', \n",
    "    '速限-第1當事者', \n",
    "    '道路型態大類別名稱', \n",
    "    '事故位置大類別名稱',\n",
    "    '號誌-號誌種類名稱',\n",
    "    '車道劃分設施-分向設施大類別名稱', '車道劃分設施-分道設施-快車道或一般車道間名稱',\n",
    "    '車道劃分設施-分道設施-快慢車道間名稱', '車道劃分設施-分道設施-路面邊線名稱',\n",
    "    '事故類型及型態大類別名稱',\n",
    "    '道路型態子類別名稱', '事故位置子類別名稱', '車道劃分設施-分向設施子類別名稱', '事故類型及型態子類別名稱', \n",
    "    '當事者行動狀態子類別名稱', '車輛撞擊部位子類別名稱-最初', '車輛撞擊部位子類別名稱-其他', '肇因研判子類別名稱-個別',\n",
    "]\n",
    "\n",
    "def get_clusterN_logit(cluster_data, lst):\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    c0_for_lm = process_data(cluster_data)\n",
    "    c0_for_lm_X = pd.DataFrame(scaler.fit_transform(c0_for_lm), columns=c0_for_lm.columns)\n",
    "    \n",
    "    # 設置三個等級的label\n",
    "    # c0_for_lm_y = cluster_data['受傷']\n",
    "    c0_for_lm_y = cluster_data.apply(lambda row: 2 if row['受傷'] >= 2 else 1, axis=1)\n",
    "        \n",
    "    c0_for_lm_X = c0_for_lm_X[lst]\n",
    "    \n",
    "    return c0_for_lm_X, c0_for_lm_y\n",
    "\n",
    "\n",
    "full_combine_X,  full_combine_y = get_clusterN_logit(full_out, lst_logit)\n",
    "full_0_X, full_0_y = get_clusterN_logit(full_0, lst_logit)\n",
    "full_1_X, full_1_y = get_clusterN_logit(full_1, lst_logit)\n",
    "\n",
    "print(full_combine_y.value_counts())\n",
    "print(full_0_y.value_counts())\n",
    "print(full_1_y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84618464-13dc-4a5d-a8d2-0d48f40727d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6600496277915633 0.6291091699371228 0.5803571428571429\n",
      "83.28679823875427\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "matrix_combine, score_combine, cm_combine = logistic_cm_gridsearch(full_combine_X,  full_combine_y)\n",
    "matrix_0, score_0, cm_0 = logistic_cm_gridsearch(full_0_X, full_0_y)\n",
    "matrix_1, score_1, cm_1 = logistic_cm_gridsearch(full_1_X, full_1_y)\n",
    "print(score_combine, score_0, score_1)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4f1af14-6296-4cfe-97b1-6f7e4a680c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "0.7741935483870968 0.7165885977127906 0.625\n",
      "89.2347686290741\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "rf_combine_X, rf_combine_y,  rf_cm_combine = rf_with_gridsearch(full_combine_X,  full_combine_y)\n",
    "rf_matrix_0, rf_score_0, rf_cm_0 = rf_with_gridsearch(full_0_X, full_0_y)\n",
    "rf_matrix_1, rf_score_1, rf_cm_1 = rf_with_gridsearch(full_1_X, full_1_y)\n",
    "print(rf_combine_y, rf_score_0, rf_score_1)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c64ac369-52ff-4e9a-a86d-1db853d1910c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6724565756823822 0.6096974300544372 0.5959821428571429\n",
      "2784.872428894043\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "svc_matrix_com, svc_score_com, svc_cm_combine = svc_cm_with_grid_search(full_combine_X, full_combine_y)\n",
    "svc_matrix_0, svc_score_0, svc_cm_0 = svc_cm_with_grid_search(full_0_X, full_0_y)\n",
    "svc_matrix_1, svc_score_1, svc_cm_1 = svc_cm_with_grid_search(full_1_X, full_1_y)\n",
    "print(svc_score_com, svc_score_0, svc_score_1)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0face31-d723-4bbe-a424-ad724028488d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.629\n",
      "0.716\n",
      "0.61\n"
     ]
    }
   ],
   "source": [
    "de = full_combine_X.shape[0] + full_0_X.shape[0] + full_1_X.shape[0]\n",
    "logit_avg_score = (full_combine_X.shape[0]/de)*score_combine + (full_0_X.shape[0]/de)*score_0 + (full_1_X.shape[0]/de)*score_1\n",
    "rf_avg_score = (full_combine_X.shape[0]/de)*rf_combine_y + (full_0_X.shape[0]/de)*rf_score_0 + (full_1_X.shape[0]/de)*rf_score_1\n",
    "svm_avg_score = (full_combine_X.shape[0]/de)*svc_score_com + (full_0_X.shape[0]/de)*svc_score_0 + (full_1_X.shape[0]/de)*svc_score_1\n",
    "\n",
    "print(round(logit_avg_score, 3))\n",
    "print(round(rf_avg_score, 3))\n",
    "print(round(svm_avg_score, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5661febe-1e11-4503-8563-6caca1c73245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# origin_X, origin_y = get_clusterN_logit(rbind_data, lst_logit)\n",
    "\n",
    "# matrix_origin, score_origin, cm_origin = logistic_cm_gridsearch(origin_X, origin_y)\n",
    "# rf_matrix_origin, rf_score_origin, rf_cm_origin = rf_with_gridsearch(origin_X, origin_y)\n",
    "# svc_matrix_origin, svc_score_origin, svc_cm_origin = svc_cm_with_grid_search(origin_X, origin_y)\n",
    "# print(round(score_origin, 3), round(rf_score_origin, 3), round(svc_score_origin, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d53c605-d192-48c3-b587-a06d3ba433a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Mapper', 'Origin']\n",
    "logit_scores = [logit_avg_score, score_origin]\n",
    "rf_scores = [rf_avg_score, rf_score_origin]\n",
    "svm_scores = [svm_avg_score, svc_score_origin]\n",
    "\n",
    "x = np.arange(len(categories))  # the label locations\n",
    "width = 0.25  # the width of the bars, 更窄一點以便容納三組數據\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width, logit_scores, width, label='Logit')\n",
    "rects2 = ax.bar(x, rf_scores, width, label='RF')\n",
    "rects3 = ax.bar(x + width, svm_scores, width, label='SVM')\n",
    "\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Scores by different models and data origins')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=3)  # 調整圖例位置和列數\n",
    "\n",
    "# Attach a text label above each bar in *rects*, displaying its height.\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.3f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 1),  # slight vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
