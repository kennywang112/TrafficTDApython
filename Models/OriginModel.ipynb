{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'C:\\\\System\\\\Library\\\\Fonts\\\\PingFang.ttc'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "from utils.models import *\n",
    "\n",
    "try:\n",
    "    myfont = FontProperties(fname=r\"/System/Library/Fonts/PingFang.ttc\")\n",
    "    sns.set(style=\"whitegrid\", font=myfont.get_name())\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "dataA2 = pd.read_csv(\"../Version3/Data/A2.csv\", low_memory=False)\n",
    "dataA1 = pd.read_csv(\"../Version3/Data/A1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_0 = pd.read_csv(os.path.join(\"../Version3/Data/CarData/full_0.csv\"), encoding='utf-8')\n",
    "car_1 = pd.read_csv(os.path.join(\"../Version3/Data/CarData/full_1.csv\"), encoding='utf-8')\n",
    "car_2 = pd.read_csv(os.path.join(\"../Version3/Data/CarData/full_2.csv\"), encoding='utf-8')\n",
    "car_out = pd.read_csv(os.path.join(\"../Version3/Data/CarData/full_out.csv\"), encoding='utf-8')\n",
    "car_overlap = pd.read_csv(os.path.join(\"../Version3/Data/CarData/overlap_data.csv\"), encoding='utf-8')\n",
    "\n",
    "motor_0 = pd.read_csv(os.path.join(\"../Version3/Data/MotorData/full_0.csv\"), encoding='utf-8')\n",
    "motor_1 = pd.read_csv(os.path.join(\"../Version3/Data/MotorData/full_1.csv\"), encoding='utf-8')\n",
    "motor_out = pd.read_csv(os.path.join(\"../Version3/Data/MotorData/full_out.csv\"), encoding='utf-8')\n",
    "motor_overlap = pd.read_csv(os.path.join(\"../Version3/Data/MotorData/overlap_data.csv\"), encoding='utf-8')\n",
    "\n",
    "pass_0 = pd.read_csv(os.path.join(\"../Version3/Data/PassData/full_0.csv\"), encoding='utf-8')\n",
    "pass_1 = pd.read_csv(os.path.join(\"../Version3/Data/PassData/full_1.csv\"), encoding='utf-8')\n",
    "pass_out = pd.read_csv(os.path.join(\"../Version3/Data/PassData/full_out.csv\"), encoding='utf-8')\n",
    "pass_overlap = pd.read_csv(os.path.join(\"../Version3/Data/PassData/overlap_data.csv\"), encoding='utf-8')\n",
    "\n",
    "full_data = pd.read_csv(os.path.join(\"../Version3/Data/FullData/full.csv\"), encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 這是由拓樸得出來的特徵，可新增於拓樸訓練，但不增加在full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_out['type'] = 'out'\n",
    "car_overlap['type'] = 'overlap'\n",
    "motor_out['type'] = 'out'\n",
    "motor_overlap['type'] = 'overlap'\n",
    "pass_out['type'] = 'out'\n",
    "pass_overlap['type'] = 'overlap'\n",
    "\n",
    "car_out_overlap = pd.concat([car_out, car_overlap])\n",
    "motor_out_overlap = pd.concat([motor_out, motor_overlap])\n",
    "pass_out_overlap = pd.concat([pass_out, pass_overlap])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 行人資料需要特別處理，因為他們沒有以下特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_0['行動電話或電腦或其他相類功能裝置名稱'] = '非駕駛人'\n",
    "pass_0['當事者區分-類別-大類別名稱-車種'] = '人'\n",
    "pass_1['行動電話或電腦或其他相類功能裝置名稱'] = '非駕駛人'\n",
    "pass_1['當事者區分-類別-大類別名稱-車種'] = '人'\n",
    "pass_out['行動電話或電腦或其他相類功能裝置名稱'] = '非駕駛人'\n",
    "pass_out['當事者區分-類別-大類別名稱-車種'] = '人'\n",
    "pass_overlap['行動電話或電腦或其他相類功能裝置名稱'] = '非駕駛人'\n",
    "pass_overlap['當事者區分-類別-大類別名稱-車種'] = '人'\n",
    "pass_out_overlap['行動電話或電腦或其他相類功能裝置名稱'] = '非駕駛人'\n",
    "pass_out_overlap['當事者區分-類別-大類別名稱-車種'] = '人'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_lst = [\n",
    "    '天候名稱', '光線名稱', \n",
    "    '道路類別-第1當事者-名稱', '速限-第1當事者', \n",
    "    \n",
    "    # 路面狀況\n",
    "    '路面狀況-路面鋪裝名稱', '路面狀況-路面狀態名稱', '路面狀況-路面缺陷名稱',\n",
    "    '道路障礙-障礙物名稱', '道路障礙-視距品質名稱', '道路障礙-視距名稱',\n",
    "    # 號誌\n",
    "    '號誌-號誌種類名稱', '號誌-號誌動作名稱',\n",
    "    # 車道\n",
    "    '車道劃分設施-分道設施-快車道或一般車道間名稱', '車道劃分設施-分道設施-快慢車道間名稱', '車道劃分設施-分道設施-路面邊線名稱',\n",
    "    # 當事人\n",
    "    '當事者屬-性-別名稱', '當事者事故發生時年齡',\n",
    "    '保護裝備名稱', '行動電話或電腦或其他相類功能裝置名稱',\n",
    "    '肇事逃逸類別名稱-是否肇逃',\n",
    "\n",
    "    # 大類別\n",
    "    '道路型態大類別名稱', '事故位置大類別名稱',\n",
    "    '車道劃分設施-分向設施大類別名稱',\n",
    "    '事故類型及型態大類別名稱', '當事者區分-類別-大類別名稱-車種',\n",
    "    '車輛撞擊部位大類別名稱-其他',\n",
    "    '肇因研判大類別名稱-主要',\n",
    "\n",
    "    # 子類別\n",
    "    '道路型態子類別名稱', '事故位置子類別名稱', '事故類型及型態子類別名稱', '肇因研判子類別名稱-主要',\n",
    "    '當事者區分-類別-子類別名稱-車種', '當事者行動狀態子類別名稱', '車輛撞擊部位子類別名稱-最初',\n",
    "    '車輛撞擊部位子類別名稱-其他', '肇因研判子類別名稱-個別',\n",
    "    \n",
    "    '死亡'\n",
    "]\n",
    "\n",
    "# select data\n",
    "car_0 = car_0[select_lst]\n",
    "car_1 = car_1[select_lst]\n",
    "car_2 = car_2[select_lst]\n",
    "motor_0 = motor_0[select_lst]\n",
    "motor_1 = motor_1[select_lst]\n",
    "pass_0 = pass_0[select_lst]\n",
    "pass_1 = pass_1[select_lst]\n",
    "\n",
    "full_data = full_data[select_lst]\n",
    "\n",
    "select_lst.append('type')\n",
    "motor_out_overlap = motor_out_overlap[select_lst]\n",
    "car_out_overlap = car_out_overlap[select_lst]\n",
    "pass_out_overlap = pass_out_overlap[select_lst]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 唯一值檢查\n",
    "第一區塊是完整模型的資料<br/>\n",
    "第二區塊是多個模型個別進行模型，所以這裡需要量化後自動drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "詳細群體\n",
      "['道路障礙-視距品質名稱', '道路障礙-視距名稱']\n",
      "['道路障礙-視距品質名稱', '道路障礙-視距名稱']\n",
      "['道路障礙-視距品質名稱', '道路障礙-視距名稱']\n",
      "[]\n",
      "['道路障礙-視距品質名稱', '道路障礙-視距名稱']\n",
      "['道路障礙-視距品質名稱', '道路障礙-視距名稱']\n",
      "[]\n",
      "['路面狀況-路面缺陷名稱', '道路障礙-視距品質名稱', '道路障礙-視距名稱', '號誌-號誌動作名稱', '行動電話或電腦或其他相類功能裝置名稱', '事故類型及型態大類別名稱', '當事者區分-類別-大類別名稱-車種']\n",
      "['道路障礙-視距品質名稱', '道路障礙-視距名稱', '行動電話或電腦或其他相類功能裝置名稱', '當事者區分-類別-大類別名稱-車種']\n",
      "['行動電話或電腦或其他相類功能裝置名稱', '肇事逃逸類別名稱-是否肇逃', '當事者區分-類別-大類別名稱-車種']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print('詳細群體')\n",
    "for data in [car_0, car_1, car_2, car_out_overlap, motor_0, motor_1, motor_out_overlap, pass_0, pass_1, pass_out_overlap, full_data]:\n",
    "    columns_to_drop = []\n",
    "    for column in data.columns:\n",
    "        if data[column].nunique() == 1:\n",
    "            columns_to_drop.append(column)\n",
    "    print(columns_to_drop)\n",
    "    data.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始特徵數: 35, 保留特徵數: 14\n",
      "原始特徵數: 35, 保留特徵數: 17\n",
      "原始特徵數: 35, 保留特徵數: 16\n",
      "原始特徵數: 38, 保留特徵數: 7\n",
      "原始特徵數: 35, 保留特徵數: 15\n",
      "原始特徵數: 35, 保留特徵數: 15\n",
      "原始特徵數: 38, 保留特徵數: 17\n",
      "原始特徵數: 30, 保留特徵數: 20\n",
      "原始特徵數: 33, 保留特徵數: 17\n",
      "原始特徵數: 35, 保留特徵數: 19\n",
      "原始特徵數: 37, 保留特徵數: 11\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def drop_low_importance_features(data, threshold=0.01):\n",
    "    # One-hot 編碼資料\n",
    "    X = pd.get_dummies(data.drop(columns=['死亡']))\n",
    "    y = data['死亡']\n",
    "\n",
    "    # 訓練 RandomForest 模型\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # 計算特徵重要性\n",
    "    feature_importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "    # 篩選重要性高於 threshold 的 dummy 特徵\n",
    "    selected_dummy_features = feature_importances[feature_importances > threshold].index.tolist()\n",
    "\n",
    "    # 找回原始的類別特徵名稱\n",
    "    original_features = data.drop(columns=['死亡']).columns\n",
    "    selected_features = set()\n",
    "\n",
    "    for feature in original_features:\n",
    "        # 如果原始特徵的任何 dummy 特徵被選中，就保留原始特徵\n",
    "        if any(dummy.startswith(f\"{feature}_\") for dummy in selected_dummy_features) or feature in selected_dummy_features:\n",
    "            selected_features.add(feature)\n",
    "\n",
    "    # 回到原始資料集中的選擇特徵\n",
    "    reduced_data = data[list(selected_features) + ['死亡']]\n",
    "    print(f\"原始特徵數: {data.shape[1]}, 保留特徵數: {len(selected_features)}\")\n",
    "    return reduced_data\n",
    "\n",
    "car0_reduced = drop_low_importance_features(car_0)\n",
    "car1_reduced = drop_low_importance_features(car_1)\n",
    "car2_reduced = drop_low_importance_features(car_2)\n",
    "car_out_overlap_reduced = drop_low_importance_features(car_out_overlap)\n",
    "motor0_reduced = drop_low_importance_features(motor_0)\n",
    "motor1_reduced = drop_low_importance_features(motor_1)\n",
    "motor_out_overlap_reduced = drop_low_importance_features(motor_out_overlap)\n",
    "pass0_reduced = drop_low_importance_features(pass_0)\n",
    "pass1_reduced = drop_low_importance_features(pass_1)\n",
    "pass_out_overlap_reduced = drop_low_importance_features(pass_out_overlap)\n",
    "full_data_reduced = drop_low_importance_features(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_0_dummy = pd.get_dummies(car0_reduced)\n",
    "car_1_dummy = pd.get_dummies(car1_reduced)\n",
    "car_2_dummy = pd.get_dummies(car2_reduced)\n",
    "car_out_overlap_dummy = pd.get_dummies(car_out_overlap_reduced)\n",
    "motor_0_dummy = pd.get_dummies(motor0_reduced)\n",
    "motor_1_dummy = pd.get_dummies(motor1_reduced)\n",
    "motor_out_overlap_dummy = pd.get_dummies(motor_out_overlap_reduced)\n",
    "pass_0_dummy = pd.get_dummies(pass0_reduced)\n",
    "pass_1_dummy = pd.get_dummies(pass1_reduced)\n",
    "pass_out_overlap = pd.get_dummies(pass_out_overlap_reduced)\n",
    "\n",
    "full_data_dummy = pd.get_dummies(full_data_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_0_X, car_0_y = get_train_test_data(car_0_dummy)\n",
    "car_1_X, car_1_y = get_train_test_data(car_1_dummy)\n",
    "car_2_X, car_2_y = get_train_test_data(car_2_dummy)\n",
    "car_out_overlap_X, car_out_overlap_y = get_train_test_data(car_out_overlap_dummy)\n",
    "motor_0_X, motor_0_y = get_train_test_data(motor_0_dummy)\n",
    "motor_1_X, motor_1_y = get_train_test_data(motor_1_dummy)\n",
    "motor_out_overlap_X, motor_out_overlap_y = get_train_test_data(motor_out_overlap_dummy)\n",
    "pass_0_X, pass_0_y = get_train_test_data(pass_0_dummy)\n",
    "pass_1_X, pass_1_y = get_train_test_data(pass_1_dummy)\n",
    "pass_out_overlap_X, pass_out_overlap_y = get_train_test_data(pass_out_overlap)\n",
    "\n",
    "full_data_X, full_data_y = get_train_test_data(full_data_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    57472\n",
      "1      285\n",
      "Name: y, dtype: int64\n",
      "0    43045\n",
      "1      175\n",
      "Name: y, dtype: int64\n",
      "0    2084\n",
      "1      35\n",
      "Name: y, dtype: int64\n",
      "0    8772\n",
      "1      88\n",
      "Name: y, dtype: int64\n",
      "0    69156\n",
      "1      318\n",
      "Name: y, dtype: int64\n",
      "0    32699\n",
      "1       87\n",
      "Name: y, dtype: int64\n",
      "0    5353\n",
      "1      18\n",
      "Name: y, dtype: int64\n",
      "0    529\n",
      "1     11\n",
      "Name: y, dtype: int64\n",
      "0    2373\n",
      "1      33\n",
      "Name: y, dtype: int64\n",
      "0    183\n",
      "1     14\n",
      "Name: y, dtype: int64\n",
      "0    218238\n",
      "1       965\n",
      "Name: y, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(car_0_y.value_counts())\n",
    "print(car_1_y.value_counts())\n",
    "print(car_2_y.value_counts())\n",
    "print(car_out_overlap_y.value_counts())\n",
    "print(motor_0_y.value_counts())\n",
    "print(motor_1_y.value_counts())\n",
    "print(motor_out_overlap_y.value_counts())\n",
    "print(pass_0_y.value_counts())\n",
    "print(pass_1_y.value_counts())\n",
    "print(pass_out_overlap_y.value_counts())\n",
    "\n",
    "print(full_data_y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57757, 106)\n",
      "(43220, 162)\n",
      "(2119, 248)\n",
      "(8860, 70)\n",
      "(69474, 122)\n",
      "(32786, 96)\n",
      "(5371, 123)\n",
      "(540, 100)\n",
      "(2406, 117)\n",
      "(197, 119)\n",
      "(219203, 78)\n"
     ]
    }
   ],
   "source": [
    "print(car_0_X.shape)\n",
    "print(car_1_X.shape)\n",
    "print(car_2_X.shape)\n",
    "print(car_out_overlap_X.shape)\n",
    "print(motor_0_X.shape)\n",
    "print(motor_1_X.shape)\n",
    "print(motor_out_overlap_X.shape)\n",
    "print(pass_0_X.shape)\n",
    "print(pass_1_X.shape)\n",
    "print(pass_out_overlap_X.shape)\n",
    "print(full_data_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(222730, 219203)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_0_X.shape[0] + car_1_X.shape[0] + car_2_X.shape[0] + car_out_overlap_X.shape[0] + motor_0_X.shape[0] + motor_1_X.shape[0] + motor_out_overlap_X.shape[0] + pass_0_X.shape[0] + pass_1_X.shape[0] + pass_out_overlap_X.shape[0], full_data_X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全部大類別資料kfold計算到motor0開始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_cm_gridsearch(X, y, random_state=42, n_jobs=12):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_state)\n",
    "\n",
    "    smote = SMOTE(random_state=random_state, k_neighbors=3)\n",
    "    enn = EditedNearestNeighbours(n_neighbors=3)\n",
    "    smote_enn = SMOTEENN(smote=smote, enn=enn, random_state=random_state)\n",
    "    X_resampled_train, y_resampled_train = smote_enn.fit_resample(X_train, y_train)\n",
    "\n",
    "    min_class_count = min(sum(y_test == 0), sum(y_test == 1))\n",
    "    rus_test = RandomUnderSampler(sampling_strategy={0: min_class_count, 1: min_class_count}, random_state=random_state)\n",
    "    X_resampled_test, y_resampled_test = rus_test.fit_resample(X_test, y_test)\n",
    "\n",
    "    model = XGBClassifier(eval_metric='logloss', random_state=random_state)\n",
    "    parameters = {\n",
    "        'n_estimators': [50, 100, 200, 400], # 樹的数量\n",
    "        'max_depth': [3, 5, 7, 9],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'colsample_bytree': [0.8, 1.0],  # 每棵樹使用的特征采样比例\n",
    "    }\n",
    "    grid_search = GridSearchCV(model, parameters, cv=5, scoring='accuracy', n_jobs=n_jobs)\n",
    "    grid_search.fit(X_resampled_train, y_resampled_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    print(\"Best parameters found by GridSearchCV:\", grid_search.best_params_)\n",
    "\n",
    "    y_proba = best_model.predict_proba(X_resampled_test)[:, 1]\n",
    "\n",
    "    return y_resampled_test, y_proba, np.arange(len(y_resampled_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_data xgboost start\n",
      "Best parameters found by GridSearchCV: {'colsample_bytree': 1.0, 'learning_rate': 0.2, 'max_depth': 9, 'n_estimators': 400}\n",
      "full_data xgboost done in 1159.79 seconds\n",
      "full_data logistic start\n",
      "Best parameters found by GridSearchCV: {'C': 100, 'penalty': 'l2'}\n",
      "full_data logistic done in 683.69 seconds\n",
      "full_data svc start\n",
      "Best parameters found by GridSearchCV: {'C': 10, 'loss': 'squared_hinge'}\n",
      "full_data svc done in 385.17 seconds\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "import gc\n",
    "\n",
    "models = [\n",
    "    # (\"pass_0\", pass_0_X, pass_0_y),\n",
    "    # (\"pass_1\", pass_1_X, pass_1_y),\n",
    "    # (\"pass_out_overlap\", pass_out_overlap_X, pass_out_overlap_y),\n",
    "    # (\"car_0\", car_0_X, car_0_y),\n",
    "    # (\"car_1\", car_1_X, car_1_y),\n",
    "    # (\"car_2\", car_2_X, car_2_y),\n",
    "    # (\"car_out_overlap\", car_out_overlap_X, car_out_overlap_y),\n",
    "    # (\"motor_0\", motor_0_X, motor_0_y),\n",
    "    # (\"motor_1\", motor_1_X, motor_1_y),\n",
    "    # (\"motor_out_overlap\", motor_out_overlap_X, motor_out_overlap_y),\n",
    "    (\"full_data\", full_data_X, full_data_y),\n",
    "]\n",
    "\n",
    "# XGBoost no fold\n",
    "for name, X, y in models:\n",
    "    print(f'{name} xgboost start')\n",
    "    start_time = time.time()\n",
    "    y_xgb, decision_scores_xgb, indices_xgb = xgboost_cm_gridsearch(X.astype(float), y)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    with open(f\"../Models/ModelPerformanceNofold/xgboost/{name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump({\n",
    "            'y': y_xgb,\n",
    "            'decision_scores': decision_scores_xgb,\n",
    "            'indices': indices_xgb,\n",
    "            'elapsed_time': elapsed_time\n",
    "        }, f)\n",
    "    print(f'{name} xgboost done in {elapsed_time:.2f} seconds')\n",
    "    del X, y, y_xgb, decision_scores_xgb\n",
    "    gc.collect()\n",
    "\n",
    "# Logistic no fold\n",
    "for name, X, y in models:\n",
    "    print(f'{name} logistic start')\n",
    "    start_time = time.time()\n",
    "    # y_log, decision_scores_log, indices_log = logistic_cm_kfold(X.astype(float), y)\n",
    "    y_log, decision_scores_log, indices_log = logistic_cm_gridsearch(X.astype(float), y)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    with open(f\"../Models/ModelPerformanceNofold/logistic/{name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump({\n",
    "            'y': y_log,\n",
    "            'decision_scores': decision_scores_log,\n",
    "            'indices': indices_log,\n",
    "            'elapsed_time': elapsed_time\n",
    "        }, f)\n",
    "    print(f'{name} logistic done in {elapsed_time:.2f} seconds')\n",
    "    del X, y, y_log, decision_scores_log\n",
    "    gc.collect()\n",
    "\n",
    "# SVC no fold\n",
    "for name, X, y in models:\n",
    "    print(f'{name} svc start')\n",
    "    start_time = time.time()\n",
    "    y_svc, decision_scores_svc, indices_svc = linear_svc_cm_gridsearch(X.astype(float), y)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    with open(f\"../Models/ModelPerformanceNofold/svc/{name}.pkl\", \"wb\") as f:\n",
    "        pickle.dump({\n",
    "            'y': y_svc,\n",
    "            'decision_scores': decision_scores_svc,\n",
    "            'indices': indices_svc,\n",
    "            'elapsed_time': elapsed_time\n",
    "        }, f)\n",
    "    print(f'{name} svc done in {elapsed_time:.2f} seconds')\n",
    "    del X, y, y_svc, decision_scores_svc\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
