{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'C:\\\\System\\\\Library\\\\Fonts\\\\PingFang.ttc'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import prince\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "# 獲取當前工作目錄\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "version3_path = os.path.join(parent_dir, \"Version3\")\n",
    "\n",
    "# 暫時將工作目錄切換到 Version3\n",
    "os.chdir(version3_path)\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from tdamapper.core_old import MapperAlgorithm\n",
    "from tdamapper.cover import CubicalCover\n",
    "from tdamapper.clustering import FailSafeClustering\n",
    "\n",
    "from utils.models import *\n",
    "from utils.utils_v3 import *\n",
    "from utils.plots import *\n",
    "\n",
    "try:\n",
    "    myfont = FontProperties(fname=r\"/System/Library/Fonts/PingFang.ttc\")\n",
    "    sns.set(style=\"whitegrid\", font=myfont.get_name())\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "dataA2 = pd.read_csv(\"./Data/A2.csv\", low_memory=False)\n",
    "dataA1 = pd.read_csv(\"./Data/A1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "汽車    105260\n",
       "Name: 車輛撞擊部位大類別名稱-最初, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_lst = [\n",
    "    # 月份是為了篩選每個月2萬筆\n",
    "    '發生月份',\n",
    "\n",
    "    '天候名稱', '光線名稱', \n",
    "    '道路類別-第1當事者-名稱', '速限-第1當事者', \n",
    "    '路面狀況-路面鋪裝名稱', '路面狀況-路面狀態名稱', '路面狀況-路面缺陷名稱',\n",
    "    '道路障礙-障礙物名稱', '道路障礙-視距品質名稱', '道路障礙-視距名稱',\n",
    "    '號誌-號誌種類名稱', '號誌-號誌動作名稱',\n",
    "    '車道劃分設施-分道設施-快車道或一般車道間名稱', '車道劃分設施-分道設施-快慢車道間名稱', '車道劃分設施-分道設施-路面邊線名稱',\n",
    "    '當事者屬-性-別名稱', '當事者事故發生時年齡',\n",
    "    '保護裝備名稱', '行動電話或電腦或其他相類功能裝置名稱',\n",
    "    '肇事逃逸類別名稱-是否肇逃',\n",
    "    '死亡受傷人數',\n",
    "\n",
    "    # 大類別\n",
    "    '道路型態大類別名稱', '事故位置大類別名稱',\n",
    "    '車道劃分設施-分向設施大類別名稱',\n",
    "    '事故類型及型態大類別名稱', '當事者區分-類別-大類別名稱-車種', '當事者行動狀態大類別名稱',\n",
    "    '車輛撞擊部位大類別名稱-最初', '車輛撞擊部位大類別名稱-其他',\n",
    "\n",
    "    # 兩個欄位只有兩個觀察值不同\n",
    "    '肇因研判大類別名稱-主要',\n",
    "    # '肇因研判大類別名稱-個別',\n",
    "    \n",
    "    # 篩選駕駛人的資料\n",
    "    '道路型態子類別名稱'\n",
    "]\n",
    "# select_lst = dataA1.columns\n",
    "\n",
    "def preprocess(input_data, select_lst):\n",
    "    # 篩選到第一個順位，因為注重的是單次事故的情況\n",
    "    main_data = input_data[input_data['當事者順位'] == 1].reset_index(drop=True, inplace=False)\n",
    "    sample_data = main_data[main_data['發生月份'] < 11]\n",
    "    selected_data = sample_data[select_lst]\n",
    "    \n",
    "    # 將資料分出死亡和受傷，合併到原本的資料後去除多餘的死亡受傷人數\n",
    "    split_death_injury_data = split_death_injury(selected_data['死亡受傷人數'])\n",
    "    full_data = pd.concat([selected_data, split_death_injury_data], axis=1)\n",
    "\n",
    "    # 補齊缺失值\n",
    "    full_data[select_lst] = full_data[select_lst].fillna('未紀錄')\n",
    "\n",
    "    # 速限範圍\n",
    "    full_data = full_data[(full_data['速限-第1當事者'] < 200) &\n",
    "                      (full_data['當事者事故發生時年齡'] < 100) &\n",
    "                      (full_data['當事者事故發生時年齡'] > 0)]\n",
    "\n",
    "    full_data.drop(columns=['死亡受傷人數'], inplace=True)\n",
    "    \n",
    "    # 篩選汽車的資料\n",
    "    full_data = full_data[full_data['車輛撞擊部位大類別名稱-最初'] == '汽車']\n",
    "    full_data.drop(columns=['當事者行動狀態大類別名稱'], inplace=True)\n",
    "    # 篩選離群資料(影響MCA的因子得分)\n",
    "    full_data = full_data[(full_data['肇因研判大類別名稱-主要'] != '非駕駛者') &\n",
    "                  (full_data['肇因研判大類別名稱-主要'] != '無(非車輛駕駛人因素)') &\n",
    "                  (full_data['肇因研判大類別名稱-主要'] != '無(車輛駕駛者因素)') &\n",
    "                  (full_data['行動電話或電腦或其他相類功能裝置名稱'] != '未紀錄') &\n",
    "                    (full_data['車輛撞擊部位大類別名稱-最初'] != '未紀錄')&\n",
    "                    (full_data['道路型態大類別名稱'] != '平交道')]\n",
    "\n",
    "    return full_data\n",
    "\n",
    "full_dataA1 = preprocess(dataA1, select_lst)\n",
    "full_dataA2 = preprocess(dataA2, select_lst)\n",
    "\n",
    "full_dataA2['車輛撞擊部位大類別名稱-最初'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy_data: (105824, 147)\n"
     ]
    }
   ],
   "source": [
    "# 下採樣資料\n",
    "# sampling_ratio = 0.4  # 下採樣比例，根據A1 和 A2 原始數據量比例調整\n",
    "# total_ratio = len(full_dataA1) / len(full_dataA2) # 保留 A1/A2 的比例\n",
    "# downsampled_A1, downsampled_A2 = downsample_by_month_simple(full_dataA1, full_dataA2, sampling_ratio, total_ratio)\n",
    "\n",
    "# Concat\n",
    "rbind_data = pd.concat([full_dataA1, full_dataA2], axis=0, ignore_index=True)\n",
    "rbind_data.drop(columns=['發生月份'], inplace=True)\n",
    "# 處理年齡和速限\n",
    "rbind_data = process_age_speed(rbind_data)\n",
    "death = rbind_data['死亡']\n",
    "rbind_data.drop(['死亡', '受傷'], axis=1, inplace=True)\n",
    "# 唯一值處理\n",
    "columns_to_drop = []\n",
    "for column in rbind_data.columns:\n",
    "    if rbind_data[column].nunique() == 1:  # 檢查唯一值數量是否等於 1\n",
    "        columns_to_drop.append(column)\n",
    "rbind_data.drop(columns=columns_to_drop, inplace=True)\n",
    "# Dummy\n",
    "rbind_data[\"速限-第1當事者\"] = rbind_data[\"速限-第1當事者\"].astype(str)\n",
    "dummy_data = pd.get_dummies(rbind_data)\n",
    "print('dummy_data:', dummy_data.shape)\n",
    "mapper_numpy = dummy_data.to_numpy()\n",
    "\n",
    "rbind_data['顯著特徵'] = rbind_data['道路型態子類別名稱'] + ',' + rbind_data['號誌-號誌動作名稱'] + ',' + rbind_data['天候名稱']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "篩選掉未紀錄資料以及分類人的狀態以及車的狀態"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kmode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmodes.kmodes import KModes\n",
    "\n",
    "data_for_kmode = rbind_data.drop(['死亡', '受傷', 'color_for_plot'], axis=1)\n",
    "\n",
    "cost = []\n",
    "all_results = {}\n",
    "K = range(1, 5)\n",
    "\n",
    "for k in K:\n",
    "\n",
    "    km = KModes(\n",
    "    n_clusters=k, \n",
    "    init='Huang',\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=10\n",
    "    )\n",
    "\n",
    "    labels = km.fit_predict(data_for_kmode)\n",
    "    cost.append(km.cost_)\n",
    "    all_results[k] = {\n",
    "        'cost': km.cost_,\n",
    "        'labels': labels,\n",
    "        'centroids': km.cluster_centroids_\n",
    "    }\n",
    "\n",
    "optimal_k = K[cost.index(min(cost))]\n",
    "optimal_result = all_results[optimal_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('Version3/Data/CarData/kmode_result.pickle', 'wb') as f:\n",
    "#     pickle.dump(all_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K, cost, marker='o')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    48690\n",
      "0    46813\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(all_results[2]['labels']).value_counts())\n",
    "rbind_data['Cluster'] = all_results[2]['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mca = prince.MCA(\n",
    "    one_hot=False,\n",
    "    n_components=8,\n",
    "    n_iter=30,\n",
    "    copy=True,\n",
    "    check_input=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "mca.fit(dummy_data)\n",
    "lens = mca.transform(dummy_data)\n",
    "\n",
    "print(mca.eigenvalues_summary)\n",
    "\n",
    "eigenvalues = mca.eigenvalues_\n",
    "\n",
    "components = range(0, len(eigenvalues))\n",
    "\n",
    "variance = mca.eigenvalues_summary['% of variance']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(components, eigenvalues, marker='o', linestyle='--')\n",
    "plt.title(\"Scree Plot\")\n",
    "plt.xlabel(\"Component\")\n",
    "plt.ylabel(\"Eigenvalue\")\n",
    "plt.xticks(components)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search_info = {\n",
    "#     'lens': lens,\n",
    "#     'mapper_numpy': mapper_numpy,\n",
    "#     'rbind_data': rbind_data,\n",
    "# }\n",
    "# with open('../ForMatrix/CalculatedData/car.pkl', 'wb') as f:\n",
    "#     pickle.dump(grid_search_info, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mca(mca, dummy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = 2\n",
    "interval = 8\n",
    "detailed_results = []\n",
    "silhouette_for_intervals = []\n",
    "\n",
    "mapper_algo = MapperAlgorithm(\n",
    "    cover=CubicalCover(\n",
    "        n_intervals=interval,\n",
    "        overlap_frac=overlap / 10\n",
    "    ),\n",
    "    clustering=FailSafeClustering(\n",
    "        AgglomerativeClustering(\n",
    "            n_clusters=2,\n",
    "            linkage='ward'\n",
    "        )\n",
    "    ),\n",
    "    n_jobs=12\n",
    ")\n",
    "\n",
    "mapper_info = mapper_algo.fit_transform(mapper_numpy, lens)\n",
    "silhouette_for_intervals.append(mapper_info[1])\n",
    "result = {\n",
    "    \"overlap\": overlap,\n",
    "    \"interval\": interval,\n",
    "    \"silhouette\": mapper_info[1],\n",
    "    \"mapper_info\": mapper_info\n",
    "}\n",
    "detailed_results.append(result)\n",
    "detailed_results_df = pd.DataFrame(detailed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Version4/GridSearch/Component8Car/results_o2i8.pkl', 'rb') as f:\n",
    "    detailed_results_df = pickle.load(f)\n",
    "\n",
    "# with open('Version3/Data/CarData/mapper_info.pickle', 'wb') as f:\n",
    "#     pickle.dump(detailed_results_df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目前分析使用的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choose = '顯著特徵'\n",
    "\n",
    "mapper_plotter = MapperPlotter(detailed_results_df['mapper_info'], rbind_data, seed=14, iterations=150,\n",
    "                                range_lst=[-0.05, 0.075, 0.2, -0.2], dim=3)\n",
    "mapper_plot = mapper_plotter.create_mapper_plot(choose, most_common_encoded_label, avg=False)\n",
    "full_info = mapper_plotter.extract_data()\n",
    "mapper_plotter.map_colors(choose, size=15, threshold=0)\n",
    "mapper_plotter.plot(choose, avg=False, set_label=True, size=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choose = '死亡'\n",
    "rbind_data['死亡'] = death\n",
    "\n",
    "for i in [14]:\n",
    "    print(f'Seed: {i}')\n",
    "    mapper_plotter = MapperPlotter(detailed_results_df['mapper_info'], rbind_data, seed=i, iterations=150,\n",
    "                                   range_lst=[-0.05, 0.075, 0.2, -0.2], dim=3)\n",
    "    mapper_plot = mapper_plotter.create_mapper_plot(choose, sum_of_data, avg=True)\n",
    "    full_info = mapper_plotter.extract_data()\n",
    "    full_info[['x', 'y', 'z']] = rotate_z(full_info[['x', 'y', 'z']], -30)\n",
    "    mapper_plotter.map_colors(choose, size=15, threshold=0)\n",
    "    mapper_plotter.plot_dens(choose, avg=True, set_label=False, size=3000, minimum_lst=[-0.025, 0.075])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "rectangle1 = Polygon([(0.0071, -0.025), (-0.04, -0.025),(-0.04, 0.055), (0.0071, 0.055)])\n",
    "rectangle2 = Polygon([(0.0071, -0.025), (0.0071, 0.055), (0.0435, 0.055), (0.0435, -0.025)])\n",
    "rectangle3 = Polygon([(0.0435, -0.03), (0.0435, 0.065),(0.09, 0.065), (0.09, -0.03)])\n",
    "\n",
    "filtered_full_info = full_info[(full_info['y'] > -0.2) &\n",
    "                               (full_info['y'] < 0.1) &\n",
    "                               (full_info['x'] > -0.1) &\n",
    "                               (full_info['x'] < 0.15)]\n",
    "filtered_full_info = filtered_full_info[filtered_full_info['size'] > 15]\n",
    "filtered_full_info = full_info\n",
    "\n",
    "# 檢查每個點是否在任意一個區塊內\n",
    "inside_indices_1 = filtered_full_info.apply(lambda row: Point(row['x'], row['y']).within(rectangle1), axis=1)\n",
    "inside_indices_2 = filtered_full_info.apply(lambda row: Point(row['x'], row['y']).within(rectangle2), axis=1)\n",
    "inside_indices_3 = filtered_full_info.apply(lambda row: Point(row['x'], row['y']).within(rectangle3), axis=1)\n",
    "\n",
    "label_0 = filtered_full_info[inside_indices_1]\n",
    "label_1 = filtered_full_info[inside_indices_2]\n",
    "label_2 = filtered_full_info[inside_indices_3]\n",
    "\n",
    "# 提取區域內和區域外的數據\n",
    "all_inside_indices = inside_indices_1 | inside_indices_2 | inside_indices_3\n",
    "outside_indices = ~all_inside_indices\n",
    "\n",
    "label_out = filtered_full_info[outside_indices]\n",
    "\n",
    "# assert label_0.shape[0] + label_1.shape[0] + label_out.shape[0] == filtered_full_info.shape[0]\n",
    "\n",
    "# 繪製數據點和矩形區塊\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(label_0['x'], label_0['y'], color='green', s=10)\n",
    "plt.scatter(label_1['x'], label_1['y'], color='blue', s=10)\n",
    "plt.scatter(label_2['x'], label_2['y'], color='purple', s=10)\n",
    "plt.scatter(label_out['x'], label_out['y'], color='red', s=10)\n",
    "\n",
    "# 繪製矩形區塊\n",
    "for rect, color, alpha in zip([rectangle1, rectangle2, rectangle3], \n",
    "                              ['green', 'blue', 'purple'], \n",
    "                              [0.2, 0.2, 0.2]):\n",
    "    x, y = rect.exterior.xy\n",
    "    plt.fill(x, y, color=color, alpha=alpha)\n",
    "\n",
    "# 圖形調整\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.axis(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105824\n",
      "105824\n"
     ]
    }
   ],
   "source": [
    "# 獲取每個label的index\n",
    "count_0 = get_unique_ids(label_0)\n",
    "count_1 = get_unique_ids(label_1)\n",
    "count_2 = get_unique_ids(label_2)\n",
    "count_out = get_unique_ids(label_out)\n",
    "\n",
    "index_to_groups = {}\n",
    "\n",
    "# 將索引與群體的關係記錄下來\n",
    "for group_name, group_indexes in zip(\n",
    "    [\"full_0\", \"full_1\", \"full_2\", \"full_out\"],\n",
    "    [count_0, count_1, count_2, count_out],\n",
    "):\n",
    "    for idx in group_indexes:\n",
    "        if idx not in index_to_groups:\n",
    "            index_to_groups[idx] = set()\n",
    "        index_to_groups[idx].add(group_name)\n",
    "\n",
    "# 找交集索引\n",
    "intersection_indexes = {idx for idx, groups in index_to_groups.items() if len(groups) > 1}\n",
    "\n",
    "# 移除交集的index\n",
    "count_0 = [i for i in count_0 if i not in intersection_indexes]\n",
    "count_1 = [i for i in count_1 if i not in intersection_indexes]\n",
    "count_2 = [i for i in count_2 if i not in intersection_indexes]\n",
    "count_out = [i for i in count_out if i not in intersection_indexes]\n",
    "\n",
    "# 分群處理\n",
    "full_0 = rbind_data.loc[count_0]\n",
    "full_1 = rbind_data.loc[count_1]\n",
    "full_2 = rbind_data.loc[count_2]\n",
    "full_out = rbind_data.loc[count_out]\n",
    "overlap_data = rbind_data.loc[list(intersection_indexes)]\n",
    "\n",
    "# 確認所有資料都被獲取\n",
    "assert len(count_0) == full_0.shape[0]\n",
    "assert len(count_1) == full_1.shape[0]\n",
    "assert len(count_2) == full_2.shape[0]\n",
    "assert len(count_out) == full_out.shape[0]\n",
    "\n",
    "print(full_0.shape[0] + full_1.shape[0] + full_2.shape[0] + full_out.shape[0] + overlap_data.shape[0])\n",
    "print(rbind_data.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_info.to_csv('./Data/CarData/full_info.csv', index=False)\n",
    "full_0.to_csv('./Data/CarData/full_0.csv', index=False)\n",
    "full_1.to_csv('./Data/CarData/full_1.csv', index=False)\n",
    "full_2.to_csv('./Data/CarData/full_2.csv', index=False)\n",
    "full_out.to_csv('./Data/CarData/full_out.csv', index=False)\n",
    "overlap_data.to_csv('./Data/CarData/overlap_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_0['死亡'].value_counts())\n",
    "print(full_1['死亡'].value_counts())\n",
    "print(full_2['死亡'].value_counts())\n",
    "print(full_out['死亡'].value_counts())\n",
    "print(overlap_data['死亡'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
