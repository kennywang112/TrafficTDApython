{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69a96d94-ab14-4996-ab85-73eae934a135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from tdamapper.core import MapperAlgorithm\n",
    "from tdamapper.cover import CubicalCover\n",
    "from tdamapper.plot import MapperLayoutInteractive, MapperLayoutStatic\n",
    "from tdamapper.clustering import FailSafeClustering\n",
    "from sklearn import metrics\n",
    "\n",
    "from functions import *\n",
    "from chi import *\n",
    "from regressionP import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b571ed9-5bfb-40f3-a864-f2029cb50332",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"./Data/NPA_TMA2_1.csv\", low_memory=False)[:-2]\n",
    "data2 = pd.read_csv(\"./Data/NPA_TMA2_2.csv\", low_memory=False)[:-2]\n",
    "data3 = pd.read_csv(\"./Data/NPA_TMA2_3.csv\", low_memory=False)[:-2]\n",
    "data4 = pd.read_csv(\"./Data/NPA_TMA2_4.csv\", low_memory=False)[:-2]\n",
    "dataA2 = pd.concat([data1, data2, data3, data4], ignore_index=True)\n",
    "\n",
    "dataA1 = pd.read_csv(\"./Data/NPA_TMA1.csv\")[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "939ce82b-c766-4042-a34f-b4780ac3335e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>天候名稱</th>\n",
       "      <th>路面狀況-路面狀態名稱</th>\n",
       "      <th>肇因研判大類別名稱-主要</th>\n",
       "      <th>當事者屬-性-別名稱</th>\n",
       "      <th>當事者事故發生時年齡</th>\n",
       "      <th>車輛撞擊部位大類別名稱-最初</th>\n",
       "      <th>光線名稱</th>\n",
       "      <th>道路類別-第1當事者-名稱</th>\n",
       "      <th>速限-第1當事者</th>\n",
       "      <th>道路型態大類別名稱</th>\n",
       "      <th>...</th>\n",
       "      <th>肇因研判大類別名稱-個別</th>\n",
       "      <th>肇事逃逸類別名稱-是否肇逃</th>\n",
       "      <th>路面狀況-路面鋪裝名稱</th>\n",
       "      <th>路面狀況-路面缺陷名稱</th>\n",
       "      <th>道路障礙-障礙物名稱</th>\n",
       "      <th>道路障礙-視距品質名稱</th>\n",
       "      <th>道路障礙-視距名稱</th>\n",
       "      <th>號誌-號誌動作名稱</th>\n",
       "      <th>死亡</th>\n",
       "      <th>受傷</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.447747</td>\n",
       "      <td>-0.331183</td>\n",
       "      <td>0.509425</td>\n",
       "      <td>0.739901</td>\n",
       "      <td>-1.261265</td>\n",
       "      <td>-0.372169</td>\n",
       "      <td>0.146102</td>\n",
       "      <td>2.120706</td>\n",
       "      <td>-0.146069</td>\n",
       "      <td>1.210906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508523</td>\n",
       "      <td>-0.135001</td>\n",
       "      <td>-0.045604</td>\n",
       "      <td>-0.029347</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.118545</td>\n",
       "      <td>0.060048</td>\n",
       "      <td>0.837867</td>\n",
       "      <td>13.660843</td>\n",
       "      <td>-2.803204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.447747</td>\n",
       "      <td>-0.331183</td>\n",
       "      <td>0.509425</td>\n",
       "      <td>0.739901</td>\n",
       "      <td>0.778508</td>\n",
       "      <td>1.175119</td>\n",
       "      <td>1.465217</td>\n",
       "      <td>-0.251720</td>\n",
       "      <td>-0.146069</td>\n",
       "      <td>-0.814068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508523</td>\n",
       "      <td>-0.135001</td>\n",
       "      <td>-0.045604</td>\n",
       "      <td>-0.029347</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.118545</td>\n",
       "      <td>0.060048</td>\n",
       "      <td>-1.192531</td>\n",
       "      <td>13.660843</td>\n",
       "      <td>-0.620846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.201000</td>\n",
       "      <td>-0.331183</td>\n",
       "      <td>0.509425</td>\n",
       "      <td>0.739901</td>\n",
       "      <td>1.100577</td>\n",
       "      <td>-0.372169</td>\n",
       "      <td>-1.173013</td>\n",
       "      <td>2.911514</td>\n",
       "      <td>-0.146069</td>\n",
       "      <td>1.210906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508523</td>\n",
       "      <td>-0.135001</td>\n",
       "      <td>-0.045604</td>\n",
       "      <td>-0.029347</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.118545</td>\n",
       "      <td>0.060048</td>\n",
       "      <td>0.837867</td>\n",
       "      <td>13.660843</td>\n",
       "      <td>-2.803204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.447747</td>\n",
       "      <td>-0.331183</td>\n",
       "      <td>0.509425</td>\n",
       "      <td>0.739901</td>\n",
       "      <td>-0.563448</td>\n",
       "      <td>-0.372169</td>\n",
       "      <td>-1.173013</td>\n",
       "      <td>-0.251720</td>\n",
       "      <td>-0.146069</td>\n",
       "      <td>-0.814068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508523</td>\n",
       "      <td>-0.135001</td>\n",
       "      <td>-0.045604</td>\n",
       "      <td>-0.029347</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.118545</td>\n",
       "      <td>0.060048</td>\n",
       "      <td>-1.192531</td>\n",
       "      <td>13.660843</td>\n",
       "      <td>-0.620846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.201000</td>\n",
       "      <td>-0.331183</td>\n",
       "      <td>0.509425</td>\n",
       "      <td>0.739901</td>\n",
       "      <td>-1.046552</td>\n",
       "      <td>-0.372169</td>\n",
       "      <td>1.465217</td>\n",
       "      <td>2.120706</td>\n",
       "      <td>-0.146069</td>\n",
       "      <td>1.210906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508523</td>\n",
       "      <td>-0.135001</td>\n",
       "      <td>-0.045604</td>\n",
       "      <td>-0.029347</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.118545</td>\n",
       "      <td>0.060048</td>\n",
       "      <td>0.837867</td>\n",
       "      <td>13.660843</td>\n",
       "      <td>-2.803204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       天候名稱  路面狀況-路面狀態名稱  肇因研判大類別名稱-主要  當事者屬-性-別名稱  當事者事故發生時年齡  \\\n",
       "0 -0.447747    -0.331183      0.509425    0.739901   -1.261265   \n",
       "1 -0.447747    -0.331183      0.509425    0.739901    0.778508   \n",
       "2  1.201000    -0.331183      0.509425    0.739901    1.100577   \n",
       "3 -0.447747    -0.331183      0.509425    0.739901   -0.563448   \n",
       "4  1.201000    -0.331183      0.509425    0.739901   -1.046552   \n",
       "\n",
       "   車輛撞擊部位大類別名稱-最初      光線名稱  道路類別-第1當事者-名稱  速限-第1當事者  道路型態大類別名稱  ...  \\\n",
       "0       -0.372169  0.146102       2.120706 -0.146069   1.210906  ...   \n",
       "1        1.175119  1.465217      -0.251720 -0.146069  -0.814068  ...   \n",
       "2       -0.372169 -1.173013       2.911514 -0.146069   1.210906  ...   \n",
       "3       -0.372169 -1.173013      -0.251720 -0.146069  -0.814068  ...   \n",
       "4       -0.372169  1.465217       2.120706 -0.146069   1.210906  ...   \n",
       "\n",
       "   肇因研判大類別名稱-個別  肇事逃逸類別名稱-是否肇逃  路面狀況-路面鋪裝名稱  路面狀況-路面缺陷名稱  道路障礙-障礙物名稱  \\\n",
       "0      0.508523      -0.135001    -0.045604    -0.029347    0.001515   \n",
       "1      0.508523      -0.135001    -0.045604    -0.029347    0.001515   \n",
       "2      0.508523      -0.135001    -0.045604    -0.029347    0.001515   \n",
       "3      0.508523      -0.135001    -0.045604    -0.029347    0.001515   \n",
       "4      0.508523      -0.135001    -0.045604    -0.029347    0.001515   \n",
       "\n",
       "   道路障礙-視距品質名稱  道路障礙-視距名稱  號誌-號誌動作名稱         死亡        受傷  \n",
       "0     0.118545   0.060048   0.837867  13.660843 -2.803204  \n",
       "1     0.118545   0.060048  -1.192531  13.660843 -0.620846  \n",
       "2     0.118545   0.060048   0.837867  13.660843 -2.803204  \n",
       "3     0.118545   0.060048  -1.192531  13.660843 -0.620846  \n",
       "4     0.118545   0.060048   0.837867  13.660843 -2.803204  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(input_data, select_lst, sample = 592):\n",
    "    sample_data = input_data[input_data['當事者順位'] == 1].reset_index(drop=True, inplace=False)\n",
    "    dataA = sample_data[select_lst]\n",
    "    \n",
    "    death_injury_data = split_death_injury(dataA['死亡受傷人數'])\n",
    "    dist_df = pd.concat([dataA, death_injury_data], axis=1)\n",
    "    dist_df.drop(columns=['死亡受傷人數'], inplace=True)\n",
    "    \n",
    "    return dist_df, sample_data\n",
    "select_lst = [\n",
    "    '天候名稱', \n",
    "    '路面狀況-路面狀態名稱',\n",
    "    '肇因研判大類別名稱-主要', '當事者屬-性-別名稱', '當事者事故發生時年齡', \n",
    "    '車輛撞擊部位大類別名稱-最初',\n",
    "    '光線名稱',\n",
    "    '道路類別-第1當事者-名稱',\n",
    "    '速限-第1當事者', \n",
    "    '道路型態大類別名稱',\n",
    "    '事故位置大類別名稱', \n",
    "    '號誌-號誌種類名稱',\n",
    "    '車道劃分設施-分向設施大類別名稱', '車道劃分設施-分道設施-快車道或一般車道間名稱',\n",
    "    '車道劃分設施-分道設施-快慢車道間名稱', '車道劃分設施-分道設施-路面邊線名稱',\n",
    "    '事故類型及型態大類別名稱',\n",
    "    '死亡受傷人數',\n",
    "    '經度', '緯度',\n",
    "    '道路型態子類別名稱', '事故位置子類別名稱', '車道劃分設施-分向設施子類別名稱', '事故類型及型態子類別名稱', \n",
    "    '當事者行動狀態子類別名稱', '車輛撞擊部位子類別名稱-最初', '車輛撞擊部位子類別名稱-其他', '肇因研判子類別名稱-個別',\n",
    "    \n",
    "    '當事者區分-類別-大類別名稱-車種', '當事者區分-類別-子類別名稱-車種',\n",
    "    '保護裝備名稱', '行動電話或電腦或其他相類功能裝置名稱', '當事者行動狀態大類別名稱',\n",
    "    '車輛撞擊部位大類別名稱-其他', '肇因研判大類別名稱-個別', '肇事逃逸類別名稱-是否肇逃',\n",
    "    '路面狀況-路面鋪裝名稱', '路面狀況-路面缺陷名稱',\n",
    "    '道路障礙-障礙物名稱', '道路障礙-視距品質名稱', '道路障礙-視距名稱','號誌-號誌動作名稱',\n",
    "]\n",
    "\n",
    "dist_dfA1 = preprocess(dataA1, select_lst, sample = 592)\n",
    "dist_dfA2 = preprocess(dataA2, select_lst, sample = 11840) # 120420\n",
    "\n",
    "    \n",
    "rbind_data = pd.concat([dist_dfA1[0], dist_dfA2[0]], axis=0, ignore_index=True)\n",
    "\n",
    "rbind_data.loc[rbind_data['受傷'] > 1, '受傷'] = 2\n",
    "rbind_data['速限-第1當事者'] = rbind_data['速限-第1當事者'].apply(lambda x: 1 if x > 60 else 0)\n",
    "# rbind_data = process_age(rbind_data)\n",
    "\n",
    "dist_df = process_data(rbind_data)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "full_dist = pd.DataFrame(scaler.fit_transform(dist_df), columns = dist_df.columns)\n",
    "X1 = full_dist.drop(['受傷', '死亡', '經度', '緯度'], axis=1).to_numpy()\n",
    "\n",
    "full_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4261b10-f9fd-4909-809c-54a70ec93b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('CalculatedData/mapper_graph1.pkl', 'rb') as f:\n",
    "    mapper_graph1 = pickle.load(f)\n",
    "    \n",
    "mapper_plot1 = MapperLayoutInteractive(\n",
    "    mapper_graph1,\n",
    "    colors = dist_df[['速限-第1當事者']].to_numpy(),\n",
    "    cmap = 'jet',\n",
    "    # agg = np.nanmean,\n",
    "    agg = most_frequent_nonan,\n",
    "    dim = 3,\n",
    "    iterations = 30,\n",
    "    seed = 6,\n",
    "    width = 800,\n",
    "    height = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5985e926-dcf2-4764-b4fe-3789bca826cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vars(mapper_plot1._MapperLayoutInteractive__fig)['_data_objs'][1]['x']\n",
    "y = vars(mapper_plot1._MapperLayoutInteractive__fig)['_data_objs'][1]['y']\n",
    "z = vars(mapper_plot1._MapperLayoutInteractive__fig)['_data_objs'][1]['z']\n",
    "\n",
    "threeDimData = pd.DataFrame({'x': x, 'y': y, 'z': z})\n",
    "\n",
    "import re\n",
    "data_tuple = vars(mapper_plot1._MapperLayoutInteractive__fig)['_data_objs'][1]['text']\n",
    "\n",
    "data = []\n",
    "for item in data_tuple:\n",
    "    color = int(re.search(r'color: (-?\\d+)', item).group(1))\n",
    "    node = int(re.search(r'node: (\\d+)', item).group(1))\n",
    "    size = int(re.search(r'size: (\\d+)', item).group(1))\n",
    "    data.append({'color': color, 'node': node, 'size': size})\n",
    "component_info = pd.DataFrame(data)\n",
    "\n",
    "full_info = pd.concat([component_info, threeDimData], axis=1)\n",
    "\n",
    "mp_content_origin = vars(mapper_plot1._MapperLayoutInteractive__graph)['_node']\n",
    "\n",
    "mp_content = pd.DataFrame.from_dict(mp_content_origin, orient='index')\n",
    "mp_content.reset_index(inplace=True)\n",
    "mp_content.rename(columns={'index': 'node'}, inplace=True)\n",
    "\n",
    "full_info = pd.merge(full_info, mp_content, on=['node', 'size'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "be7e62f3-7454-4853-a894-ff05756df795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calinski_data = get_calinski_from_db(full_info, 0.03)\n",
    "# labels = calinski_data[3]\n",
    "# db = calinski_data[2]\n",
    "# n_clusters_ = calinski_data[4]\n",
    "\n",
    "# unique_labels = set(labels)\n",
    "# core_samples_mask = np.zeros_like(labels, dtype=bool)\n",
    "# core_samples_mask[db.core_sample_indices_] = True\n",
    "\n",
    "# def matplotlib_to_plotly(cmap, alpha=1):\n",
    "#     \"\"\"rgba\"\"\"\n",
    "#     return f'rgba({int(cmap[0]*200)}, {int(cmap[1]*200)}, {int(cmap[2]*200)}, {alpha})'\n",
    "\n",
    "# colors = [matplotlib_to_plotly(plt.cm.Spectral(each), alpha=0.8) for each in np.linspace(0, 1, len(unique_labels))]\n",
    "# fig = go.Figure()\n",
    "\n",
    "# for k, col in zip(unique_labels, colors):\n",
    "#     if k == -1:\n",
    "#         # col = 'rgba(0,0,0,0)'\n",
    "#         col = 'rgba(0,0,0,0)'\n",
    "\n",
    "#     class_member_mask = labels == k\n",
    "\n",
    "#     core_samples = full_info.iloc[:, 3:6][class_member_mask & core_samples_mask]\n",
    "#     fig.add_trace(go.Scatter3d(\n",
    "#         x=core_samples.iloc[:, 0],\n",
    "#         y=core_samples.iloc[:, 1],\n",
    "#         z=core_samples.iloc[:, 2],\n",
    "#         mode='markers',\n",
    "#         marker=dict(\n",
    "#             size=6,\n",
    "#             color=col,\n",
    "#             opacity=0.8\n",
    "#         ),\n",
    "#         name=f'Cluster {k} Core'\n",
    "#     ))\n",
    "\n",
    "#     non_core_samples = full_info.iloc[:, 3:6][class_member_mask & ~core_samples_mask]\n",
    "#     fig.add_trace(go.Scatter3d(\n",
    "#         x=non_core_samples.iloc[:, 0],\n",
    "#         y=non_core_samples.iloc[:, 1],\n",
    "#         z=non_core_samples.iloc[:, 2],\n",
    "#         mode='markers',\n",
    "#         marker=dict(\n",
    "#             size=6,\n",
    "#             color=col,\n",
    "#             opacity=0.5\n",
    "#         ),\n",
    "#         name=f'Cluster {k} Non-Core'\n",
    "#     ))\n",
    "\n",
    "# fig.update_layout(\n",
    "#     title=f\"Estimated number of clusters: {n_clusters_}\",\n",
    "#     margin=dict(l=0, r=0, b=0, t=0)\n",
    "# )\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6353476-45f3-46ff-b616-33db90377f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calinski_from_db(input_data, eps): \n",
    "    X = input_data.iloc[:, 3:6]\n",
    "\n",
    "    db = DBSCAN(eps=eps, min_samples=10).fit(X)\n",
    "    labels = db.labels_\n",
    "    n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    print(set(labels))\n",
    "\n",
    "    input_data['label'] = labels\n",
    "    \n",
    "    unique_labels = np.unique(labels)\n",
    "    colors = plt.cm.Spectral(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "    if len(set(labels)) != 1:\n",
    "        score = metrics.calinski_harabasz_score(X, labels)\n",
    "        silhouette_score_value = silhouette_score(X, labels)\n",
    "    else:\n",
    "        score = -1\n",
    "        silhouette_score_value = -1\n",
    "        \n",
    "    return score, input_data, db, labels, n_clusters_, silhouette_score_value, unique_labels, colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5560cf2a-713a-49c6-a96a-4fd21f0164b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, -1}\n",
      "[ 0  1  2 -1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "538"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.03 預測最好\n",
    "calinski_data = get_calinski_from_db(full_info, 0.03)\n",
    "\n",
    "label_0 = full_info[full_info['label'] == 0]\n",
    "label_1 = full_info[full_info['label'] == 1]\n",
    "label_2 = full_info[full_info['label'] == 2]\n",
    "label_out = full_info[(full_info['label'] != 1) & (full_info['label'] != 2) & (full_info['label'] != 0)]\n",
    "\n",
    "count_0 = get_count_dict(label_0)\n",
    "count_1 = get_count_dict(label_1)\n",
    "count_2 = get_count_dict(label_2)\n",
    "count_out = get_count_dict(label_out)\n",
    "\n",
    "print(full_info['label'].unique())\n",
    "\n",
    "len(count_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7958c3b3-880d-432c-a6af-c06e595b0dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_0 = rbind_data.loc[count_0.keys()]\n",
    "full_1 = rbind_data.loc[count_1.keys()]\n",
    "full_2 = rbind_data.loc[count_2.keys()]\n",
    "full_out = rbind_data.loc[count_out.keys()]\n",
    "\n",
    "full_combine.shape[0] + full_0.shape[0] + full_1.shape[0] + full_2.shape[0] == rbind_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64e78bdb-763d-4935-a1ec-46d4b5caf5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    512\n",
      "2    245\n",
      "dtype: int64\n",
      "1    80749\n",
      "2    31957\n",
      "dtype: int64\n",
      "1    3857\n",
      "2    2080\n",
      "dtype: int64\n",
      "1    1652\n",
      "2     779\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "lst_logit = [\n",
    "    '路面狀況-路面狀態名稱',\n",
    "    # '肇因研判大類別名稱-主要', # 降低預測值\n",
    "    '當事者屬-性-別名稱', '當事者事故發生時年齡', \n",
    "    '車輛撞擊部位大類別名稱-最初',\n",
    "    '光線名稱',\n",
    "    '道路類別-第1當事者-名稱',\n",
    "    '速限-第1當事者',\n",
    "    '道路型態大類別名稱',\n",
    "    '事故位置大類別名稱', \n",
    "    '號誌-號誌種類名稱',\n",
    "    '車道劃分設施-分向設施大類別名稱', '車道劃分設施-分道設施-快車道或一般車道間名稱',\n",
    "    '車道劃分設施-分道設施-快慢車道間名稱', '車道劃分設施-分道設施-路面邊線名稱',\n",
    "    '事故類型及型態大類別名稱',\n",
    "    '事故位置子類別名稱', '事故類型及型態子類別名稱', \n",
    "    '當事者行動狀態子類別名稱', '車輛撞擊部位子類別名稱-最初', '肇因研判子類別名稱-個別',\n",
    "    # '當事者區分-類別-大類別名稱-車種', \n",
    "    '當事者區分-類別-子類別名稱-車種',\n",
    "    '保護裝備名稱', '行動電話或電腦或其他相類功能裝置名稱', '當事者行動狀態大類別名稱',\n",
    "    '車輛撞擊部位大類別名稱-其他', '肇因研判大類別名稱-個別', '肇事逃逸類別名稱-是否肇逃',\n",
    "    '號誌-號誌動作名稱',\n",
    "    # '路面狀況-路面鋪裝名稱', '道路障礙-視距名稱', '車道劃分設施-分向設施子類別名稱', '車道劃分設施-分道設施-快慢車道間名稱', '車輛撞擊部位大類別名稱-其他',\n",
    "    # '道路障礙-障礙物名稱', '道路型態子類別名稱', '路面狀況-路面缺陷名稱', '天候名稱', '車輛撞擊部位子類別名稱-其他', \n",
    "]\n",
    "\n",
    "def get_clusterN_logit(cluster_data, lst):\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    c0_for_lm = process_data(cluster_data)\n",
    "    c0_for_lm_X = pd.DataFrame(scaler.fit_transform(c0_for_lm), columns=c0_for_lm.columns)\n",
    "    \n",
    "    # 設置三個等級的label\n",
    "    # c0_for_lm_y = cluster_data['受傷']\n",
    "    c0_for_lm_y = cluster_data.apply(lambda row: 2 if row['受傷'] >= 2 else 1, axis=1)\n",
    "        \n",
    "    c0_for_lm_X = c0_for_lm_X[lst]\n",
    "    \n",
    "    return c0_for_lm_X, c0_for_lm_y\n",
    "\n",
    "\n",
    "full_combine_X,  full_combine_y = get_clusterN_logit(full_combine, lst_logit)\n",
    "full_0_X, full_0_y = get_clusterN_logit(full_0, lst_logit)\n",
    "full_1_X, full_1_y = get_clusterN_logit(full_1, lst_logit)\n",
    "full_2_X, full_2_y = get_clusterN_logit(full_2, lst_logit)\n",
    "\n",
    "print(full_combine_y.value_counts())\n",
    "print(full_0_y.value_counts())\n",
    "print(full_1_y.value_counts())\n",
    "print(full_2_y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84618464-13dc-4a5d-a8d2-0d48f40727d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6118421052631579 0.645195634815012 0.7163299663299664 0.5482546201232033\n",
      "61.59420943260193\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "matrix_combine, score_combine, cm_combine = logistic_cm_gridsearch(full_combine_X,  full_combine_y)\n",
    "matrix_0, score_0, cm_0 = logistic_cm_gridsearch(full_0_X, full_0_y)\n",
    "matrix_1, score_1, cm_1 = logistic_cm_gridsearch(full_1_X, full_1_y)\n",
    "matrix_2, score_2, cm_2 = logistic_cm_gridsearch(full_2_X, full_2_y)\n",
    "print(score_combine, score_0, score_1, score_2)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d6b469d7-5c6d-4ebd-afc3-1db4b20a378b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6465205217289972\n"
     ]
    }
   ],
   "source": [
    "de = full_combine_X.shape[0] + full_0_X.shape[0] + full_1_X.shape[0] + full_2_X.shape[0]\n",
    "logit_avg_score = (full_combine_X.shape[0]/de)*score_combine + (full_0_X.shape[0]/de)*score_0 + (full_1_X.shape[0]/de)*score_1 + (full_2_X.shape[0]/de)*score_2\n",
    "print(logit_avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4f1af14-6296-4cfe-97b1-6f7e4a680c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "0.7741935483870968 0.7165885977127906 0.625\n",
      "89.2347686290741\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "rf_combine_X, rf_combine_y,  rf_cm_combine = rf_with_gridsearch(full_combine_X,  full_combine_y)\n",
    "rf_matrix_0, rf_score_0, rf_cm_0 = rf_with_gridsearch(full_0_X, full_0_y)\n",
    "rf_matrix_1, rf_score_1, rf_cm_1 = rf_with_gridsearch(full_1_X, full_1_y)\n",
    "print(rf_combine_y, rf_score_0, rf_score_1)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c64ac369-52ff-4e9a-a86d-1db853d1910c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6724565756823822 0.6096974300544372 0.5959821428571429\n",
      "2784.872428894043\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "svc_matrix_com, svc_score_com, svc_cm_combine = svc_cm_with_grid_search(full_combine_X, full_combine_y)\n",
    "svc_matrix_0, svc_score_0, svc_cm_0 = svc_cm_with_grid_search(full_0_X, full_0_y)\n",
    "svc_matrix_1, svc_score_1, svc_cm_1 = svc_cm_with_grid_search(full_1_X, full_1_y)\n",
    "print(svc_score_com, svc_score_0, svc_score_1)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0face31-d723-4bbe-a424-ad724028488d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.629\n",
      "0.716\n",
      "0.61\n"
     ]
    }
   ],
   "source": [
    "de = full_combine_X.shape[0] + full_0_X.shape[0] + full_1_X.shape[0]\n",
    "logit_avg_score = (full_combine_X.shape[0]/de)*score_combine + (full_0_X.shape[0]/de)*score_0 + (full_1_X.shape[0]/de)*score_1\n",
    "rf_avg_score = (full_combine_X.shape[0]/de)*rf_combine_y + (full_0_X.shape[0]/de)*rf_score_0 + (full_1_X.shape[0]/de)*rf_score_1\n",
    "svm_avg_score = (full_combine_X.shape[0]/de)*svc_score_com + (full_0_X.shape[0]/de)*svc_score_0 + (full_1_X.shape[0]/de)*svc_score_1\n",
    "\n",
    "print(round(logit_avg_score, 3))\n",
    "print(round(rf_avg_score, 3))\n",
    "print(round(svm_avg_score, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5661febe-1e11-4503-8563-6caca1c73245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# origin_X, origin_y = get_clusterN_logit(rbind_data, lst_logit)\n",
    "\n",
    "# matrix_origin, score_origin, cm_origin = logistic_cm_gridsearch(origin_X, origin_y)\n",
    "# rf_matrix_origin, rf_score_origin, rf_cm_origin = rf_with_gridsearch(origin_X, origin_y)\n",
    "# svc_matrix_origin, svc_score_origin, svc_cm_origin = svc_cm_with_grid_search(origin_X, origin_y)\n",
    "# print(round(score_origin, 3), round(rf_score_origin, 3), round(svc_score_origin, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d53c605-d192-48c3-b587-a06d3ba433a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Mapper', 'Origin']\n",
    "logit_scores = [logit_avg_score, score_origin]\n",
    "rf_scores = [rf_avg_score, rf_score_origin]\n",
    "svm_scores = [svm_avg_score, svc_score_origin]\n",
    "\n",
    "x = np.arange(len(categories))  # the label locations\n",
    "width = 0.25  # the width of the bars, 更窄一點以便容納三組數據\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width, logit_scores, width, label='Logit')\n",
    "rects2 = ax.bar(x, rf_scores, width, label='RF')\n",
    "rects3 = ax.bar(x + width, svm_scores, width, label='SVM')\n",
    "\n",
    "ax.set_xlabel('Models')\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Scores by different models and data origins')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), ncol=3)  # 調整圖例位置和列數\n",
    "\n",
    "# Attach a text label above each bar in *rects*, displaying its height.\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.3f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 1),  # slight vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
