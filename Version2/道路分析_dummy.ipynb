{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f86ea7dc-6799-42a5-8e84-aa0f6422f5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_dir_path = os.getcwd()\n",
    "current_file_path = os.path.abspath(current_dir_path)\n",
    "current_dir_path = os.path.dirname(current_file_path)\n",
    "parent_dir_path = os.path.dirname(current_dir_path)\n",
    "\n",
    "os.chdir(current_dir_path)\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from tdamapper.core import MapperAlgorithm\n",
    "from tdamapper.cover import CubicalCover\n",
    "from tdamapper.plot import MapperLayoutInteractive, MapperLayoutStatic\n",
    "from tdamapper.clustering import FailSafeClustering\n",
    "from sklearn import metrics\n",
    "\n",
    "from functions import *\n",
    "from chi import *\n",
    "from regressionP import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d35c7e7-b928-434e-b417-3e3e7b30a96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"./Data/NPA_TMA2_1.csv\", low_memory=False)[:-2]\n",
    "data2 = pd.read_csv(\"./Data/NPA_TMA2_2.csv\", low_memory=False)[:-2]\n",
    "data3 = pd.read_csv(\"./Data/NPA_TMA2_3.csv\", low_memory=False)[:-2]\n",
    "data4 = pd.read_csv(\"./Data/NPA_TMA2_4_new.csv\", low_memory=False)[:-2]\n",
    "data5 = pd.read_csv(\"./Data/NPA_TMA2_5.csv\", low_memory=False)[:-2]\n",
    "data6 = pd.read_csv(\"./Data/NPA_TMA2_6_new.csv\", low_memory=False)[:-2]\n",
    "\n",
    "dataA2 = pd.concat([data1, data2, data3, data4, data5, data6], ignore_index=True)\n",
    "\n",
    "dataA1 = pd.read_csv(\"./Data/NPA_TMA1_new.csv\")[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86ccd12a-31b8-46f8-acd7-fbee6f9a531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_lst = [\n",
    "    '道路類別-第1當事者-名稱', '速限-第1當事者', \n",
    "    '道路型態大類別名稱', '道路型態子類別名稱',\n",
    "    '事故位置大類別名稱', '事故位置子類別名稱', \n",
    "    '事故類型及型態大類別名稱', '事故類型及型態子類別名稱',\n",
    "    '路面狀況-路面鋪裝名稱', '路面狀況-路面狀態名稱', '路面狀況-路面缺陷名稱',\n",
    "    '道路障礙-障礙物名稱', '道路障礙-視距品質名稱', '道路障礙-視距名稱',\n",
    "    '號誌-號誌種類名稱', '號誌-號誌動作名稱',\n",
    "    '車道劃分設施-分向設施大類別名稱', '車道劃分設施-分向設施子類別名稱',\n",
    "    '車道劃分設施-分道設施-快車道或一般車道間名稱', '車道劃分設施-分道設施-快慢車道間名稱', '車道劃分設施-分道設施-路面邊線名稱',\n",
    "    '死亡受傷人數'\n",
    "]\n",
    "\n",
    "dist_dfA1 = preprocess(dataA1, select_lst)\n",
    "dist_dfA2 = preprocess(dataA2, select_lst)\n",
    "\n",
    "rbind_data = pd.concat([dist_dfA1[0], dist_dfA2[0]], axis=0, ignore_index=True)\n",
    "rbind_data['速限-第1當事者'] = rbind_data['速限-第1當事者'].apply(lambda x: 1 if x > 60 else 0)\n",
    "\n",
    "select_lst.remove('死亡受傷人數')\n",
    "\n",
    "rbind_data = pd.get_dummies(rbind_data[select_lst], columns=select_lst)\n",
    "\n",
    "X1 = rbind_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbf3b8be-8455-44ea-abda-59837183de66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7968339261493916\n",
      "[0.24139843 0.11647993 0.06990822 0.05897289 0.04888923 0.03367925\n",
      " 0.03299789 0.03136332 0.02868323 0.02471669 0.02423999 0.02255262\n",
      " 0.02212497 0.02188056 0.0189467 ]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=15)\n",
    "lens1 = pca.fit_transform(X1)\n",
    "\n",
    "# 查看每個主成分保留的變異量比例\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "print(sum(explained_variance_ratio))\n",
    "print(explained_variance_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62ebfe06-7d7d-4fd9-b985-931fc2900963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "678.5134079456329\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "lens1 = PCA(5).fit_transform(X1)\n",
    "\n",
    "mapper_algo1 = MapperAlgorithm(\n",
    "    cover = CubicalCover(\n",
    "        n_intervals = 5,\n",
    "        overlap_frac = 0.45\n",
    "    ),\n",
    "    clustering = FailSafeClustering(\n",
    "        clustering = AgglomerativeClustering(3),\n",
    "        verbose = False)\n",
    ")\n",
    "\n",
    "mapper_graph1 = mapper_algo1.fit_transform(X1, lens1)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7378f777-4701-4a73-99f1-82a61ec14739",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapper_plot1 = MapperLayoutInteractive(\n",
    "    mapper_graph1,\n",
    "    colors = rbind_data[['速限-第1當事者_0']].to_numpy(),\n",
    "    cmap = 'jet',\n",
    "    agg = np.nanmean,\n",
    "    # agg = most_frequent_nonan,\n",
    "    dim = 3,\n",
    "    iterations = 30,\n",
    "    seed = 6,\n",
    "    width = 800,\n",
    "    height = 500)\n",
    "\n",
    "# fig_mean1 = mapper_plot1.plot()\n",
    "# fig_mean1.show(config={'scrollZoom': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80968938-b915-4b08-a38e-3a6d90a1f41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('CalculatedData/道路V2_dummy.pkl', 'wb') as f:\n",
    "#     pickle.dump(mapper_graph1, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6c0e0f-f626-4701-86bf-91e47e81379a",
   "metadata": {},
   "source": [
    "# 模型比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69136bea-425b-4b64-9056-ff3ac294982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to select\n",
    "select_lst = [\n",
    "    '天候名稱', \n",
    "    '路面狀況-路面狀態名稱',\n",
    "    '肇因研判大類別名稱-主要', '當事者屬-性-別名稱', '當事者事故發生時年齡', \n",
    "    '車輛撞擊部位大類別名稱-最初',\n",
    "    '光線名稱',\n",
    "    '道路類別-第1當事者-名稱',\n",
    "    '速限-第1當事者', \n",
    "    '道路型態大類別名稱',\n",
    "    '事故位置大類別名稱', \n",
    "    '號誌-號誌種類名稱',\n",
    "    '車道劃分設施-分向設施大類別名稱', '車道劃分設施-分道設施-快車道或一般車道間名稱',\n",
    "    '車道劃分設施-分道設施-快慢車道間名稱', '車道劃分設施-分道設施-路面邊線名稱',\n",
    "    '事故類型及型態大類別名稱',\n",
    "    '死亡受傷人數',\n",
    "    '經度', '緯度',\n",
    "    '道路型態子類別名稱', '事故位置子類別名稱', '車道劃分設施-分向設施子類別名稱', '事故類型及型態子類別名稱', \n",
    "    '當事者行動狀態子類別名稱', '車輛撞擊部位子類別名稱-最初', '車輛撞擊部位子類別名稱-其他', '肇因研判子類別名稱-個別',\n",
    "    \n",
    "    '當事者區分-類別-大類別名稱-車種', '當事者區分-類別-子類別名稱-車種',\n",
    "    '保護裝備名稱', '行動電話或電腦或其他相類功能裝置名稱', '當事者行動狀態大類別名稱',\n",
    "    '車輛撞擊部位大類別名稱-其他', '肇因研判大類別名稱-個別', '肇事逃逸類別名稱-是否肇逃',\n",
    "    '路面狀況-路面鋪裝名稱', '路面狀況-路面缺陷名稱',\n",
    "    '道路障礙-障礙物名稱', '道路障礙-視距品質名稱', '道路障礙-視距名稱','號誌-號誌動作名稱',\n",
    "]\n",
    "\n",
    "dist_dfA1 = preprocess(dataA1, select_lst)\n",
    "dist_dfA2 = preprocess(dataA2, select_lst)\n",
    "\n",
    "rbind_data = pd.concat([dist_dfA1[0], dist_dfA2[0]], axis=0, ignore_index=True)\n",
    "\n",
    "rbind_data.loc[rbind_data['受傷'] > 1, '受傷'] = 2\n",
    "rbind_data['速限-第1當事者'] = rbind_data['速限-第1當事者'].apply(lambda x: 1 if x > 60 else 0)\n",
    "rbind_data = process_age(rbind_data)\n",
    "# 顏色處理\n",
    "rbind_data['color'] = rbind_data['速限-第1當事者'].astype(str) + rbind_data['事故類型及型態大類別名稱']\n",
    "\n",
    "dist_df = process_data(rbind_data)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "full_dist = pd.DataFrame(scaler.fit_transform(dist_df), columns = dist_df.columns)\n",
    "X1 = full_dist.drop(['受傷', '死亡'], axis=1).to_numpy()\n",
    "\n",
    "# full_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a3fee9f-4aaa-4b0d-a22d-da5c1ac6f820",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # List of columns to select\n",
    "# select_lst = [\n",
    "#     '道路類別-第1當事者-名稱', '速限-第1當事者', \n",
    "#     '道路型態大類別名稱', '道路型態子類別名稱',\n",
    "#     '事故位置大類別名稱', '事故位置子類別名稱', \n",
    "#     '事故類型及型態大類別名稱', '事故類型及型態子類別名稱',\n",
    "#     '路面狀況-路面鋪裝名稱', '路面狀況-路面狀態名稱', '路面狀況-路面缺陷名稱',\n",
    "#     '道路障礙-障礙物名稱', '道路障礙-視距品質名稱', '道路障礙-視距名稱',\n",
    "#     '號誌-號誌種類名稱', '號誌-號誌動作名稱',\n",
    "#     '車道劃分設施-分向設施大類別名稱', '車道劃分設施-分向設施子類別名稱',\n",
    "#     '車道劃分設施-分道設施-快車道或一般車道間名稱', '車道劃分設施-分道設施-快慢車道間名稱', '車道劃分設施-分道設施-路面邊線名稱',\n",
    "#     '死亡受傷人數'\n",
    "# ]\n",
    "\n",
    "# dist_dfA1 = preprocess(dataA1, select_lst)\n",
    "# dist_dfA2 = preprocess(dataA2, select_lst)\n",
    "\n",
    "# rbind_data = pd.concat([dist_dfA1[0], dist_dfA2[0]], axis=0, ignore_index=True)\n",
    "# rbind_data['速限-第1當事者'] = rbind_data['速限-第1當事者'].apply(lambda x: 1 if x > 60 else 0)\n",
    "\n",
    "# select_lst.remove('死亡受傷人數')\n",
    "\n",
    "# dist_df = process_data(rbind_data)\n",
    "# scaler = StandardScaler()\n",
    "# full_dist = pd.DataFrame(scaler.fit_transform(dist_df), columns = dist_df.columns)\n",
    "# rbind_data = pd.get_dummies(rbind_data[select_lst], columns=select_lst)\n",
    "\n",
    "# X1 = rbind_data.to_numpy()\n",
    "# # rbind_data\n",
    "\n",
    "# merged_df = pd.concat([dist_dfA1[0][['死亡', '受傷']], dist_dfA2[0][['死亡', '受傷']]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db1f9889-86ab-4636-b16d-0774223146dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rbind_data_reset = rbind_data.reset_index(drop=True)\n",
    "# merged_df_reset = merged_df.reset_index(drop=True)\n",
    "\n",
    "# rbind_data = pd.concat([rbind_data_reset, merged_df_reset], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db92e887-d74c-43ac-9f5c-e72b066bdc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CalculatedData/道路V2_dummy.pkl', 'rb') as f:\n",
    "    mapper_graph1 = pickle.load(f)\n",
    "    \n",
    "mapper_plot1 = MapperLayoutInteractive(\n",
    "    mapper_graph1,\n",
    "    colors = rbind_data[['速限-第1當事者_0']].to_numpy(),\n",
    "    cmap = 'jet',\n",
    "    # agg = most_frequent_nonan,\n",
    "    agg = np.mean,\n",
    "    dim = 3,\n",
    "    iterations = 30,\n",
    "    seed = 6,\n",
    "    width = 800,\n",
    "    height = 500)\n",
    "\n",
    "# fig_mean1 = mapper_plot1.plot()\n",
    "# fig_mean1.show(config={'scrollZoom': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "03afc0b6-e649-43c7-9805-d2a709913430",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vars(mapper_plot1._MapperLayoutInteractive__fig)['_data_objs'][1]['x']\n",
    "y = vars(mapper_plot1._MapperLayoutInteractive__fig)['_data_objs'][1]['y']\n",
    "z = vars(mapper_plot1._MapperLayoutInteractive__fig)['_data_objs'][1]['z']\n",
    "\n",
    "threeDimData = pd.DataFrame({'x': x, 'y': y, 'z': z})\n",
    "\n",
    "import re\n",
    "data_tuple = vars(mapper_plot1._MapperLayoutInteractive__fig)['_data_objs'][1]['text']\n",
    "\n",
    "data = []\n",
    "for item in data_tuple:\n",
    "    color = int(re.search(r'color: (-?\\d+)', item).group(1))\n",
    "    node = int(re.search(r'node: (\\d+)', item).group(1))\n",
    "    size = int(re.search(r'size: (\\d+)', item).group(1))\n",
    "    data.append({'color': color, 'node': node, 'size': size})\n",
    "component_info = pd.DataFrame(data)\n",
    "\n",
    "full_info = pd.concat([component_info, threeDimData], axis=1)\n",
    "\n",
    "mp_content_origin = vars(mapper_plot1._MapperLayoutInteractive__graph)['_node']\n",
    "\n",
    "mp_content = pd.DataFrame.from_dict(mp_content_origin, orient='index')\n",
    "mp_content.reset_index(inplace=True)\n",
    "mp_content.rename(columns={'index': 'node'}, inplace=True)\n",
    "\n",
    "full_info = pd.merge(full_info, mp_content, on=['node', 'size'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eeaebfc3-9ae4-4b1c-bd58-f97e868a8837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "calinski_data = get_calinski_from_db(full_info, 0.15)\n",
    "labels = calinski_data[3]\n",
    "db = calinski_data[2]\n",
    "n_clusters_ = calinski_data[4]\n",
    "\n",
    "print(n_clusters_)\n",
    "\n",
    "# do_plot(full_info, calinski_data, labels, db, n_clusters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e1b7d8f-059a-48cc-83db-f9be90f7fe7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01連接點數量 5576\n",
      "o0連接點數量 6362\n",
      "o1連接點數量 1026\n",
      "離群值數量 7541\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_0 = full_info[full_info['label'] == 0]\n",
    "label_1 = full_info[full_info['label'] == 1]\n",
    "label_out = full_info[(full_info['label'] != 1) & (full_info['label'] != 0)]\n",
    "\n",
    "count_0 = get_count_dict(label_0)\n",
    "count_1 = get_count_dict(label_1)\n",
    "count_out = get_count_dict(label_out)\n",
    "\n",
    "full_0 = rbind_data.loc[count_0.keys()]\n",
    "full_1 = rbind_data.loc[count_1.keys()]\n",
    "# 離群值不需要被處理\n",
    "full_out = rbind_data.loc[count_out.keys()]\n",
    "lst01 = list(count_0.keys() & count_1.keys())\n",
    "lsto0 = list(count_out.keys() & count_0.keys())\n",
    "lsto1 = list(count_out.keys() & count_1.keys())\n",
    "# Node\n",
    "full_01 = full_0.loc[lst01]\n",
    "\n",
    "full_combine = pd.concat([full_01], axis=0)\n",
    "full_combine = full_combine.reset_index()\n",
    "full_combine = full_combine.drop_duplicates(subset='index', keep='first')\n",
    "full_combine = full_combine.drop('index', axis=1)\n",
    "# 去掉連接點，使分析更嚴謹\n",
    "full_0 = full_0.drop(lst01 + lsto0, errors='ignore')\n",
    "full_1 = full_1.drop(lst01 + lsto1, errors='ignore')\n",
    "\n",
    "print('01連接點數量', len(lst01))\n",
    "print('o0連接點數量', len(lsto0))\n",
    "print('o1連接點數量', len(lsto1))\n",
    "print('離群值數量', full_out.shape[0])\n",
    "\n",
    "full_combine.shape[0] + full_0.shape[0] + full_1.shape[0] + full_out.shape[0] == rbind_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "808fc784-1f28-4ca9-bfd3-bf8d5b44ac0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    5531\n",
      "1      45\n",
      "dtype: int64\n",
      "2    7497\n",
      "1      44\n",
      "dtype: int64\n",
      "2    100396\n",
      "1       478\n",
      "dtype: int64\n",
      "2    75819\n",
      "1      221\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "lst_logit = [\n",
    "    '路面狀況-路面狀態名稱', '當事者屬-性-別名稱', '當事者事故發生時年齡', \n",
    "    '車輛撞擊部位大類別名稱-最初', \n",
    "    '光線名稱', '道路類別-第1當事者-名稱',\n",
    "    '速限-第1當事者', '道路型態大類別名稱', '事故位置大類別名稱', \n",
    "    '號誌-號誌種類名稱', '車道劃分設施-分向設施大類別名稱', '車道劃分設施-分道設施-快車道或一般車道間名稱',\n",
    "    '車道劃分設施-分道設施-快慢車道間名稱', '車道劃分設施-分道設施-路面邊線名稱',\n",
    "    '事故類型及型態大類別名稱', '事故位置子類別名稱', '事故類型及型態子類別名稱', \n",
    "    '當事者行動狀態子類別名稱', '車輛撞擊部位子類別名稱-最初', '肇因研判子類別名稱-個別',\n",
    "    '當事者區分-類別-子類別名稱-車種', '保護裝備名稱', '行動電話或電腦或其他相類功能裝置名稱', \n",
    "    '當事者行動狀態大類別名稱', '車輛撞擊部位大類別名稱-其他', \n",
    "    '肇因研判大類別名稱-個別', '肇事逃逸類別名稱-是否肇逃', '路面狀況-路面鋪裝名稱', \n",
    "    # '車道劃分設施-分向設施子類別名稱', '道路障礙-障礙物名稱', '車輛撞擊部位子類別名稱-其他',\n",
    "\n",
    "    # '號誌-號誌動作名稱', '當事者區分-類別-大類別名稱-車種', '肇因研判大類別名稱-主要', # 降低預測值\n",
    "    # '道路障礙-視距名稱', '車道劃分設施-分道設施-快慢車道間名稱', '車輛撞擊部位大類別名稱-其他', # 降低預測值\n",
    "    # '道路型態子類別名稱', '路面狀況-路面缺陷名稱', '天候名稱' # 降低\n",
    "]\n",
    "\n",
    "full_combine_X, full_combine_y = get_clusterN_logit(full_combine, lst_logit)\n",
    "full_0_X, full_0_y = get_clusterN_logit(full_0, lst_logit)\n",
    "full_1_X, full_1_y = get_clusterN_logit(full_1, lst_logit)\n",
    "full_out_X, full_out_y = get_clusterN_logit(full_out, lst_logit)\n",
    "\n",
    "print(full_combine_y.value_counts())\n",
    "print(full_out_y.value_counts())\n",
    "print(full_0_y.value_counts())\n",
    "print(full_1_y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b5e12d7-102a-4bcc-9d3c-af059fe6cb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=5)\n",
    "# full_0_X = pca.fit_transform(full_0_X)\n",
    "# full_1_X = pca.fit_transform(full_1_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9fafe329-ded7-42e4-b414-3be7adf3fc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6111111111111112 0.6\n",
      "62.06708002090454\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "matrix_combine, score_combine, cm_combine = logistic_cm_gridsearch(full_combine_X, full_combine_y)\n",
    "matrix_out, score_out, cm_out = logistic_cm_gridsearch(full_out_X, full_out_y)\n",
    "print(score_combine, score_out)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "30418102-e983-411a-b004-4883143c00ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0.7013422818791947 0.7619047619047619\n",
      "666.6848707199097\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "matrix_0, score_0, cm_0 = logistic_cm_gridsearch(full_0_X, full_0_y)\n",
    "print('0')\n",
    "matrix_1, score_1, cm_1 = logistic_cm_gridsearch(full_1_X, full_1_y)\n",
    "print('1')\n",
    "\n",
    "print(score_0, score_1)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a2668ca9-b4a7-415f-a31f-709df1dd48cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7193396226415094"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_0_1 = cm_0 + cm_1\n",
    "\n",
    "TP = cm_0_1[0][0]\n",
    "FP = cm_0_1[0][1]\n",
    "FN = cm_0_1[1][0]\n",
    "TN = cm_0_1[1][1]\n",
    "\n",
    "# Re-calculating accuracy\n",
    "accuracy_given_cm = (TP + TN) / (TP + TN + FP + FN)\n",
    "accuracy_given_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e3ae67-f1db-401a-8c89-1feb7c4d6c46",
   "metadata": {},
   "source": [
    "# 顯著特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0783da52-2c60-42c9-bb9b-089c7bb9efb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table(colnames, full_0, full_1):\n",
    "    \n",
    "    combined_df = pd.concat([full_0[colnames].value_counts(normalize = True), \n",
    "                             full_1[colnames].value_counts(normalize = True)\n",
    "                            ],\n",
    "                            axis=1).fillna(0)\n",
    "\n",
    "    combined_df.columns = ['A', 'B']\n",
    "    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a2bdbdac-b321-4651-8213-c66ef99b8cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in full_0.columns:\n",
    "#     print(table(i, full_0, full_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "13681972-633f-46ca-b5ff-b67ca2e95b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y, p = pval(full_0, full_1, [x for x in full_1.columns if x not in ['受傷', '死亡']])\n",
    "# p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
