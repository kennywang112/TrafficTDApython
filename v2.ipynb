{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bddaf5c-ea91-4a28-9b70-d27a27c4f800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from tdamapper.core import MapperAlgorithm\n",
    "from tdamapper.cover import CubicalCover\n",
    "from tdamapper.plot import MapperLayoutInteractive, MapperLayoutStatic\n",
    "from tdamapper.clustering import FailSafeClustering\n",
    "from sklearn import metrics\n",
    "\n",
    "from functions import *\n",
    "from chi import *\n",
    "from regressionP import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "856b81c2-b4a4-4cc0-81c6-59bf5e3bab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"./Data/NPA_TMA2_1.csv\", low_memory=False)[:-2]\n",
    "data2 = pd.read_csv(\"./Data/NPA_TMA2_2.csv\", low_memory=False)[:-2]\n",
    "data3 = pd.read_csv(\"./Data/NPA_TMA2_3.csv\", low_memory=False)[:-2]\n",
    "data4 = pd.read_csv(\"./Data/NPA_TMA2_4.csv\", low_memory=False)[:-2]\n",
    "dataA2 = pd.concat([data1, data2, data3, data4], ignore_index=True)\n",
    "\n",
    "dataA1 = pd.read_csv(\"./Data/NPA_TMA1.csv\")[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e8560f5-14f7-4f9d-ad6b-7ee1e53706ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>天候名稱</th>\n",
       "      <th>路面狀況-路面狀態名稱</th>\n",
       "      <th>肇因研判大類別名稱-主要</th>\n",
       "      <th>當事者屬-性-別名稱</th>\n",
       "      <th>當事者事故發生時年齡</th>\n",
       "      <th>車輛撞擊部位大類別名稱-最初</th>\n",
       "      <th>光線名稱</th>\n",
       "      <th>道路類別-第1當事者-名稱</th>\n",
       "      <th>速限-第1當事者</th>\n",
       "      <th>道路型態大類別名稱</th>\n",
       "      <th>...</th>\n",
       "      <th>肇因研判大類別名稱-個別</th>\n",
       "      <th>肇事逃逸類別名稱-是否肇逃</th>\n",
       "      <th>路面狀況-路面鋪裝名稱</th>\n",
       "      <th>路面狀況-路面缺陷名稱</th>\n",
       "      <th>道路障礙-障礙物名稱</th>\n",
       "      <th>道路障礙-視距品質名稱</th>\n",
       "      <th>道路障礙-視距名稱</th>\n",
       "      <th>號誌-號誌動作名稱</th>\n",
       "      <th>死亡</th>\n",
       "      <th>受傷</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.447747</td>\n",
       "      <td>-0.331183</td>\n",
       "      <td>0.509425</td>\n",
       "      <td>0.739901</td>\n",
       "      <td>-1.09744</td>\n",
       "      <td>-0.372169</td>\n",
       "      <td>0.146102</td>\n",
       "      <td>2.120706</td>\n",
       "      <td>-0.146069</td>\n",
       "      <td>1.210906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508523</td>\n",
       "      <td>-0.135001</td>\n",
       "      <td>-0.045604</td>\n",
       "      <td>-0.029347</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.118545</td>\n",
       "      <td>0.060048</td>\n",
       "      <td>0.837867</td>\n",
       "      <td>13.660843</td>\n",
       "      <td>-2.803204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.447747</td>\n",
       "      <td>-0.331183</td>\n",
       "      <td>0.509425</td>\n",
       "      <td>0.739901</td>\n",
       "      <td>0.67326</td>\n",
       "      <td>1.175119</td>\n",
       "      <td>1.465217</td>\n",
       "      <td>-0.251720</td>\n",
       "      <td>-0.146069</td>\n",
       "      <td>-0.814068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508523</td>\n",
       "      <td>-0.135001</td>\n",
       "      <td>-0.045604</td>\n",
       "      <td>-0.029347</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.118545</td>\n",
       "      <td>0.060048</td>\n",
       "      <td>-1.192531</td>\n",
       "      <td>13.660843</td>\n",
       "      <td>-0.620846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.201000</td>\n",
       "      <td>-0.331183</td>\n",
       "      <td>0.509425</td>\n",
       "      <td>0.739901</td>\n",
       "      <td>0.67326</td>\n",
       "      <td>-0.372169</td>\n",
       "      <td>-1.173013</td>\n",
       "      <td>2.911514</td>\n",
       "      <td>-0.146069</td>\n",
       "      <td>1.210906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508523</td>\n",
       "      <td>-0.135001</td>\n",
       "      <td>-0.045604</td>\n",
       "      <td>-0.029347</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.118545</td>\n",
       "      <td>0.060048</td>\n",
       "      <td>0.837867</td>\n",
       "      <td>13.660843</td>\n",
       "      <td>-2.803204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.447747</td>\n",
       "      <td>-0.331183</td>\n",
       "      <td>0.509425</td>\n",
       "      <td>0.739901</td>\n",
       "      <td>-0.21209</td>\n",
       "      <td>-0.372169</td>\n",
       "      <td>-1.173013</td>\n",
       "      <td>-0.251720</td>\n",
       "      <td>-0.146069</td>\n",
       "      <td>-0.814068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508523</td>\n",
       "      <td>-0.135001</td>\n",
       "      <td>-0.045604</td>\n",
       "      <td>-0.029347</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.118545</td>\n",
       "      <td>0.060048</td>\n",
       "      <td>-1.192531</td>\n",
       "      <td>13.660843</td>\n",
       "      <td>-0.620846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.201000</td>\n",
       "      <td>-0.331183</td>\n",
       "      <td>0.509425</td>\n",
       "      <td>0.739901</td>\n",
       "      <td>-1.09744</td>\n",
       "      <td>-0.372169</td>\n",
       "      <td>1.465217</td>\n",
       "      <td>2.120706</td>\n",
       "      <td>-0.146069</td>\n",
       "      <td>1.210906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.508523</td>\n",
       "      <td>-0.135001</td>\n",
       "      <td>-0.045604</td>\n",
       "      <td>-0.029347</td>\n",
       "      <td>0.001515</td>\n",
       "      <td>0.118545</td>\n",
       "      <td>0.060048</td>\n",
       "      <td>0.837867</td>\n",
       "      <td>13.660843</td>\n",
       "      <td>-2.803204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       天候名稱  路面狀況-路面狀態名稱  肇因研判大類別名稱-主要  當事者屬-性-別名稱  當事者事故發生時年齡  \\\n",
       "0 -0.447747    -0.331183      0.509425    0.739901    -1.09744   \n",
       "1 -0.447747    -0.331183      0.509425    0.739901     0.67326   \n",
       "2  1.201000    -0.331183      0.509425    0.739901     0.67326   \n",
       "3 -0.447747    -0.331183      0.509425    0.739901    -0.21209   \n",
       "4  1.201000    -0.331183      0.509425    0.739901    -1.09744   \n",
       "\n",
       "   車輛撞擊部位大類別名稱-最初      光線名稱  道路類別-第1當事者-名稱  速限-第1當事者  道路型態大類別名稱  ...  \\\n",
       "0       -0.372169  0.146102       2.120706 -0.146069   1.210906  ...   \n",
       "1        1.175119  1.465217      -0.251720 -0.146069  -0.814068  ...   \n",
       "2       -0.372169 -1.173013       2.911514 -0.146069   1.210906  ...   \n",
       "3       -0.372169 -1.173013      -0.251720 -0.146069  -0.814068  ...   \n",
       "4       -0.372169  1.465217       2.120706 -0.146069   1.210906  ...   \n",
       "\n",
       "   肇因研判大類別名稱-個別  肇事逃逸類別名稱-是否肇逃  路面狀況-路面鋪裝名稱  路面狀況-路面缺陷名稱  道路障礙-障礙物名稱  \\\n",
       "0      0.508523      -0.135001    -0.045604    -0.029347    0.001515   \n",
       "1      0.508523      -0.135001    -0.045604    -0.029347    0.001515   \n",
       "2      0.508523      -0.135001    -0.045604    -0.029347    0.001515   \n",
       "3      0.508523      -0.135001    -0.045604    -0.029347    0.001515   \n",
       "4      0.508523      -0.135001    -0.045604    -0.029347    0.001515   \n",
       "\n",
       "   道路障礙-視距品質名稱  道路障礙-視距名稱  號誌-號誌動作名稱         死亡        受傷  \n",
       "0     0.118545   0.060048   0.837867  13.660843 -2.803204  \n",
       "1     0.118545   0.060048  -1.192531  13.660843 -0.620846  \n",
       "2     0.118545   0.060048   0.837867  13.660843 -2.803204  \n",
       "3     0.118545   0.060048  -1.192531  13.660843 -0.620846  \n",
       "4     0.118545   0.060048   0.837867  13.660843 -2.803204  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(input_data, select_lst, sample = 592):\n",
    "    sample_data = input_data[input_data['當事者順位'] == 1].reset_index(drop=True, inplace=False)\n",
    "    # sample_data = sample_data[sample_data['發生月份'] < 3]\n",
    "    dataA = sample_data[select_lst]\n",
    "    \n",
    "    death_injury_data = split_death_injury(dataA['死亡受傷人數'])\n",
    "    dist_df = pd.concat([dataA, death_injury_data], axis=1)\n",
    "    dist_df.drop(columns=['死亡受傷人數'], inplace=True)\n",
    "    \n",
    "    return dist_df, sample_data\n",
    "\n",
    "# List of columns to select\n",
    "select_lst = [\n",
    "    '天候名稱', \n",
    "    '路面狀況-路面狀態名稱',\n",
    "    '肇因研判大類別名稱-主要', '當事者屬-性-別名稱', '當事者事故發生時年齡', \n",
    "    '車輛撞擊部位大類別名稱-最初',\n",
    "    '光線名稱',\n",
    "    '道路類別-第1當事者-名稱',\n",
    "    '速限-第1當事者', \n",
    "    '道路型態大類別名稱',\n",
    "    '事故位置大類別名稱', \n",
    "    '號誌-號誌種類名稱',\n",
    "    '車道劃分設施-分向設施大類別名稱', '車道劃分設施-分道設施-快車道或一般車道間名稱',\n",
    "    '車道劃分設施-分道設施-快慢車道間名稱', '車道劃分設施-分道設施-路面邊線名稱',\n",
    "    '事故類型及型態大類別名稱',\n",
    "    '死亡受傷人數',\n",
    "    '經度', '緯度',\n",
    "    '道路型態子類別名稱', '事故位置子類別名稱', '車道劃分設施-分向設施子類別名稱', '事故類型及型態子類別名稱', \n",
    "    '當事者行動狀態子類別名稱', '車輛撞擊部位子類別名稱-最初', '車輛撞擊部位子類別名稱-其他', '肇因研判子類別名稱-個別',\n",
    "    \n",
    "    '當事者區分-類別-大類別名稱-車種', '當事者區分-類別-子類別名稱-車種',\n",
    "    '保護裝備名稱', '行動電話或電腦或其他相類功能裝置名稱', '當事者行動狀態大類別名稱',\n",
    "    '車輛撞擊部位大類別名稱-其他', '肇因研判大類別名稱-個別', '肇事逃逸類別名稱-是否肇逃',\n",
    "    '路面狀況-路面鋪裝名稱', '路面狀況-路面缺陷名稱',\n",
    "    '道路障礙-障礙物名稱', '道路障礙-視距品質名稱', '道路障礙-視距名稱','號誌-號誌動作名稱',\n",
    "]\n",
    "\n",
    "dist_dfA1 = preprocess(dataA1, select_lst, sample = 592)\n",
    "dist_dfA2 = preprocess(dataA2, select_lst, sample = 11841) # 120420\n",
    "\n",
    "    \n",
    "rbind_data = pd.concat([dist_dfA1[0], dist_dfA2[0]], axis=0, ignore_index=True)\n",
    "\n",
    "rbind_data.loc[rbind_data['受傷'] > 1, '受傷'] = 2\n",
    "rbind_data['速限-第1當事者'] = rbind_data['速限-第1當事者'].apply(lambda x: 1 if x > 60 else 0)\n",
    "rbind_data = process_age(rbind_data)\n",
    "\n",
    "dist_df = process_data(rbind_data)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "full_dist = pd.DataFrame(scaler.fit_transform(dist_df), columns = dist_df.columns)\n",
    "X1 = full_dist.drop(['受傷', '死亡'], axis=1).to_numpy()\n",
    "\n",
    "full_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfac514e-f5cc-432b-8808-c6f3cbaf0b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CalculatedData/new1.pkl', 'rb') as f:\n",
    "    mapper_graph1 = pickle.load(f)\n",
    "\n",
    "mapper_plot1 = MapperLayoutInteractive(\n",
    "    mapper_graph1,\n",
    "    colors = dist_df[['天候名稱']].to_numpy(),\n",
    "    cmap = 'jet',\n",
    "    # agg = np.nanmean,\n",
    "    agg = most_frequent_nonan,\n",
    "    dim = 3,\n",
    "    iterations = 30,\n",
    "    seed = 5,\n",
    "    width = 800,\n",
    "    height = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f407b41-ee2b-495d-8e76-9a8aadc895f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_mean1 = mapper_plot1.plot()\n",
    "# fig_mean1.show(config={'scrollZoom': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ce56370-fce5-4b42-8f71-f63bf97e6c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>node</th>\n",
       "      <th>size</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>ids</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>0.010557</td>\n",
       "      <td>0.052523</td>\n",
       "      <td>-0.029602</td>\n",
       "      <td>[0, 34, 164, 210, 262, 317, 342, 386, 417, 503...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>192</td>\n",
       "      <td>0.007043</td>\n",
       "      <td>0.048798</td>\n",
       "      <td>-0.027370</td>\n",
       "      <td>[0, 12, 24, 47, 116, 164, 178, 182, 285, 317, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>0.007296</td>\n",
       "      <td>-0.070300</td>\n",
       "      <td>-0.093677</td>\n",
       "      <td>[1, 11643, 13481, 15825, 16714, 18757, 20676, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1723</td>\n",
       "      <td>298</td>\n",
       "      <td>-0.000934</td>\n",
       "      <td>-0.054598</td>\n",
       "      <td>-0.087617</td>\n",
       "      <td>[1, 78, 518, 1513, 1614, 1930, 1943, 1966, 315...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2306</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.005466</td>\n",
       "      <td>-0.049236</td>\n",
       "      <td>-0.082377</td>\n",
       "      <td>[1, 15825, 16714, 20676, 63665, 75722, 78455, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  node  size         x         y         z  \\\n",
       "0      0     0   214  0.010557  0.052523 -0.029602   \n",
       "1      0    38   192  0.007043  0.048798 -0.027370   \n",
       "2      0     2    24  0.007296 -0.070300 -0.093677   \n",
       "3      0  1723   298 -0.000934 -0.054598 -0.087617   \n",
       "4      0  2306     8 -0.005466 -0.049236 -0.082377   \n",
       "\n",
       "                                                 ids  label  \n",
       "0  [0, 34, 164, 210, 262, 317, 342, 386, 417, 503...      0  \n",
       "1  [0, 12, 24, 47, 116, 164, 178, 182, 285, 317, ...      0  \n",
       "2  [1, 11643, 13481, 15825, 16714, 18757, 20676, ...      1  \n",
       "3  [1, 78, 518, 1513, 1614, 1930, 1943, 1966, 315...      1  \n",
       "4  [1, 15825, 16714, 20676, 63665, 75722, 78455, ...      1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = vars(mapper_plot1._MapperLayoutInteractive__fig)['_data_objs'][1]['x']\n",
    "y = vars(mapper_plot1._MapperLayoutInteractive__fig)['_data_objs'][1]['y']\n",
    "z = vars(mapper_plot1._MapperLayoutInteractive__fig)['_data_objs'][1]['z']\n",
    "\n",
    "threeDimData = pd.DataFrame({'x': x, 'y': y, 'z': z})\n",
    "\n",
    "import re\n",
    "data_tuple = vars(mapper_plot1._MapperLayoutInteractive__fig)['_data_objs'][1]['text']\n",
    "\n",
    "data = []\n",
    "for item in data_tuple:\n",
    "    color = int(re.search(r'color: (-?\\d+)', item).group(1))\n",
    "    node = int(re.search(r'node: (\\d+)', item).group(1))\n",
    "    size = int(re.search(r'size: (\\d+)', item).group(1))\n",
    "    data.append({'color': color, 'node': node, 'size': size})\n",
    "component_info = pd.DataFrame(data)\n",
    "\n",
    "full_info = pd.concat([component_info, threeDimData], axis=1)\n",
    "\n",
    "mp_content_origin = vars(mapper_plot1._MapperLayoutInteractive__graph)['_node']\n",
    "\n",
    "mp_content = pd.DataFrame.from_dict(mp_content_origin, orient='index')\n",
    "mp_content.reset_index(inplace=True)\n",
    "mp_content.rename(columns={'index': 'node'}, inplace=True)\n",
    "\n",
    "full_info = pd.merge(full_info, mp_content, on=['node', 'size'], how='inner')\n",
    "\n",
    "# calinski_data = get_calinski_from_db(full_info, 0.021)\n",
    "calinski_data = get_calinski_from_db(full_info, 0.015)\n",
    "\n",
    "full_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64fe05b8-b339-45eb-a527-5d585a23b608",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = calinski_data[3]\n",
    "db = calinski_data[2]\n",
    "n_clusters_ = calinski_data[4]\n",
    "\n",
    "unique_labels = set(labels)\n",
    "core_samples_mask = np.zeros_like(labels, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "\n",
    "def matplotlib_to_plotly(cmap, alpha=1):\n",
    "    \"\"\"rgba\"\"\"\n",
    "    return f'rgba({int(cmap[0]*200)}, {int(cmap[1]*200)}, {int(cmap[2]*200)}, {alpha})'\n",
    "\n",
    "# colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]  \n",
    "colors = [matplotlib_to_plotly(plt.cm.Spectral(each), alpha=0.8) for each in np.linspace(0, 1, len(unique_labels))]\n",
    "# fig = go.Figure()\n",
    "\n",
    "# for k, col in zip(unique_labels, colors):\n",
    "#     if k == -1:\n",
    "#         # col = 'rgba(0,0,0,0)'\n",
    "#         col = 'rgba(0,0,0,0)'\n",
    "\n",
    "#     class_member_mask = labels == k\n",
    "\n",
    "#     core_samples = full_info.iloc[:, 3:6][class_member_mask & core_samples_mask]\n",
    "#     fig.add_trace(go.Scatter3d(\n",
    "#         x=core_samples.iloc[:, 0],\n",
    "#         y=core_samples.iloc[:, 1],\n",
    "#         z=core_samples.iloc[:, 2],\n",
    "#         mode='markers',\n",
    "#         marker=dict(\n",
    "#             size=6,\n",
    "#             color=col,\n",
    "#             opacity=0.8\n",
    "#         ),\n",
    "#         name=f'Cluster {k} Core'\n",
    "#     ))\n",
    "\n",
    "#     non_core_samples = full_info.iloc[:, 3:6][class_member_mask & ~core_samples_mask]\n",
    "#     fig.add_trace(go.Scatter3d(\n",
    "#         x=non_core_samples.iloc[:, 0],\n",
    "#         y=non_core_samples.iloc[:, 1],\n",
    "#         z=non_core_samples.iloc[:, 2],\n",
    "#         mode='markers',\n",
    "#         marker=dict(\n",
    "#             size=6,\n",
    "#             color=col,\n",
    "#             opacity=0.5\n",
    "#         ),\n",
    "#         name=f'Cluster {k} Non-Core'\n",
    "#     ))\n",
    "\n",
    "# fig.update_layout(\n",
    "#     title=f\"Estimated number of clusters: {n_clusters_}\",\n",
    "#     margin=dict(l=0, r=0, b=0, t=0)\n",
    "# )\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21b7e3c0-9498-41b1-8101-8615298b8b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1 -1  2  3  4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7137"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_0 = full_info[full_info['label'] == 0]\n",
    "label_1 = full_info[full_info['label'] == 1]\n",
    "label_2 = full_info[full_info['label'] == 2]\n",
    "label_3 = full_info[full_info['label'] == 3]\n",
    "label_out = full_info[(full_info['label'] != 0) & (full_info['label'] != 1) & (full_info['label'] != 2) & (full_info['label'] != 3)]\n",
    "\n",
    "count_0 = get_count_dict(label_0)\n",
    "count_1 = get_count_dict(label_1)\n",
    "count_2 = get_count_dict(label_2)\n",
    "count_3 = get_count_dict(label_3)\n",
    "count_out = get_count_dict(label_out)\n",
    "\n",
    "print(full_info['label'].unique())\n",
    "\n",
    "len(count_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a643f6d-2b0b-41f0-a277-9fe45288184a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 處理函數，確保每次操作前後索引的一致性和唯一性\n",
    "def drop_keys(dataframe, keys_list):\n",
    "    for keys in keys_list:\n",
    "        if keys:\n",
    "            dataframe.drop(keys, errors='ignore', inplace=True)\n",
    "\n",
    "# 各個集合的初始加載\n",
    "full_0 = rbind_data.loc[count_0.keys()].copy()\n",
    "full_1 = rbind_data.loc[count_1.keys()].copy()\n",
    "full_2 = rbind_data.loc[count_2.keys()].copy()\n",
    "full_3 = rbind_data.loc[count_3.keys()].copy()\n",
    "full_out = rbind_data.loc[count_out.keys()].copy()\n",
    "\n",
    "lst01 = list(count_0.keys() & count_1.keys()) \n",
    "lst02 = list(count_0.keys() & count_2.keys()) \n",
    "lst03 = list(count_0.keys() & count_3.keys()) \n",
    "lst12 = list(count_1.keys() & count_2.keys()) \n",
    "lst13 = list(count_1.keys() & count_3.keys())\n",
    "lst23 = list(count_2.keys() & count_3.keys()) \n",
    "lsto0 = list(count_out.keys() & count_0.keys()) \n",
    "lsto1 = list(count_out.keys() & count_1.keys()) \n",
    "lsto2 = list(count_out.keys() & count_2.keys()) \n",
    "lsto3 = list(count_out.keys() & count_3.keys())\n",
    "\n",
    "full_01 = full_0.loc[lst01]\n",
    "full_02 = full_0.loc[lst02]\n",
    "full_03 = full_0.loc[lst03]\n",
    "full_12 = full_1.loc[lst12]\n",
    "full_13 = full_1.loc[lst13]\n",
    "full_23 = full_2.loc[lst23]\n",
    "\n",
    "# 合併重複數據集並去重\n",
    "full_combine = pd.concat([full_01, full_02, full_03, full_12, full_13, full_23, full_out], axis=0)\n",
    "full_combine.reset_index(inplace=True)\n",
    "full_combine.drop_duplicates(subset='index', keep='first', inplace=True)\n",
    "full_combine.drop('index', axis=1, inplace=True)\n",
    "\n",
    "# 移除每個數據集中的重複鍵\n",
    "drop_keys(full_0, [lst01, lst02, lst03, lsto0])\n",
    "drop_keys(full_1, [lst01, lst12, lst13, lsto1])\n",
    "drop_keys(full_2, [lst02, lst12, lst23, lsto2])\n",
    "drop_keys(full_3, [lst03, lst13, lst23, lsto3]) \n",
    "\n",
    "full_combine.shape[0] + full_0.shape[0] + full_1.shape[0] == rbind_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e9617c6-d263-489e-b0e8-75f98fc77dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116859"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_combine.shape[0] + full_0.shape[0] + full_1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94f5136a-01e1-4245-bb1a-9c1f69399d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    5743\n",
      "2    2748\n",
      "dtype: int64\n",
      "1    34717\n",
      "2    12022\n",
      "dtype: int64\n",
      "1    42612\n",
      "2    19017\n",
      "dtype: int64\n",
      "1    1124\n",
      "2     452\n",
      "dtype: int64\n",
      "1    1458\n",
      "2    1119\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "lst_logit = [\n",
    "    '路面狀況-路面狀態名稱',\n",
    "    # '肇因研判大類別名稱-主要', # 降低預測值\n",
    "    '當事者屬-性-別名稱', '當事者事故發生時年齡', \n",
    "    '車輛撞擊部位大類別名稱-最初',\n",
    "    '光線名稱',\n",
    "    '道路類別-第1當事者-名稱',\n",
    "    '速限-第1當事者',\n",
    "    '道路型態大類別名稱',\n",
    "    '事故位置大類別名稱', \n",
    "    '號誌-號誌種類名稱',\n",
    "    '車道劃分設施-分向設施大類別名稱', '車道劃分設施-分道設施-快車道或一般車道間名稱',\n",
    "    '車道劃分設施-分道設施-快慢車道間名稱', '車道劃分設施-分道設施-路面邊線名稱',\n",
    "    '事故類型及型態大類別名稱',\n",
    "    '事故位置子類別名稱', '事故類型及型態子類別名稱', \n",
    "    '當事者行動狀態子類別名稱', '車輛撞擊部位子類別名稱-最初', '肇因研判子類別名稱-個別',\n",
    "    # '當事者區分-類別-大類別名稱-車種', \n",
    "    '當事者區分-類別-子類別名稱-車種',\n",
    "    '保護裝備名稱', '行動電話或電腦或其他相類功能裝置名稱', '當事者行動狀態大類別名稱',\n",
    "    '車輛撞擊部位大類別名稱-其他', '肇因研判大類別名稱-個別', '肇事逃逸類別名稱-是否肇逃',\n",
    "    '號誌-號誌動作名稱',\n",
    "    # '路面狀況-路面鋪裝名稱', '道路障礙-視距名稱', '車道劃分設施-分向設施子類別名稱', '車道劃分設施-分道設施-快慢車道間名稱', '車輛撞擊部位大類別名稱-其他',\n",
    "    # '道路障礙-障礙物名稱', '道路型態子類別名稱', '路面狀況-路面缺陷名稱', '天候名稱', '車輛撞擊部位子類別名稱-其他', \n",
    "]\n",
    "def get_clusterN_logit(cluster_data, lst):\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    c0_for_lm = process_data(cluster_data)\n",
    "    c0_for_lm_X = pd.DataFrame(scaler.fit_transform(c0_for_lm), columns = c0_for_lm.columns)\n",
    "    # c0_for_lm_y = cluster_data['受傷']\n",
    "    # c0_for_lm_y = cluster_data.apply(lambda row: 1 if row['死亡'] != 0 else 0, axis=1)\n",
    "    c0_for_lm_y = cluster_data.apply(lambda row: 2 if row['死亡'] != 0 else (2 if row['受傷'] >= 2 else 1), axis=1)\n",
    "    # c0_for_lm_y = cluster_data.apply(lambda row: '非常嚴重' if row['死亡'] > 0 or row['受傷'] > 2 else ('嚴重' if row['受傷'] > 1 else '一般'), axis=1)\n",
    "    c0_for_lm_X = c0_for_lm_X[lst]\n",
    "    \n",
    "    return c0_for_lm_X, c0_for_lm_y\n",
    "\n",
    "full_combine_X,  full_combine_y = get_clusterN_logit(full_combine, lst_logit)\n",
    "full_0_X, full_0_y = get_clusterN_logit(full_0, lst_logit)\n",
    "full_1_X, full_1_y = get_clusterN_logit(full_1, lst_logit)\n",
    "full_2_X, full_2_y = get_clusterN_logit(full_2, lst_logit)\n",
    "full_3_X, full_3_y = get_clusterN_logit(full_3, lst_logit)\n",
    "\n",
    "print(full_combine_y.value_counts())\n",
    "print(full_0_y.value_counts())\n",
    "print(full_1_y.value_counts())\n",
    "print(full_2_y.value_counts())\n",
    "print(full_3_y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76506c23-f882-48b5-8793-61f2c151b6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46739, 28)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_0_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3060b9e9-dddd-4df0-84af-0f1eb65a7ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6327251324308417 0.6220581942661532 0.6510627940937855 0.75 0.6763565891472868\n",
      "352.39549112319946\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "matrix_combine, score_combine, cm_combine = logistic_cm_gridsearch(full_combine_X,  full_combine_y)\n",
    "matrix_0, score_0, cm_0 = logistic_cm_gridsearch(full_0_X, full_0_y)\n",
    "matrix_1, score_1, cm_1 = logistic_cm_gridsearch(full_1_X, full_1_y)\n",
    "matrix_2, score_2, cm_2 = logistic_cm_gridsearch(full_2_X, full_2_y)\n",
    "matrix_3, score_3, cm_3 = logistic_cm_gridsearch(full_3_X, full_3_y)\n",
    "print(score_combine, score_0, score_1, score_2, score_3)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6d8934c-4d65-42cc-9f81-aa1ff3399b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64\n"
     ]
    }
   ],
   "source": [
    "de = full_combine_X.shape[0] + full_0_X.shape[0] + full_1_X.shape[0] + full_2_X.shape[0] + full_3_X.shape[0]\n",
    "logit_avg_score = (full_combine_X.shape[0]/de)*score_combine + (full_0_X.shape[0]/de)*score_0 + (full_1_X.shape[0]/de)*score_1 + (full_2_X.shape[0]/de)*score_2 + (full_3_X.shape[0]/de)*score_3\n",
    "print(round(logit_avg_score, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6b14083-9b9d-4edd-bbc5-b112498b7928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(confusion_matrix):\n",
    "    TP = confusion_matrix[1, 1]\n",
    "    TN = confusion_matrix[0, 0]\n",
    "    FP = confusion_matrix[0, 1]\n",
    "    FN = confusion_matrix[1, 0]\n",
    "    \n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return accuracy, precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "161fdc3e-3891-4c81-8d60-6f3d75c3ce14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>LR Mapper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.640405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.430715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.753890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1 Score</td>\n",
       "      <td>0.548220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric  LR Mapper\n",
       "0   Accuracy   0.640405\n",
       "1  Precision   0.430715\n",
       "2     Recall   0.753890\n",
       "3   F1 Score   0.548220"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_metrics = calculate_metrics(cm_combine + cm_0 + cm_1 + cm_2 + cm_3)\n",
    "logistic_metrics\n",
    "data = {\n",
    "    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"],\n",
    "    \"LR Mapper\": logistic_metrics,\n",
    "}\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b429866a-ce8b-428a-9cc6-b7736f9767e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangqiqian/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n",
      "/Users/wangqiqian/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning:\n",
      "\n",
      "Liblinear failed to converge, increase the number of iterations.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "svc_matrix_com, svc_score_com, svc_cm_combine = svc_cm_with_grid_search(full_combine_X, full_combine_y)\n",
    "svc_matrix_0, svc_score_0, svc_cm_0 = svc_cm_with_grid_search(full_0_X, full_0_y)\n",
    "svc_matrix_1, svc_score_1, svc_cm_1 = svc_cm_with_grid_search(full_1_X, full_1_y)\n",
    "print(svc_score_com, svc_score_0, svc_score_1)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(elapsed_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
