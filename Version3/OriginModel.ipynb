{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'C:\\\\System\\\\Library\\\\Fonts\\\\PingFang.ttc'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import prince\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.cm import get_cmap\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "# 獲取當前工作目錄\n",
    "current_dir = os.getcwd()\n",
    "version3_path = os.path.join(current_dir, \"TrafficTDApython\", \"Version3\", \"tdamapper\", \"core_old.py\")\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from tdamapper.core_old import MapperAlgorithm\n",
    "from tdamapper.cover import CubicalCover\n",
    "from tdamapper.clustering import FailSafeClustering\n",
    "from tdamapper.plot import MapperLayoutInteractive, MapperPlot\n",
    "\n",
    "from models import *\n",
    "from utils_v3 import *\n",
    "from plots import *\n",
    "\n",
    "try:\n",
    "    myfont = FontProperties(fname=r\"/System/Library/Fonts/PingFang.ttc\")\n",
    "    sns.set(style=\"whitegrid\", font=myfont.get_name())\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"../Data/NPA_TMA2_1.csv\", low_memory=False)[:-2]\n",
    "data2 = pd.read_csv(\"../Data/NPA_TMA2_2.csv\", low_memory=False)[:-2]\n",
    "data3 = pd.read_csv(\"../Data/NPA_TMA2_3.csv\", low_memory=False)[:-2]\n",
    "data4 = pd.read_csv(\"../Data/NPA_TMA2_4_new.csv\", low_memory=False)[:-2]\n",
    "data5 = pd.read_csv(\"../Data/NPA_TMA2_5.csv\", low_memory=False)[:-2]\n",
    "data6 = pd.read_csv(\"../Data/NPA_TMA2_6_new.csv\", low_memory=False)[:-2]\n",
    "data7 = pd.read_csv(\"../Data/NPA_TMA2_7.csv\", low_memory=False)[:-2]\n",
    "data8 = pd.read_csv(\"../Data/NPA_TMA2_8.csv\", low_memory=False)[:-2]\n",
    "data9 = pd.read_csv(\"../Data/NPA_TMA2_9.csv\", low_memory=False)[:-2]\n",
    "data10 = pd.read_csv(\"../Data/NPA_TMA2_10.csv\", low_memory=False)[:-2]\n",
    "\n",
    "dataA2 = pd.concat([data1, data2, data3, data4, data5, data6, data7, data8, data9, data10], ignore_index=True)\n",
    "# dataA2 = pd.concat([data1, data2, data3, data4, data5], ignore_index=True)\n",
    "\n",
    "dataA1 = pd.read_csv(\"../Data/NPA_TMA1_V3.csv\")[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA2 = pd.read_csv(\"../Version3/Data/A2.csv\", low_memory=False)\n",
    "dataA1 = pd.read_csv(\"../Version3/Data/A1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# car data\n",
    "car_0 = pd.read_csv(os.path.join(current_dir, \"Data/CarData/full_0.csv\"), encoding='utf-8')\n",
    "car_1 = pd.read_csv(os.path.join(current_dir, \"Data/CarData/full_1.csv\"), encoding='utf-8')\n",
    "car_2 = pd.read_csv(os.path.join(current_dir, \"Data/CarData/full_2.csv\"), encoding='utf-8')\n",
    "car_3 = pd.read_csv(os.path.join(current_dir, \"Data/CarData/full_3.csv\"), encoding='utf-8')\n",
    "car_21 = pd.read_csv(os.path.join(current_dir, \"Data/CarData/full_21.csv\"), encoding='utf-8')\n",
    "car_out = pd.read_csv(os.path.join(current_dir, \"Data/CarData/full_out.csv\"), encoding='utf-8')\n",
    "# pass data\n",
    "pass_data = pd.read_csv(os.path.join(current_dir, \"Data/PassData/full.csv\"), encoding='utf-8')\n",
    "# full data\n",
    "full_car = pd.concat([car_0, car_1, car_2, car_3, car_21, car_out], axis=0)\n",
    "full_car['當事者行動狀態大類別名稱'] = 'car'\n",
    "passforfull = pass_data.copy()\n",
    "passforfull['當事者行動狀態大類別名稱'] = 'pass'\n",
    "full_data = pd.concat([full_car, passforfull], axis=0)\n",
    "car_out = pd.concat([car_out, car_21], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_lst = [\n",
    "    '天候名稱', '光線名稱', \n",
    "    '道路類別-第1當事者-名稱', '速限-第1當事者', \n",
    "    '路面狀況-路面鋪裝名稱', '路面狀況-路面狀態名稱', '路面狀況-路面缺陷名稱',\n",
    "    '道路障礙-障礙物名稱', '道路障礙-視距品質名稱', '道路障礙-視距名稱',\n",
    "    '號誌-號誌種類名稱', '號誌-號誌動作名稱',\n",
    "    '車道劃分設施-分道設施-快車道或一般車道間名稱', '車道劃分設施-分道設施-快慢車道間名稱', '車道劃分設施-分道設施-路面邊線名稱',\n",
    "    '當事者屬-性-別名稱', '當事者事故發生時年齡',\n",
    "    '保護裝備名稱', '行動電話或電腦或其他相類功能裝置名稱',\n",
    "    '肇事逃逸類別名稱-是否肇逃',\n",
    "\n",
    "    # 大類別\n",
    "    '道路型態大類別名稱', '事故位置大類別名稱',\n",
    "    '車道劃分設施-分向設施大類別名稱',\n",
    "    '事故類型及型態大類別名稱', '當事者區分-類別-大類別名稱-車種',\n",
    "    '車輛撞擊部位大類別名稱-最初', '車輛撞擊部位大類別名稱-其他',\n",
    "\n",
    "    # 兩個欄位只有兩個觀察值不同\n",
    "    '肇因研判大類別名稱-主要',\n",
    "    # '肇因研判大類別名稱-個別',\n",
    "    '受傷', '死亡'\n",
    "]\n",
    "\n",
    "# select data\n",
    "car_0 = car_0[select_lst]\n",
    "car_1 = car_1[select_lst]\n",
    "car_2 = car_2[select_lst]\n",
    "car_3 = car_3[select_lst]\n",
    "car_out = car_out[select_lst]\n",
    "pass_data = pass_data[select_lst]\n",
    "select_lst.append('當事者行動狀態大類別名稱')\n",
    "full_data = full_data[select_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummy\n",
    "car_0 = pd.get_dummies(car_0)\n",
    "car_1 = pd.get_dummies(car_1)\n",
    "car_2 = pd.get_dummies(car_2)\n",
    "car_3 = pd.get_dummies(car_3)\n",
    "car_out = pd.get_dummies(car_out)\n",
    "pass_data = pd.get_dummies(pass_data)\n",
    "full_data = pd.get_dummies(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2910\n",
      "1      10\n",
      "Name: 死亡, dtype: int64\n",
      "0    30072\n",
      "1      116\n",
      "2        3\n",
      "3        1\n",
      "Name: 死亡, dtype: int64\n",
      "0    51765\n",
      "1      214\n",
      "2        2\n",
      "Name: 死亡, dtype: int64\n",
      "0    4905\n",
      "1      17\n",
      "Name: 死亡, dtype: int64\n",
      "0    4336\n",
      "1      44\n",
      "2       4\n",
      "3       2\n",
      "Name: 死亡, dtype: int64\n",
      "0    3038\n",
      "1      57\n",
      "2       1\n",
      "Name: 死亡, dtype: int64\n",
      "0    97026\n",
      "1      458\n",
      "2       10\n",
      "3        3\n",
      "Name: 死亡, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(car_0['死亡'].value_counts())\n",
    "print(car_1['死亡'].value_counts())\n",
    "print(car_2['死亡'].value_counts())\n",
    "print(car_3['死亡'].value_counts())\n",
    "print(car_out['死亡'].value_counts())\n",
    "print(pass_data['死亡'].value_counts())\n",
    "print(full_data['死亡'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data(input_data):\n",
    "    input_data['y'] = input_data['死亡'].apply(lambda x: 1 if x >= 1 else 0)\n",
    "    \n",
    "    new_input_data = input_data.drop(columns=['受傷', '死亡'], inplace=False)\n",
    "    \n",
    "    X = new_input_data.drop(columns=['y'])\n",
    "    y = new_input_data['y']\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_0_X, car_0_y = get_train_test_data(car_0)\n",
    "car_1_X, car_1_y = get_train_test_data(car_1)\n",
    "car_2_X, car_2_y = get_train_test_data(car_2)\n",
    "car_3_X, car_3_y = get_train_test_data(car_3)\n",
    "car_out_X, car_out_y = get_train_test_data(car_out)\n",
    "pass_data_X, pass_data_y = get_train_test_data(pass_data)\n",
    "full_data_X, full_data_y = get_train_test_data(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found by GridSearchCV: {'C': 1, 'penalty': 'l2'}\n",
      "Best parameters found by GridSearchCV: {'C': 1, 'penalty': 'l2'}\n",
      "Best parameters found by GridSearchCV: {'C': 1, 'penalty': 'l2'}\n",
      "Best parameters found by GridSearchCV: {'C': 1, 'penalty': 'l2'}\n",
      "Best parameters found by GridSearchCV: {'C': 1, 'penalty': 'l2'}\n",
      "Best parameters found by GridSearchCV: {'C': 1, 'penalty': 'l2'}\n",
      "Best parameters found by GridSearchCV: {'C': 1, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "car0_logistic_metric, car0_logistic_score, car0_logistic_cm, car0_y_resampled_test, car0_decision_scores = logistic_cm_gridsearch(car_0_X, car_0_y, threshold=5)\n",
    "car1_logistic_metric, car1_logistic_score, car1_logistic_cm, car1_y_resampled_test, car1_decision_scores = logistic_cm_gridsearch(car_1_X, car_1_y, threshold=5)\n",
    "car2_logistic_metric, car2_logistic_score, car2_logistic_cm, car2_y_resampled_test, car2_decision_scores = logistic_cm_gridsearch(car_2_X, car_2_y, threshold=5)\n",
    "car3_logistic_metric, car3_logistic_score, car3_logistic_cm, car3_y_resampled_test, car3_decision_scores = logistic_cm_gridsearch(car_3_X, car_3_y, threshold=5)\n",
    "carout_logistic_metric, carout_logistic_score, carout_logistic_cm, carout_y_resampled_test, carout_decision_scores = logistic_cm_gridsearch(car_out_X, car_out_y, threshold=5)\n",
    "pass_logistic_metric, pass_logistic_score, pass_logistic_cm, pass_y_resampled_test, pass_decision_scores = logistic_cm_gridsearch(pass_data_X, pass_data_y, threshold=5)\n",
    "full_logistic_metric, full_logistic_score, full_logistic_cm, full_y_resampled_test, full_decision_scores = logistic_cm_gridsearch(full_data_X, full_data_y, threshold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(resampled_test, decision_scores, threshold=0.5):\n",
    "    \n",
    "    y_pred = (decision_scores >= threshold).astype(int)\n",
    "\n",
    "    conf_matrix = confusion_matrix(resampled_test, y_pred)\n",
    "    acc = accuracy_score(resampled_test, y_pred)\n",
    "    \n",
    "    return conf_matrix, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2, 2],\n",
       "        [2, 2]], dtype=int64),\n",
       " 0.5)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(car0_y_resampled_test, car0_decision_scores, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save car0_y_resampled_test, car0_decision_scores\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'score': car0_decision_scores,\n",
    "    'y': car0_y_resampled_test\n",
    "})\n",
    "metrics_df.to_csv(\"./ModelPerformance/car0.csv\", index=False)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'score': car1_decision_scores,\n",
    "    'y': car1_y_resampled_test\n",
    "})\n",
    "metrics_df.to_csv(\"./ModelPerformance/car1.csv\", index=False)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'score': car2_decision_scores,\n",
    "    'y': car2_y_resampled_test\n",
    "})\n",
    "metrics_df.to_csv(\"./ModelPerformance/car2.csv\", index=False)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'score': car3_decision_scores,\n",
    "    'y': car3_y_resampled_test\n",
    "})\n",
    "metrics_df.to_csv(\"./ModelPerformance/car3.csv\", index=False)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'score': carout_decision_scores,\n",
    "    'y': carout_y_resampled_test\n",
    "})\n",
    "metrics_df.to_csv(\"./ModelPerformance/carout.csv\", index=False)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'score': pass_decision_scores,\n",
    "    'y': pass_y_resampled_test\n",
    "})\n",
    "metrics_df.to_csv(\"./ModelPerformance/pass.csv\", index=False)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'score': full_decision_scores,\n",
    "    'y': full_y_resampled_test\n",
    "})\n",
    "metrics_df.to_csv(\"./ModelPerformance/full.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00739187, 0.01219601, 0.0215474 , 0.02724232, 0.04964881,\n",
       "       0.00894119, 0.02023626, 0.01526169])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car0_decision_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
