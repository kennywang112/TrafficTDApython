{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 該檔案將駕駛的overlap和outlier區分，但是由於overlap資料量太少，無法使用smote生成新資料點"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'C:\\\\System\\\\Library\\\\Fonts\\\\PingFang.ttc'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.cm import get_cmap\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "# 獲取當前工作目錄\n",
    "current_dir = os.getcwd()\n",
    "version3_path = os.path.join(current_dir, \"TrafficTDApython\", \"Version3\", \"tdamapper\", \"core_old.py\")\n",
    "\n",
    "from utils.models import *\n",
    "from utils.utils_v3 import *\n",
    "from utils.plots import *\n",
    "\n",
    "try:\n",
    "    myfont = FontProperties(fname=r\"/System/Library/Fonts/PingFang.ttc\")\n",
    "    sns.set(style=\"whitegrid\", font=myfont.get_name())\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "dataA2 = pd.read_csv(\"./Data/A2.csv\", low_memory=False)\n",
    "dataA1 = pd.read_csv(\"./Data/A1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# car data\n",
    "car_data = pd.read_csv(os.path.join(current_dir, \"Data/CarDataNew/full_1.csv\"), encoding='utf-8')\n",
    "motor_data = pd.read_csv(os.path.join(current_dir, \"Data/CarDataNew/full_2.csv\"), encoding='utf-8')\n",
    "car_overlap_data = pd.read_csv(os.path.join(current_dir, \"Data/CarDataNew/full_out.csv\"), encoding='utf-8')\n",
    "car_outlier_data = pd.read_csv(os.path.join(current_dir, \"Data/CarDataNew/overlap_data.csv\"), encoding='utf-8')\n",
    "# pass data\n",
    "pass_data0 = pd.read_csv(os.path.join(current_dir, \"Data/PassData/full_0.csv\"), encoding='utf-8')\n",
    "pass_data1 = pd.read_csv(os.path.join(current_dir, \"Data/PassData/full_1.csv\"), encoding='utf-8')\n",
    "pass_data2 = pd.read_csv(os.path.join(current_dir, \"Data/PassData/full_2.csv\"), encoding='utf-8')\n",
    "pass_data3 = pd.read_csv(os.path.join(current_dir, \"Data/PassData/full_3.csv\"), encoding='utf-8')\n",
    "pass_data_overlap = pd.read_csv(os.path.join(current_dir, \"Data/PassData/overlap_data.csv\"), encoding='utf-8')\n",
    "pass_data_out = pd.read_csv(os.path.join(current_dir, \"Data/PassData/full_out.csv\"), encoding='utf-8')\n",
    "\n",
    "# 合併模型輸入資料，總共有 5 種資料\n",
    "pass_data = pd.concat([pass_data0, pass_data1, pass_data2, pass_data3, pass_data_overlap], axis=0)\n",
    "\n",
    "# 補回當事者行動狀態大類別名稱\n",
    "car_data['當事者行動狀態大類別名稱'] = '車的狀態'\n",
    "motor_data['當事者行動狀態大類別名稱'] = '車的狀態'\n",
    "car_overlap_data['當事者行動狀態大類別名稱'] = '車的狀態'\n",
    "car_outlier_data['當事者行動狀態大類別名稱'] = '車的狀態'\n",
    "pass_data['當事者行動狀態大類別名稱'] = '人的狀態'\n",
    "pass_data_out['當事者行動狀態大類別名稱'] = '人的狀態'\n",
    "\n",
    "full_data = pd.concat([car_data, motor_data, car_overlap_data, car_outlier_data, pass_data, pass_data_out], axis=0)\n",
    "car_data.drop(columns=['當事者行動狀態大類別名稱'], inplace=True)\n",
    "motor_data.drop(columns=['當事者行動狀態大類別名稱'], inplace=True)\n",
    "car_overlap_data.drop(columns=['當事者行動狀態大類別名稱'], inplace=True)\n",
    "car_outlier_data.drop(columns=['當事者行動狀態大類別名稱'], inplace=True)\n",
    "pass_data.drop(columns=['當事者行動狀態大類別名稱'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_lst = [\n",
    "    '天候名稱', '光線名稱', \n",
    "    '道路類別-第1當事者-名稱', '速限-第1當事者', \n",
    "    \n",
    "    # 路面狀況\n",
    "    '路面狀況-路面鋪裝名稱', '路面狀況-路面狀態名稱', '路面狀況-路面缺陷名稱',\n",
    "    '道路障礙-障礙物名稱', '道路障礙-視距品質名稱', '道路障礙-視距名稱',\n",
    "    # 號誌\n",
    "    '號誌-號誌種類名稱', '號誌-號誌動作名稱',\n",
    "    # 車道\n",
    "    '車道劃分設施-分道設施-快車道或一般車道間名稱', '車道劃分設施-分道設施-快慢車道間名稱', '車道劃分設施-分道設施-路面邊線名稱',\n",
    "    # 當事人\n",
    "    '當事者屬-性-別名稱', '當事者事故發生時年齡',\n",
    "    '保護裝備名稱', '行動電話或電腦或其他相類功能裝置名稱',\n",
    "    '肇事逃逸類別名稱-是否肇逃',\n",
    "\n",
    "    # 大類別\n",
    "    '道路型態大類別名稱', '事故位置大類別名稱',\n",
    "    '車道劃分設施-分向設施大類別名稱',\n",
    "    '事故類型及型態大類別名稱', '當事者區分-類別-大類別名稱-車種',\n",
    "    '車輛撞擊部位大類別名稱-最初', \n",
    "    '車輛撞擊部位大類別名稱-其他',\n",
    "\n",
    "    # 兩個欄位只有兩個觀察值不同\n",
    "    '肇因研判大類別名稱-主要',\n",
    "    # '肇因研判大類別名稱-個別',\n",
    "    '受傷', '死亡',\n",
    "    \n",
    "    # 子類別\n",
    "    # '道路型態子類別名稱', '事故位置子類別名稱', '事故類型及型態子類別名稱', '肇因研判子類別名稱-主要',\n",
    "    # '當事者區分-類別-子類別名稱-車種', '當事者行動狀態子類別名稱', '車輛撞擊部位子類別名稱-最初',\n",
    "    # '車輛撞擊部位子類別名稱-其他', '肇因研判子類別名稱-個別'\n",
    "]\n",
    "\n",
    "# select data\n",
    "full_data = full_data[select_lst]\n",
    "car_data = car_data[select_lst]\n",
    "motor_data = motor_data[select_lst]\n",
    "car_overlap_data = car_overlap_data[select_lst]\n",
    "car_outlier_data = car_outlier_data[select_lst]\n",
    "select_lst.remove('車輛撞擊部位大類別名稱-最初')\n",
    "select_lst.remove('行動電話或電腦或其他相類功能裝置名稱')\n",
    "select_lst.remove('當事者區分-類別-大類別名稱-車種')\n",
    "pass_data = pass_data[select_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = pd.get_dummies(full_data)\n",
    "car_data = pd.get_dummies(car_data)\n",
    "motor_data = pd.get_dummies(motor_data)\n",
    "car_overlap_data = pd.get_dummies(car_overlap_data)\n",
    "car_outlier_data = pd.get_dummies(car_outlier_data)\n",
    "pass_data = pd.get_dummies(pass_data)\n",
    "pass_data_outlier = pd.get_dummies(pass_data_out)\n",
    "\n",
    "full_data_X, full_data_y = get_train_test_data(full_data)\n",
    "car_data_X, car_data_y = get_train_test_data(car_data)\n",
    "motor_data_X, motor_data_y = get_train_test_data(motor_data)\n",
    "car_overlap_data_X, car_overlap_data_y = get_train_test_data(car_overlap_data)\n",
    "car_outlier_data_X, car_outlier_data_y = get_train_test_data(car_outlier_data)\n",
    "pass_data_X, pass_data_y = get_train_test_data(pass_data)\n",
    "pass_data_outlier_X, pass_data_outlier_y = get_train_test_data(pass_data_outlier)\n",
    "\n",
    "assert car_data_X.shape[0] + pass_data_X.shape[0] + motor_data_X.shape[0] + car_overlap_data_X.shape[0] + car_outlier_data_X.shape[0] + pass_data_outlier_X.shape[0] == full_data_X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ModelPerformance 為不使用kfold大類別 <br/>\n",
    "ModelPerformanceNew 為大類別模型 <br/>\n",
    "ModelPerformanceNewV2 為子類別的納入<br/>\n",
    "ModelPerformanceV3 將駕駛的覆蓋和離群分開"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass_outlier logistic start\n",
      "Best parameters found by GridSearchCV: {'C': 0.01, 'penalty': 'l2'}\n",
      "pass_outlier logistic done\n",
      "pass logistic start\n",
      "Best parameters found by GridSearchCV: {'C': 10, 'penalty': 'l1'}\n",
      "pass logistic done\n",
      "car_overlap logistic start\n",
      "Best parameters found by GridSearchCV: {'C': 10, 'penalty': 'l1'}\n",
      "car_overlap logistic done\n",
      "car_outlier logistic start\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples_fit, but n_neighbors = 4, n_samples_fit = 3, n_samples = 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, X, y \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m logistic start\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m     y_log, decision_scores_log \u001b[38;5;241m=\u001b[39m \u001b[43mlogistic_cm_gridsearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./ModelPerformance/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_performance_log.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     19\u001b[0m         pickle\u001b[38;5;241m.\u001b[39mdump({\n\u001b[0;32m     20\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m: y_log,\n\u001b[0;32m     21\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecision_scores\u001b[39m\u001b[38;5;124m'\u001b[39m: decision_scores_log,\n\u001b[0;32m     22\u001b[0m         }, f)\n",
      "File \u001b[1;32mc:\\Users\\USER\\Desktop\\TrafficTDApython\\Version3\\utils\\models.py:32\u001b[0m, in \u001b[0;36mlogistic_cm_gridsearch\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     30\u001b[0m enn \u001b[38;5;241m=\u001b[39m EditedNearestNeighbours(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     31\u001b[0m smote_enn \u001b[38;5;241m=\u001b[39m SMOTEENN(smote\u001b[38;5;241m=\u001b[39msmote, enn\u001b[38;5;241m=\u001b[39menn)\n\u001b[1;32m---> 32\u001b[0m X_resampled_train, y_resampled_train \u001b[38;5;241m=\u001b[39m \u001b[43msmote_enn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# print(\"Resampled train class distribution:\", dict(zip(*np.unique(y_resampled_train, return_counts=True))))\u001b[39;00m\n\u001b[0;32m     36\u001b[0m min_class_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28msum\u001b[39m(y_test \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;28msum\u001b[39m(y_test \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\imblearn\\base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\imblearn\\base.py:112\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    106\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[0;32m    110\u001b[0m )\n\u001b[1;32m--> 112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    116\u001b[0m )\n\u001b[0;32m    118\u001b[0m X_, y_ \u001b[38;5;241m=\u001b[39m arrays_transformer\u001b[38;5;241m.\u001b[39mtransform(output[\u001b[38;5;241m0\u001b[39m], y_)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\imblearn\\combine\\_smote_enn.py:160\u001b[0m, in \u001b[0;36mSMOTEENN._fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    157\u001b[0m X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, accept_sparse\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy\n\u001b[1;32m--> 160\u001b[0m X_res, y_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmote_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menn_\u001b[38;5;241m.\u001b[39mfit_resample(X_res, y_res)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\imblearn\\base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\imblearn\\base.py:112\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    106\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[0;32m    110\u001b[0m )\n\u001b[1;32m--> 112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m y_ \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m     label_binarize(output[\u001b[38;5;241m1\u001b[39m], classes\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;28;01mif\u001b[39;00m binarize_y \u001b[38;5;28;01melse\u001b[39;00m output[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    116\u001b[0m )\n\u001b[0;32m    118\u001b[0m X_, y_ \u001b[38;5;241m=\u001b[39m arrays_transformer\u001b[38;5;241m.\u001b[39mtransform(output[\u001b[38;5;241m0\u001b[39m], y_)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:389\u001b[0m, in \u001b[0;36mSMOTE._fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    386\u001b[0m X_class \u001b[38;5;241m=\u001b[39m _safe_indexing(X, target_class_indices)\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_k_\u001b[38;5;241m.\u001b[39mfit(X_class)\n\u001b[1;32m--> 389\u001b[0m nns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn_k_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    390\u001b[0m X_new, y_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_samples(\n\u001b[0;32m    391\u001b[0m     X_class, y\u001b[38;5;241m.\u001b[39mdtype, class_sample, X_class, nns, n_samples, \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m    392\u001b[0m )\n\u001b[0;32m    393\u001b[0m X_resampled\u001b[38;5;241m.\u001b[39mappend(X_new)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py:834\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    832\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    833\u001b[0m         inequality_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_neighbors <= n_samples_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 834\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    835\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minequality_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    836\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_neighbors = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_neighbors\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, n_samples_fit = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_samples_fit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    837\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# include n_samples for common tests\u001b[39;00m\n\u001b[0;32m    838\u001b[0m     )\n\u001b[0;32m    840\u001b[0m n_jobs \u001b[38;5;241m=\u001b[39m effective_n_jobs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[0;32m    841\u001b[0m chunked_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected n_neighbors <= n_samples_fit, but n_neighbors = 4, n_samples_fit = 3, n_samples = 3"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Define the data for each model\n",
    "models = [\n",
    "    (\"pass_outlier\", pass_data_outlier_X, pass_data_outlier_y),\n",
    "    (\"pass\", pass_data_X, pass_data_y),\n",
    "    (\"car_overlap\", car_overlap_data_X, car_overlap_data_y),\n",
    "    (\"car_outlier\", car_outlier_data_X, car_outlier_data_y),\n",
    "    (\"motor\", motor_data_X, motor_data_y),\n",
    "    (\"car\", car_data_X, car_data_y),\n",
    "    (\"full\", full_data_X, full_data_y)\n",
    "]\n",
    "\n",
    "# Logistic\n",
    "for name, X, y in models:\n",
    "    print(f'{name} logistic start')\n",
    "    y_log, decision_scores_log = logistic_cm_gridsearch(X.astype(float), y)\n",
    "    with open(f\"./ModelPerformance/{name}_performance_log.pkl\", \"wb\") as f:\n",
    "        pickle.dump({\n",
    "            'y': y_log,\n",
    "            'decision_scores': decision_scores_log,\n",
    "        }, f)\n",
    "    print(f'{name} logistic done')\n",
    "\n",
    "# SVC\n",
    "for name, X, y in models:\n",
    "    print(f'{name} svc start')\n",
    "    y_svc, decision_scores_svc = linear_svc_cm_gridsearch(X.astype(float), y)\n",
    "    with open(f\"./ModelPerformance/{name}_performance_svc.pkl\", \"wb\") as f:\n",
    "        pickle.dump({\n",
    "            'y': y_svc,\n",
    "            'decision_scores': decision_scores_svc,\n",
    "        }, f)\n",
    "    print(f'{name} svc done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
