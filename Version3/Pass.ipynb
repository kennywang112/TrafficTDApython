{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import prince\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.cm import get_cmap\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# 獲取當前工作目錄\n",
    "current_dir = os.getcwd()\n",
    "version3_path = os.path.join(current_dir, \"TrafficTDApython\", \"Version3\", \"tdamapper\", \"core_old.py\")\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from tdamapper.core_old import MapperAlgorithm\n",
    "from tdamapper.cover import CubicalCover\n",
    "from tdamapper.clustering import FailSafeClustering\n",
    "\n",
    "from utils.utils_v3 import *\n",
    "from utils.plots import *\n",
    "from utils.preprocess import preprocess, process_other, get_unique_ids\n",
    "\n",
    "try:\n",
    "    myfont = FontProperties(fname=r\"/System/Library/Fonts/PingFang.ttc\")\n",
    "    sns.set(style=\"whitegrid\", font=myfont.get_name())\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "dataA2 = pd.read_csv(\"./Data/A2.csv\", low_memory=False)\n",
    "dataA1 = pd.read_csv(\"./Data/A1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_lst = [\n",
    "    # 月份是為了篩選每個月2萬筆\n",
    "    '發生月份',\n",
    "\n",
    "    '天候名稱', '光線名稱', \n",
    "    '道路類別-第1當事者-名稱', '速限-第1當事者', \n",
    "    '路面狀況-路面鋪裝名稱', '路面狀況-路面狀態名稱', '路面狀況-路面缺陷名稱',\n",
    "    '道路障礙-障礙物名稱', '道路障礙-視距品質名稱', '道路障礙-視距名稱',\n",
    "    '號誌-號誌種類名稱', '號誌-號誌動作名稱',\n",
    "    '車道劃分設施-分道設施-快車道或一般車道間名稱', '車道劃分設施-分道設施-快慢車道間名稱', '車道劃分設施-分道設施-路面邊線名稱',\n",
    "    '當事者屬-性-別名稱', '當事者事故發生時年齡',\n",
    "    '保護裝備名稱', '行動電話或電腦或其他相類功能裝置名稱',\n",
    "    '肇事逃逸類別名稱-是否肇逃',\n",
    "    '死亡受傷人數',\n",
    "\n",
    "    # 大類別\n",
    "    '道路型態大類別名稱', '事故位置大類別名稱',\n",
    "    '車道劃分設施-分向設施大類別名稱',\n",
    "    '事故類型及型態大類別名稱', '當事者區分-類別-大類別名稱-車種', '當事者行動狀態大類別名稱',\n",
    "    '車輛撞擊部位大類別名稱-最初', '車輛撞擊部位大類別名稱-其他',\n",
    "\n",
    "    # 兩個欄位只有兩個觀察值不同\n",
    "    '肇因研判大類別名稱-主要',\n",
    "    # '肇因研判大類別名稱-個別',\n",
    "    \n",
    "    # 子類別\n",
    "    # '道路型態子類別名稱', '事故位置子類別名稱', '事故類型及型態子類別名稱', '肇因研判子類別名稱-主要',\n",
    "    # '當事者區分-類別-子類別名稱-車種', '當事者行動狀態子類別名稱', '車輛撞擊部位子類別名稱-最初',\n",
    "    # '車輛撞擊部位子類別名稱-其他', '肇因研判子類別名稱-個別',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbind_data['事故類型及型態大類別名稱'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataA1 = preprocess(dataA1, target='行人', lst=select_lst)\n",
    "full_dataA2 = preprocess(dataA2, target='行人', lst=select_lst)\n",
    "mapper_numpy, rbind_data, dummy_data, death, injuried = process_other(full_dataA1, full_dataA2, downsample=False, en=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmodes.kmodes import KModes\n",
    "\n",
    "cost = []\n",
    "all_results = {}\n",
    "K = range(1, 6)\n",
    "\n",
    "for k in K:\n",
    "\n",
    "    km = KModes(\n",
    "    n_clusters=k, \n",
    "    init='Huang',\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=10\n",
    "    )\n",
    "\n",
    "    labels = km.fit_predict(rbind_data)\n",
    "    cost.append(km.cost_)\n",
    "    all_results[k] = {\n",
    "        'cost': km.cost_,\n",
    "        'labels': labels,\n",
    "        'centroids': km.cluster_centroids_\n",
    "    }\n",
    "\n",
    "optimal_k = K[cost.index(min(cost))]\n",
    "optimal_result = all_results[optimal_k]\n",
    "\n",
    "# with open('Version3/Data/CarData/kmode_result.pickle', 'wb') as f:\n",
    "#     pickle.dump(all_results, f)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(K, cost, marker='o')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.show()\n",
    "# save all_results\n",
    "with open('./Data/Kmode/Pass.pkl', 'wb') as f:\n",
    "    pickle.dump(all_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Series(all_results[2]['labels']).value_counts())\n",
    "rbind_data['Cluster'] = all_results[2]['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mca = prince.MCA(\n",
    "    one_hot=False,\n",
    "    n_components=12,\n",
    "    n_iter=30,\n",
    "    copy=True,\n",
    "    check_input=True,\n",
    "    random_state=42\n",
    ")\n",
    "mca.fit(dummy_data)\n",
    "lens = mca.transform(dummy_data)\n",
    "\n",
    "print(mca.eigenvalues_summary)\n",
    "\n",
    "eigenvalues = mca.eigenvalues_\n",
    "\n",
    "components = range(0, len(eigenvalues))\n",
    "\n",
    "variance = mca.eigenvalues_summary['% of variance']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(components, eigenvalues, marker='o', linestyle='--')\n",
    "plt.title(\"Scree Plot\")\n",
    "plt.xlabel(\"Component\")\n",
    "plt.ylabel(\"Eigenvalue\")\n",
    "plt.xticks(components)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mca(mca, dummy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_info = {\n",
    "    'lens': lens,\n",
    "    'mapper_numpy': mapper_numpy,\n",
    "    'rbind_data': rbind_data,\n",
    "}\n",
    "with open('../ForMatrix/CalculatedData/Pass.pkl', 'wb') as f:\n",
    "    pickle.dump(grid_search_info, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = 3\n",
    "interval = 7\n",
    "detailed_results = []\n",
    "silhouette_for_intervals = []\n",
    "\n",
    "mapper_algo = MapperAlgorithm(\n",
    "    cover=CubicalCover(\n",
    "        n_intervals=interval,\n",
    "        overlap_frac=overlap / 10\n",
    "    ),\n",
    "    clustering=FailSafeClustering(\n",
    "        AgglomerativeClustering(\n",
    "            n_clusters=2,\n",
    "            linkage='ward'\n",
    "        )\n",
    "    ),\n",
    "    n_jobs=14\n",
    ")\n",
    "\n",
    "mapper_info = mapper_algo.fit_transform(mapper_numpy, lens)\n",
    "silhouette_for_intervals.append(mapper_info[1])\n",
    "result = {\n",
    "    \"overlap\": overlap,\n",
    "    \"interval\": interval,\n",
    "    \"silhouette\": mapper_info[1],\n",
    "    \"mapper_info\": mapper_info\n",
    "}\n",
    "detailed_results.append(result)\n",
    "detailed_results_df = pd.DataFrame(detailed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = './Data/Mapper/pass_o3i7.pkl'\n",
    "\n",
    "with open(output_file, 'rb') as f:\n",
    "    detailed_results_df = pickle.load(f)\n",
    "    \n",
    "# with open(output_file, 'wb') as f:\n",
    "#     pickle.dump(detailed_results_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pickle\n",
    "with open('./ModelPerformance/pass_performance_svc.pkl', 'rb') as f:\n",
    "    pass_decision_scores = pickle.load(f)\n",
    "\n",
    "sorted_indices = np.argsort(pass_decision_scores['indices'])\n",
    "y_decision_sorted = pass_decision_scores['decision_scores'][sorted_indices]\n",
    "rbind_data['score'] = y_decision_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose = '顯著特徵'\n",
    "# rbind_data['顯著特徵'] = rbind_data['道路型態子類別名稱'] + ',' + rbind_data['號誌-號誌動作名稱'] + ',' + rbind_data['天候名稱']\n",
    "choose = 'Significant Features'\n",
    "rbind_data['Significant Features'] = rbind_data['Road Category - Subcategory'] + ',' + rbind_data['Traffic Signal - Signal Operation'] + ',' + rbind_data[\"Weather Condition\"]\n",
    "\n",
    "mapper_plotter = MapperPlotter(detailed_results_df['mapper_info'][0], rbind_data, seed=87, iterations=100, dim=2,\n",
    "                                range_lst=[-0.2, 0.2, 0.2, -0.2])\n",
    "mapper_plot = mapper_plotter.create_mapper_plot(choose, most_common_encoded_label, avg=False)\n",
    "full_info = mapper_plotter.extract_data()\n",
    "mapper_plotter.map_colors(choose, size=0, threshold=10)\n",
    "mapper_plotter.plot(choose, avg=False, set_label=True, size=1000, anchor=1.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_plotter.update_colors(choose='天候名稱')\n",
    "mapper_plotter.plot('天候名稱', set_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choose = '死亡'\n",
    "rbind_data['死亡'] = death\n",
    "\n",
    "mapper_plotter = MapperPlotter(detailed_results_df['mapper_info'][0], rbind_data, seed=87, iterations=100, dim=2,\n",
    "                                range_lst=[-0.15, 0.15, 0.2, -0.2])\n",
    "mapper_plot = mapper_plotter.create_mapper_plot(choose, sum_of_data, avg=True)\n",
    "full_info, label_out = mapper_plotter.extract_data()\n",
    "mapper_plotter.map_colors(choose, size=0, threshold=0)\n",
    "mapper_plotter.plot_dens(choose, avg=True, set_label=False, size=100000, minimum_lst=[-0.05, 0.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "threshold = -0.0328\n",
    "x_max = 0.25\n",
    "x_min = -0.25\n",
    "y_max = 0.25\n",
    "y_min = -0.25\n",
    "\n",
    "rectangle1 = Polygon([(threshold, y_min), (x_min, y_min), (x_min, y_max), (threshold, y_max)])\n",
    "rectangle2 = Polygon([(threshold, y_min), (threshold, y_max), (x_max, y_max), (x_max, y_min)])\n",
    "\n",
    "th = 2\n",
    "filtered_full_info = full_info[(full_info['y'] > -th) &\n",
    "                               (full_info['y'] < th) &\n",
    "                               (full_info['x'] > -th) &\n",
    "                               (full_info['x'] < th)]\n",
    "\n",
    "# 檢查每個點是否在任意一個區塊內\n",
    "inside_indices_1 = filtered_full_info.apply(lambda row: Point(row['x'], row['y']).within(rectangle1), axis=1)\n",
    "inside_indices_2 = filtered_full_info.apply(lambda row: Point(row['x'], row['y']).within(rectangle2), axis=1)\n",
    "\n",
    "label_0 = filtered_full_info[inside_indices_1]\n",
    "label_1 = filtered_full_info[inside_indices_2]\n",
    "\n",
    "# 繪製數據點和矩形區塊\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(label_0['x'], label_0['y'], color='green', s=10)\n",
    "plt.scatter(label_1['x'], label_1['y'], color='blue', s=10)\n",
    "# 繪製矩形區塊\n",
    "for rect, color, alpha in zip([rectangle1, rectangle2], \n",
    "                              ['green', 'blue'], \n",
    "                              [0.2, 0.2]):\n",
    "    x, y = rect.exterior.xy\n",
    "    plt.fill(x, y, color=color, alpha=alpha)\n",
    "# 圖形調整\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.axis(\"equal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_labels(label_0, label_1, label_out, title=\"Label and Outlier Visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbind_data['死亡'] = death\n",
    "# 獲取每個label的index\n",
    "count_0 = get_unique_ids(label_0)\n",
    "count_1 = get_unique_ids(label_1)\n",
    "count_out = get_unique_ids(label_out)\n",
    "\n",
    "index_to_groups = {}\n",
    "\n",
    "# 將索引與群體的關係記錄下來\n",
    "for group_name, group_indexes in zip(\n",
    "    [\"full_0\", \"full_1\", \"full_out\"],\n",
    "    [count_0, count_1, count_out],\n",
    "):\n",
    "    for idx in group_indexes:\n",
    "        if idx not in index_to_groups:\n",
    "            index_to_groups[idx] = set()\n",
    "        index_to_groups[idx].add(group_name)\n",
    "\n",
    "# 找交集索引\n",
    "intersection_indexes = {idx for idx, groups in index_to_groups.items() if len(groups) > 1}\n",
    "\n",
    "# 移除交集的index\n",
    "count_0 = [i for i in count_0 if i not in intersection_indexes]\n",
    "count_1 = [i for i in count_1 if i not in intersection_indexes]\n",
    "count_out = [i for i in count_out if i not in intersection_indexes]\n",
    "\n",
    "\n",
    "full_0 = rbind_data.loc[count_0]\n",
    "full_1 = rbind_data.loc[count_1]\n",
    "full_out = rbind_data.loc[count_out]\n",
    "overlap_data = rbind_data.loc[list(intersection_indexes)]\n",
    "\n",
    "# 確認所有資料都被獲取\n",
    "assert len(count_0) == full_0.shape[0]\n",
    "assert len(count_1) == full_1.shape[0]\n",
    "assert len(count_out) == full_out.shape[0]\n",
    "\n",
    "print(full_0.shape[0] + full_1.shape[0] + full_out.shape[0] + overlap_data.shape[0])\n",
    "print(rbind_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_0['死亡'].value_counts())\n",
    "print(full_1['死亡'].value_counts())\n",
    "print(full_out['死亡'].value_counts())\n",
    "print(overlap_data['死亡'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_info.to_csv('./Data/PassData/full_info.csv', index=False)\n",
    "full_0.to_csv('./Data/PassData/full_0.csv', index=False)\n",
    "full_1.to_csv('./Data/PassData/full_1.csv', index=False)\n",
    "full_out.to_csv('./Data/PassData/full_out.csv', index=False)\n",
    "overlap_data.to_csv('./Data/PassData/overlap_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 統計分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_lst = [\n",
    "    'Weather Condition', 'Lighting Condition', 'Road Category - First Party - Name', 'Speed Limit - First Party', 'Road Surface Condition - Pavement Type',\n",
    "    'Road Surface Condition - Surface State', 'Road Surface Condition - Surface Defects', 'Road Obstruction - Obstacle Type', 'Road Obstruction - Visibility Quality', 'Road Obstruction - Sight Distance',\n",
    "    'Traffic Signal - Signal Type', 'Traffic Signal - Signal Operation', 'Lane Division Facility - Between Fast and General Lanes',\n",
    "    'Lane Division Facility - Between Fast and Slow Lanes', 'Lane Division Facility - Road Edge Line', 'Party Attribute - Gender', 'Party Age at Accident',\n",
    "    'Protective Equipment', 'Hit and Run - Yes or No', 'Road Category - Major Category',\n",
    "    'Accident Location - Major Category', 'Lane Division Facility - Major Category', 'Accident Type and Form - Major Category',\n",
    "    'Vehicle Impact Area - Other',\n",
    "]\n",
    "\n",
    "results = []\n",
    "rbind_data['death'] = death.apply(lambda x: 1 if x >= 1 else 0)\n",
    "rbind_data['受傷'] = injuried\n",
    "\n",
    "for chi_value in chi_lst:\n",
    "    contingency_table = pd.crosstab(rbind_data[chi_value], rbind_data['death'])\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "    if p < 0.01:  # 只篩選顯著結果\n",
    "        results.append({'變數': chi_value, '卡方值': chi2, '自由度': dof, 'p值': p})\n",
    "\n",
    "# 將結果轉為資料框\n",
    "df_results = pd.DataFrame(results).sort_values(by='卡方值', ascending=True)\n",
    "\n",
    "# 視覺化：條形圖\n",
    "plt.figure(figsize=(10, 3.3))\n",
    "plt.barh(df_results['變數'], df_results['卡方值'], alpha=0.7)\n",
    "plt.xlabel('Chi-square Value')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Pass Significant Features (p < 0.01)')\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_lst = [\n",
    "    '天候名稱', '光線名稱', '道路類別-第1當事者-名稱', '速限-第1當事者', '路面狀況-路面鋪裝名稱',\n",
    "    '路面狀況-路面狀態名稱', '路面狀況-路面缺陷名稱', '道路障礙-障礙物名稱', '道路障礙-視距品質名稱', '道路障礙-視距名稱',\n",
    "    '號誌-號誌種類名稱', '號誌-號誌動作名稱', '車道劃分設施-分道設施-快車道或一般車道間名稱',\n",
    "    '車道劃分設施-分道設施-快慢車道間名稱', '車道劃分設施-分道設施-路面邊線名稱', '當事者屬-性-別名稱', '當事者事故發生時年齡',\n",
    "    '保護裝備名稱', '肇事逃逸類別名稱-是否肇逃', '道路型態大類別名稱',\n",
    "    '事故位置大類別名稱', '車道劃分設施-分向設施大類別名稱', '事故類型及型態大類別名稱',\n",
    "    '車輛撞擊部位大類別名稱-其他']\n",
    "\n",
    "results = []\n",
    "rbind_data['death'] = death.apply(lambda x: 1 if x >= 1 else 0)\n",
    "rbind_data['受傷'] = injuried\n",
    "\n",
    "for chi_value in chi_lst:\n",
    "    contingency_table = pd.crosstab(rbind_data[chi_value], rbind_data['death'])\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "    if p < 0.01:  # 只篩選顯著結果\n",
    "        results.append({'變數': chi_value, '卡方值': chi2, '自由度': dof, 'p值': p})\n",
    "\n",
    "# 將結果轉為資料框\n",
    "df_results = pd.DataFrame(results).sort_values(by='卡方值', ascending=True)\n",
    "\n",
    "# 視覺化：條形圖\n",
    "plt.figure(figsize=(10, 3.3))\n",
    "plt.barh(df_results['變數'], df_results['卡方值'], alpha=0.7)\n",
    "plt.xlabel('卡方值')\n",
    "plt.ylabel('特徵')\n",
    "plt.title('行人 顯著特徵 (p < 0.01)')\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 道路類別-第1當事者-名稱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_column = '道路類別-第1當事者-名稱'\n",
    "\n",
    "data_dict = {\n",
    "    \"正常號誌、四岔路\": full_0[plot_column].value_counts(),\n",
    "    \"正常號誌、直路\": full_1[plot_column].value_counts(),\n",
    "    \"無號誌、三岔路\": full_2[plot_column].value_counts(),\n",
    "    \"無號誌、直路\": full_3[plot_column].value_counts(),\n",
    "    \"覆蓋值\": overlap_data[plot_column].value_counts(),\n",
    "    \"離群值\": full_out[plot_column].value_counts(),\n",
    "    \n",
    "}\n",
    "\n",
    "# 將資料轉為 DataFrame，便於比較\n",
    "comparison_df = pd.DataFrame(data_dict).fillna(0)\n",
    "comparison_df = comparison_df.sort_values(by='正常號誌、四岔路', axis=0, ascending=False)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    \"正常號誌、四岔路\": full_0[plot_column].value_counts(normalize=True),\n",
    "    \"正常號誌、直路\": full_1[plot_column].value_counts(normalize=True),\n",
    "    \"無號誌、三岔路\": full_2[plot_column].value_counts(normalize=True),\n",
    "    \"無號誌、直路\": full_3[plot_column].value_counts(normalize=True),\n",
    "    \"覆蓋值\": overlap_data[plot_column].value_counts(normalize=True),\n",
    "    \"離群值\": full_out[plot_column].value_counts(normalize=True),\n",
    "    \n",
    "}\n",
    "\n",
    "# 將資料轉為 DataFrame，便於比較\n",
    "comparison_df = pd.DataFrame(data_dict).fillna(0)\n",
    "comparison_df = comparison_df.sort_values(by='正常號誌、四岔路', axis=0, ascending=False)\n",
    "\n",
    "categories_to_merge = [\"縣道\", \"省道\", \"鄉道\", \"國道\", \"專用道路\", \"快速(公)道\"]\n",
    "comparison_df.loc[\"其他\"] += comparison_df.loc[categories_to_merge].sum()\n",
    "comparison_df = comparison_df.drop(index=categories_to_merge)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 嚴重程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_severity(input_data):\n",
    "    \"\"\"\n",
    "    更新嚴重程度欄位邏輯：\n",
    "    - 死亡 > 0 時，設定為 2\n",
    "    - 死亡 = 0 且受傷 = 1 時，設定為 0\n",
    "    - 死亡 = 0 且受傷 > 1 時，設定為 1\n",
    "    \"\"\"\n",
    "    def severity_logic(row):\n",
    "        if row['死亡'] > 0:\n",
    "            return '死亡'\n",
    "        elif row['死亡'] == 0 and row['受傷'] == 1:\n",
    "            return '受傷1'\n",
    "        elif row['死亡'] == 0 and row['受傷'] > 1:\n",
    "            return '受傷1+'\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    input_data['嚴重程度'] = input_data.apply(severity_logic, axis=1)\n",
    "    return input_data\n",
    "\n",
    "full_0_s = get_severity(full_0)\n",
    "full_1_s = get_severity(full_1)\n",
    "full_2_s = get_severity(full_2)\n",
    "full_3_s = get_severity(full_3)\n",
    "full_out_s = get_severity(full_out)\n",
    "overlap_data_s = get_severity(overlap_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_column = '嚴重程度'\n",
    "\n",
    "data_dict = {\n",
    "    \"正常號誌、四岔路\": full_0[plot_column].value_counts(),\n",
    "    \"正常號誌、直路\": full_1[plot_column].value_counts(),\n",
    "    \"無號誌、三岔路\": full_2[plot_column].value_counts(),\n",
    "    \"無號誌、直路\": full_3[plot_column].value_counts(),\n",
    "    \"覆蓋值\": overlap_data[plot_column].value_counts(),\n",
    "    \"離群值\": full_out[plot_column].value_counts(),\n",
    "    \n",
    "}\n",
    "\n",
    "# 將資料轉為 DataFrame，便於比較\n",
    "comparison_df = pd.DataFrame(data_dict).fillna(0)\n",
    "total_row = comparison_df.sum(axis=0)\n",
    "comparison_df.loc[\"Total\"] = total_row\n",
    "# comparison_df.loc[\"Total\"] = comparison_df.loc[\"Total\"].astype(int)\n",
    "comparison_df = comparison_df.sort_values(by='正常號誌、四岔路', axis=0, ascending=False)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    \"正常號誌、四岔路\": full_0[plot_column].value_counts(normalize=True),\n",
    "    \"正常號誌、直路\": full_1[plot_column].value_counts(normalize=True),\n",
    "    \"無號誌、三岔路\": full_2[plot_column].value_counts(normalize=True),\n",
    "    \"無號誌、直路\": full_3[plot_column].value_counts(normalize=True),\n",
    "    \"覆蓋值\": overlap_data[plot_column].value_counts(normalize=True),\n",
    "    \"離群值\": full_out[plot_column].value_counts(normalize=True),\n",
    "    \n",
    "}\n",
    "\n",
    "# 將資料轉為 DataFrame，便於比較\n",
    "comparison_df = pd.DataFrame(data_dict).fillna(0)\n",
    "comparison_df.loc[\"Total\"] = total_row\n",
    "comparison_df = comparison_df.sort_values(by='正常號誌、四岔路', axis=0, ascending=False)\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新計算 Total 行，並添加到 DataFrame\n",
    "comparison_df.loc[\"Total\"] = comparison_df.sum(axis=0)\n",
    "\n",
    "# 獲取 Total 行數據\n",
    "total_row = comparison_df.loc[\"Total\"]\n",
    "\n",
    "# 提取僅包含數值的列，並移除 Total 行\n",
    "numeric_df = comparison_df.select_dtypes(include=[float, int]).drop(\"Total\")\n",
    "\n",
    "# 繪製 heatmap\n",
    "plt.figure(figsize=(8, 2))\n",
    "sns.heatmap(numeric_df.tail(3), annot=True, cmap='coolwarm', fmt=\".3f\")\n",
    "\n",
    "# 添加總數標註在每個欄位的頂部\n",
    "for i, total in enumerate(total_row):\n",
    "    plt.text(i + 0.5, -0.2, f\"{int(total)}\", ha='center', va='center', fontsize=10, color='black')\n",
    "\n",
    "# 調整外觀\n",
    "plt.xticks(rotation=20)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_tda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
