{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'C:\\\\System\\\\Library\\\\Fonts\\\\PingFang.ttc'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "# 獲取當前工作目錄\n",
    "current_dir = os.getcwd()\n",
    "version3_path = os.path.join(current_dir, \"TrafficTDApython\", \"Version3\", \"tdamapper\", \"core_old.py\")\n",
    "\n",
    "from utils.utils_v3 import *\n",
    "from utils.plots import *\n",
    "from utils.mappping_model import *\n",
    "\n",
    "try:\n",
    "    myfont = FontProperties(fname=r\"/System/Library/Fonts/PingFang.ttc\")\n",
    "    sns.set(style=\"whitegrid\", font=myfont.get_name())\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "dataA2 = pd.read_csv(\"../Version3/Data/A2.csv\", low_memory=False)\n",
    "dataA1 = pd.read_csv(\"../Version3/Data/A1.csv\")\n",
    "info = pd.read_csv(\"./Data/CarData/full_info.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 10057\n",
      "45 10286\n",
      "40 9143\n",
      "35 8000\n",
      "36 8229\n",
      "39 8914\n",
      "47 10743\n",
      "43 9829\n",
      "40 9143\n",
      "47 10743\n",
      "dummy_data: (95503, 146)\n"
     ]
    }
   ],
   "source": [
    "select_lst = [\n",
    "    # 月份是為了篩選每個月2萬筆\n",
    "    '發生月份',\n",
    "\n",
    "    '天候名稱', '光線名稱', \n",
    "    '道路類別-第1當事者-名稱', '速限-第1當事者', \n",
    "    '路面狀況-路面鋪裝名稱', '路面狀況-路面狀態名稱', '路面狀況-路面缺陷名稱',\n",
    "    '道路障礙-障礙物名稱', '道路障礙-視距品質名稱', '道路障礙-視距名稱',\n",
    "    '號誌-號誌種類名稱', '號誌-號誌動作名稱',\n",
    "    '車道劃分設施-分道設施-快車道或一般車道間名稱', '車道劃分設施-分道設施-快慢車道間名稱', '車道劃分設施-分道設施-路面邊線名稱',\n",
    "    '當事者屬-性-別名稱', '當事者事故發生時年齡',\n",
    "    '保護裝備名稱', '行動電話或電腦或其他相類功能裝置名稱',\n",
    "    '肇事逃逸類別名稱-是否肇逃',\n",
    "    '死亡受傷人數',\n",
    "\n",
    "    # 大類別\n",
    "    '道路型態大類別名稱', '事故位置大類別名稱',\n",
    "    '車道劃分設施-分向設施大類別名稱',\n",
    "    '事故類型及型態大類別名稱', '當事者區分-類別-大類別名稱-車種', '當事者行動狀態大類別名稱',\n",
    "    '車輛撞擊部位大類別名稱-最初', '車輛撞擊部位大類別名稱-其他',\n",
    "\n",
    "    # 小類別\n",
    "    # '道路型態子類別名稱', '事故位置子類別名稱', '事故類型及型態子類別名稱', '肇因研判子類別名稱-主要',\n",
    "    # '當事者區分-類別-子類別名稱-車種', '當事者行動狀態子類別名稱', '車輛撞擊部位子類別名稱-最初',\n",
    "    # '車輛撞擊部位子類別名稱-其他', '肇因研判子類別名稱-個別',\n",
    "\n",
    "    # 兩個欄位只有兩個觀察值不同\n",
    "    '肇因研判大類別名稱-主要',\n",
    "    # '肇因研判大類別名稱-個別',\n",
    "    \n",
    "    '經度', '緯度',\n",
    "]\n",
    "\n",
    "def preprocess(input_data, select_lst):\n",
    "    # 篩選到第一個順位，因為注重的是單次事故的情況\n",
    "    main_data = input_data[input_data['當事者順位'] == 1].reset_index(drop=True, inplace=False)\n",
    "    sample_data = main_data[main_data['發生月份'] < 11]\n",
    "    selected_data = sample_data[select_lst]\n",
    "    \n",
    "    # 將資料分出死亡和受傷，合併到原本的資料後去除多餘的死亡受傷人數\n",
    "    split_death_injury_data = split_death_injury(selected_data['死亡受傷人數'])\n",
    "    full_data = pd.concat([selected_data, split_death_injury_data], axis=1)\n",
    "\n",
    "    # 補齊缺失值\n",
    "    full_data[select_lst] = full_data[select_lst].fillna('未紀錄')\n",
    "\n",
    "    # 速限範圍\n",
    "    full_data = full_data[(full_data['速限-第1當事者'] < 200) &\n",
    "                      (full_data['當事者事故發生時年齡'] < 100) &\n",
    "                      (full_data['當事者事故發生時年齡'] > 0)]\n",
    "\n",
    "    full_data.drop(columns=['死亡受傷人數'], inplace=True)\n",
    "    \n",
    "    # 篩選駕駛人的資料\n",
    "    full_data = full_data[full_data['當事者行動狀態大類別名稱'] == '車的狀態']\n",
    "    full_data.drop(columns=['當事者行動狀態大類別名稱'], inplace=True)\n",
    "    # 篩選離群資料(影響MCA的因子得分)\n",
    "    full_data = full_data[(full_data['肇因研判大類別名稱-主要'] != '非駕駛者') &\n",
    "                  (full_data['肇因研判大類別名稱-主要'] != '無(非車輛駕駛人因素)') &\n",
    "                  (full_data['肇因研判大類別名稱-主要'] != '無(車輛駕駛者因素)') &\n",
    "                  (full_data['行動電話或電腦或其他相類功能裝置名稱'] != '未紀錄') &\n",
    "                    (full_data['車輛撞擊部位大類別名稱-最初'] != '未紀錄')]\n",
    "\n",
    "    return full_data\n",
    "\n",
    "full_dataA1 = preprocess(dataA1, select_lst)\n",
    "full_dataA2 = preprocess(dataA2, select_lst)\n",
    "\n",
    "# 下採樣資料\n",
    "sampling_ratio = 0.33  # 下採樣比例，根據A1 和 A2 原始數據量比例調整\n",
    "total_ratio = len(full_dataA1) / len(full_dataA2) # 保留 A1/A2 的比例\n",
    "downsampled_A1, downsampled_A2 = downsample_by_month_simple(full_dataA1, full_dataA2, sampling_ratio, total_ratio)\n",
    "# Concat\n",
    "rbind_data = pd.concat([downsampled_A1, downsampled_A2], axis=0, ignore_index=True)\n",
    "rbind_data.drop(columns=['發生月份'], inplace=True)\n",
    "# 處理年齡和速限\n",
    "rbind_data = process_age_speed(rbind_data)\n",
    "# rbind_data.drop(['死亡', '受傷'], axis=1, inplace=True)\n",
    "# 唯一值處理\n",
    "columns_to_drop = []\n",
    "for column in rbind_data.columns:\n",
    "    if rbind_data[column].nunique() == 1:  # 檢查唯一值數量是否等於 1\n",
    "        columns_to_drop.append(column)\n",
    "# Dummy\n",
    "rbind_data[\"速限-第1當事者\"] = rbind_data[\"速限-第1當事者\"].astype(str)\n",
    "dummy_data = pd.get_dummies(rbind_data)\n",
    "print('dummy_data:', dummy_data.shape)\n",
    "mapper_numpy = dummy_data.to_numpy()\n",
    "\n",
    "# rbind_data['顯著特徵'] = rbind_data['道路型態子類別名稱'] + ',' + rbind_data['號誌-號誌動作名稱'] + ',' + rbind_data['天候名稱']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "地圖已生成，保存為 traffic_heatmap.html\n"
     ]
    }
   ],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "# 基於經緯度生成熱點數據\n",
    "heat_data = rbind_data[[\"緯度\", \"經度\"]].dropna().values.tolist()\n",
    "\n",
    "# 創建地圖\n",
    "map_taiwan = folium.Map(location=[23.5, 121], zoom_start=7)\n",
    "\n",
    "# 添加熱點圖\n",
    "HeatMap(heat_data).add_to(map_taiwan)\n",
    "\n",
    "# 保存地圖\n",
    "map_taiwan.save(\"./Map/traffic_heatmap.html\")\n",
    "print(\"地圖已生成，保存為 traffic_heatmap.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_proportion_tables = []\n",
    "\n",
    "for id in info['ids']:\n",
    "    \n",
    "    id_lst = ast.literal_eval(id)\n",
    "    datas = len(id_lst)\n",
    "    normalized_datas = datas / len(dummy_data)\n",
    "    original_data = dummy_data.iloc[id_lst]\n",
    "    proportion_data  = original_data.sum() / len(original_data)\n",
    "    proportion_data['資料數量'] = normalized_datas\n",
    "    proportion_table = proportion_data.to_frame(name='比例').T\n",
    "    all_proportion_tables.append(proportion_table)\n",
    "    \n",
    "final_table = pd.concat(all_proportion_tables, ignore_index=True)\n",
    "\n",
    "columns_to_drop = []\n",
    "for column in final_table.columns:\n",
    "    if final_table[column].nunique() == 1:  # 檢查唯一值數量是否等於 1\n",
    "        columns_to_drop.append(column)\n",
    "        \n",
    "columns_to_drop\n",
    "final_table = final_table.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.0066\n",
      "R^2 Score: -0.0143\n",
      "Mean Squared Error (MSE): 0.0065\n",
      "R^2 Score: -0.0005\n"
     ]
    }
   ],
   "source": [
    "pass_X, pass_y = get_train_test_data(final_table, classify=False)\n",
    "pass_y_ridge, pass_decision_scores_ridge, pass_indices_ridge = ridge_cm_kfold(pass_X, pass_y)\n",
    "pass_y_lasso, pass_decision_scores_lasso, pass_indices_lasso = lasso_cm_kfold(pass_X, pass_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "info['死亡比例'] = final_table['死亡']\n",
    "info['score'] = pass_decision_scores_lasso\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Step 1: 計算每個索引的總出現次數\n",
    "index_counts = defaultdict(int)\n",
    "\n",
    "for _, row in info.iterrows():\n",
    "    row['ids'] = ast.literal_eval(row['ids'])  # 將字串轉換為列表\n",
    "    for idx in row['ids']:\n",
    "        index_counts[idx] += 1\n",
    "        \n",
    "# Step 2: 根據總次數計算權重\n",
    "weights = defaultdict(float)\n",
    "\n",
    "for _, row in info.iterrows():\n",
    "    row['ids'] = ast.literal_eval(row['ids'])  # 再次解析 ids\n",
    "    for idx in row['ids']:\n",
    "        weights[idx] += row['score'] / index_counts[idx]  # 使用索引的總出現次數作為分母\n",
    "\n",
    "# Step 3: 將結果轉為 DataFrame\n",
    "weights_df = pd.DataFrame(list(weights.items()), columns=['index', 'weight']).sort_values(by='index').reset_index(drop=True)\n",
    "\n",
    "final_data = rbind_data.merge(weights_df, left_index=True, right_on='index', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Map/car_weighted_map.html'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import folium\n",
    "from folium import plugins\n",
    "import matplotlib\n",
    "\n",
    "# Normalize weights for color scaling\n",
    "norm = matplotlib.colors.Normalize(vmin=final_data['weight'].min(), vmax=final_data['weight'].max())\n",
    "cmap = matplotlib.cm.ScalarMappable(norm=norm, cmap='viridis')  # Using 'viridis' colormap\n",
    "\n",
    "# Create a Folium map centered on the first data point\n",
    "m = folium.Map(location=[final_data['緯度'].mean(), final_data['經度'].mean()], zoom_start=12)\n",
    "\n",
    "# Add each point to the map with color based on weight\n",
    "for _, row in final_data.iterrows():\n",
    "    if pd.notna(row['weight']):  # Check if weight is not NaN\n",
    "        color = matplotlib.colors.to_hex(cmap.to_rgba(row['weight']))  # Convert weight to color\n",
    "        folium.CircleMarker(\n",
    "            location=(row['緯度'], row['經度']),\n",
    "            radius=6,\n",
    "            color=color,\n",
    "            fill=True,\n",
    "            fill_color=color,\n",
    "            fill_opacity=0.8,\n",
    "            popup=f\"Weight: {row['weight']:.3f}\"\n",
    "        ).add_to(m)\n",
    "\n",
    "# Save the map as an HTML file\n",
    "map_file_path = \"./Map/car_weighted_map.html\"\n",
    "m.save(map_file_path)\n",
    "\n",
    "# Provide the link to the user\n",
    "map_file_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
