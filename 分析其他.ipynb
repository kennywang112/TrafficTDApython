{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77cc55ff-3f53-45f7-b598-d35f5860e373",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/18/2024 04:14:29 PM utils INFO: Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "06/18/2024 04:14:29 PM utils INFO: NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from tdamapper.core import MapperAlgorithm\n",
    "from tdamapper.cover import CubicalCover\n",
    "from tdamapper.plot import MapperLayoutInteractive\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering\n",
    "from tdamapper.clustering import FailSafeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from functions import *\n",
    "from chi import *\n",
    "from regressionP import *\n",
    "from models import *\n",
    "from distance import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5606481a-a9a8-4ae8-8179-b2ea7f4af9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"./Data/NPA_TMA2_1.csv\", low_memory=False)[:-2]\n",
    "data2 = pd.read_csv(\"./Data/NPA_TMA2_2.csv\", low_memory=False)[:-2]\n",
    "data3 = pd.read_csv(\"./Data/NPA_TMA2_3.csv\", low_memory=False)[:-2]\n",
    "data4 = pd.read_csv(\"./Data/NPA_TMA2_4.csv\", low_memory=False)[:-2]\n",
    "dataA2 = pd.concat([data1, data2, data3, data4], ignore_index=True)\n",
    "dataA1 = pd.read_csv(\"./Data/NPA_TMA1.csv\")[:-2]\n",
    "# Qmap\n",
    "school_data = pd.read_csv('CalculatedData/coord/school_data.csv')\n",
    "train_data = pd.read_csv('CalculatedData/coord/train_data.csv')\n",
    "post_data = pd.read_csv('CalculatedData/coord/post_data.csv')\n",
    "museum_data = pd.read_csv('CalculatedData/coord/museum_data.csv')\n",
    "guesthouse_data = pd.read_csv('CalculatedData/coord/guesthouse_data.csv')\n",
    "themepark_data = pd.read_csv('CalculatedData/coord/themepark_data.csv')\n",
    "supermarket_data = pd.read_csv('CalculatedData/coord/supermarket_data.csv')\n",
    "coffee_data = pd.read_csv('CalculatedData/coord/coffee_data.csv')\n",
    "fastfood_data = pd.read_csv('CalculatedData/coord/fastfood_data.csv')\n",
    "rtc_data = pd.read_csv('CalculatedData/coord/rtc_data.csv')\n",
    "thsrc_data = pd.read_csv('CalculatedData/coord/thsrc_data.csv')\n",
    "baseball_data = pd.read_csv('CalculatedData/coord/baseball_data.csv')\n",
    "night_data = pd.read_csv('CalculatedData/coord/night_data.csv')\n",
    "port_data = pd.read_csv('CalculatedData/coord/port_data.csv')\n",
    "library_data = pd.read_csv('CalculatedData/coord/library_data.csv')\n",
    "bank_data = pd.read_csv('CalculatedData/coord/bank_data.csv')\n",
    "hospital_data = pd.read_csv('CalculatedData/coord/hospital_data.csv')\n",
    "temple_data = pd.read_csv('CalculatedData/coord/temple_data.csv')\n",
    "police_data = pd.read_csv('CalculatedData/coord/police_data.csv')\n",
    "gas_data = pd.read_csv('CalculatedData/coord/gas_data.csv')\n",
    "town_office_data = pd.read_csv('CalculatedData/coord/town_office_data.csv')\n",
    "hr_office_data = pd.read_csv('CalculatedData/coord/hr_office_data.csv')\n",
    "mv_data = pd.read_csv('CalculatedData/coord/mv_data.csv')\n",
    "ntb_data = pd.read_csv('CalculatedData/coord/ntb_data.csv')\n",
    "# 開放平台\n",
    "scenic = pd.read_csv(\"./Data/Scenic_Spot_C_f.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2bb92fa-7ec3-40e5-aa9f-452a061346c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to select\n",
    "select_lst = [\n",
    "    '天候名稱', \n",
    "    '路面狀況-路面狀態名稱',\n",
    "    '肇因研判大類別名稱-主要', '當事者屬-性-別名稱', '當事者事故發生時年齡', \n",
    "    '車輛撞擊部位大類別名稱-最初',\n",
    "    '光線名稱',\n",
    "    '道路類別-第1當事者-名稱',\n",
    "    '速限-第1當事者', \n",
    "    '道路型態大類別名稱',\n",
    "    '事故位置大類別名稱', \n",
    "    '號誌-號誌種類名稱',\n",
    "    '車道劃分設施-分向設施大類別名稱', '車道劃分設施-分道設施-快車道或一般車道間名稱',\n",
    "    '車道劃分設施-分道設施-快慢車道間名稱', '車道劃分設施-分道設施-路面邊線名稱',\n",
    "    '事故類型及型態大類別名稱',\n",
    "    '死亡受傷人數',\n",
    "    '經度', '緯度',\n",
    "    '道路型態子類別名稱', '事故位置子類別名稱', '車道劃分設施-分向設施子類別名稱', '事故類型及型態子類別名稱', \n",
    "    '當事者行動狀態子類別名稱', '車輛撞擊部位子類別名稱-最初', '車輛撞擊部位子類別名稱-其他', '肇因研判子類別名稱-個別',\n",
    "    \n",
    "    '當事者區分-類別-大類別名稱-車種', '當事者區分-類別-子類別名稱-車種',\n",
    "    '保護裝備名稱', '行動電話或電腦或其他相類功能裝置名稱', '當事者行動狀態大類別名稱',\n",
    "    '車輛撞擊部位大類別名稱-其他', '肇因研判大類別名稱-個別', '肇事逃逸類別名稱-是否肇逃',\n",
    "    '路面狀況-路面鋪裝名稱', '路面狀況-路面缺陷名稱',\n",
    "    '道路障礙-障礙物名稱', '道路障礙-視距品質名稱', '道路障礙-視距名稱','號誌-號誌動作名稱',\n",
    "]\n",
    "def preprocess(input_data, select_lst, sample = 592):\n",
    "    sample_data = input_data[input_data['當事者順位'] == 1].reset_index(drop=True, inplace=False)\n",
    "    dataA = sample_data[select_lst]\n",
    "    \n",
    "    death_injury_data = split_death_injury(dataA['死亡受傷人數'])\n",
    "    dist_df = pd.concat([dataA, death_injury_data], axis=1)\n",
    "    dist_df.drop(columns=['死亡受傷人數'], inplace=True)\n",
    "    \n",
    "    return dist_df, sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac9b4ad5-1834-4c18-b5f6-3992299aafda",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_dfA1 = preprocess(dataA1, select_lst, sample = 592)\n",
    "dist_dfA2 = preprocess(dataA2, select_lst, sample = 5920)\n",
    "\n",
    "data_frames = {\n",
    "    '學校': school_data,\n",
    "    # '火車站': train_data,\n",
    "    # '郵局': post_data,\n",
    "    # '博物館': museum_data,\n",
    "    # '民宿': guesthouse_data,\n",
    "    # '遊樂園': themepark_data,\n",
    "    # # '大賣場': supermarket_data,\n",
    "    # # '咖啡店': coffee_data,\n",
    "    # # '速食店': fastfood_data,\n",
    "    # '捷運車站': rtc_data,\n",
    "    # '高鐵車站': thsrc_data,\n",
    "    # # '棒球場': baseball_data,\n",
    "    # '夜市': night_data,\n",
    "    # '漁港': port_data,\n",
    "    # # '圖書館': library_data,\n",
    "    # # '銀行': bank_data,\n",
    "    # '醫院': hospital_data,\n",
    "    # '寺廟': temple_data,\n",
    "    # '警察局': police_data,\n",
    "    # '加油站': gas_data,\n",
    "    # '公所': town_office_data,\n",
    "    # # '戶政事務所': hr_office_data,\n",
    "    # '監理站': mv_data,\n",
    "    # '國稅局': ntb_data,\n",
    "}\n",
    "for colname, data_frame in data_frames.items():\n",
    "    scenic_dfA1 = calculate_distances(dist_dfA1[0], data_frame, colname=colname)\n",
    "    scenic_dfA2 = calculate_distances(dist_dfA2[0], data_frame, colname=colname)\n",
    "    \n",
    "rbind_data = pd.concat([scenic_dfA1, scenic_dfA2], axis=0, ignore_index=True)\n",
    "\n",
    "for col in data_frames.keys():\n",
    "    rbind_data.loc[rbind_data[col] > 1, col] = 2\n",
    "rbind_data.loc[rbind_data['受傷'] > 1, '受傷'] = 2\n",
    "rbind_data['速限-第1當事者'] = rbind_data['速限-第1當事者'].apply(lambda x: 1 if x > 60 else 0)\n",
    "rbind_data = process_age(rbind_data)\n",
    "\n",
    "dist_df = process_data(rbind_data)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "full_dist = pd.DataFrame(scaler.fit_transform(dist_df), columns = dist_df.columns)\n",
    "X1 = full_dist.drop(['受傷', '死亡', '經度', '緯度'], axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a87aa7ae-7f93-462b-92a2-df46ffc7e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in dist_df.columns:\n",
    "    # print(dist_df[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55637584-f062-4da0-83db-fdd4325737cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ratio(input_data, components) :\n",
    "    best_comp = {}\n",
    "    for comp in range(1,components+1):   \n",
    "        pca = PCA(comp).fit(input_data)\n",
    "        \n",
    "        best_comp[comp] = pca.explained_variance_ratio_.sum()\n",
    "        \n",
    "    max_comp = max(best_comp, key=best_comp.get)  # 使用 key=best_comp.get 找到最大值的鍵\n",
    "    print(\"最佳成分數：\", max_comp)\n",
    "    print(\"解釋方差比率累計值：\", best_comp[max_comp])\n",
    "\n",
    "# lens1 = find_ratio(X1, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69ca9382-c45c-4223-a925-aa57393004fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lens1 = PCA(10).fit_transform(X1)\n",
    "\n",
    "# mapper_algo1 = MapperAlgorithm(\n",
    "#     cover = CubicalCover(\n",
    "#         n_intervals = 3,\n",
    "#         overlap_frac = 0.3\n",
    "#     ),\n",
    "#     clustering = FailSafeClustering(\n",
    "#         clustering = AgglomerativeClustering(3, affinity='euclidean', linkage='ward'),\n",
    "#         verbose = False)\n",
    "# )\n",
    "\n",
    "# mapper_graph1 = mapper_algo1.fit_transform(X1, lens1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e967cd13-c7d5-49b2-9d3c-208ff95b41eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('CalculatedData/mapper_graph1.pkl', 'rb') as f:\n",
    "    mapper_graph1 = pickle.load(f)\n",
    "    \n",
    "mapper_plot1 = MapperLayoutInteractive(\n",
    "    mapper_graph1,\n",
    "    colors = dist_df[['速限-第1當事者']].to_numpy(),\n",
    "    cmap = 'jet',\n",
    "    # agg = np.nanmean,\n",
    "    agg = most_frequent_nonan,\n",
    "    dim = 3,\n",
    "    iterations = 30,\n",
    "    seed = 6,\n",
    "    width = 800,\n",
    "    height = 500)\n",
    "\n",
    "# fig_mean1 = mapper_plot1.plot()\n",
    "# fig_mean1.show(config={'scrollZoom': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31ff84fb-ef16-43e4-b4de-669a5b1e2e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vars(mapper_plot1._MapperLayoutInteractive__fig)['_data_objs'][1]['x']\n",
    "y = vars(mapper_plot1._MapperLayoutInteractive__fig)['_data_objs'][1]['y']\n",
    "z = vars(mapper_plot1._MapperLayoutInteractive__fig)['_data_objs'][1]['z']\n",
    "\n",
    "threeDimData = pd.DataFrame({'x': x, 'y': y, 'z': z})\n",
    "\n",
    "import re\n",
    "data_tuple = vars(mapper_plot1._MapperLayoutInteractive__fig)['_data_objs'][1]['text']\n",
    "\n",
    "data = []\n",
    "for item in data_tuple:\n",
    "    color = int(re.search(r'color: (\\d+)', item).group(1))\n",
    "    node = int(re.search(r'node: (\\d+)', item).group(1))\n",
    "    size = int(re.search(r'size: (\\d+)', item).group(1))\n",
    "    data.append({'color': color, 'node': node, 'size': size})\n",
    "component_info = pd.DataFrame(data)\n",
    "\n",
    "full_info = pd.concat([component_info, threeDimData], axis=1)\n",
    "\n",
    "mp_content_origin = vars(mapper_plot1._MapperLayoutInteractive__graph)['_node']\n",
    "\n",
    "mp_content = pd.DataFrame.from_dict(mp_content_origin, orient='index')\n",
    "mp_content.reset_index(inplace=True)\n",
    "mp_content.rename(columns={'index': 'node'}, inplace=True)\n",
    "\n",
    "full_info = pd.merge(full_info, mp_content, on=['node', 'size'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4554443-3e1f-4100-a934-cd8f2300d011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2 -1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0.045 預測最好\n",
    "calinski_data = get_calinski_from_db(full_info, 0.045)\n",
    "\n",
    "label_0 = full_info[full_info['label'] == 0]\n",
    "label_1 = full_info[full_info['label'] == 1]\n",
    "label_2 = full_info[full_info['label'] == 2]\n",
    "label_out = full_info[(full_info['label'] != 1) & (full_info['label'] != 2) & (full_info['label'] != 0)]\n",
    "\n",
    "count_0 = get_count_dict(label_0)\n",
    "count_1 = get_count_dict(label_1)\n",
    "count_2 = get_count_dict(label_2)\n",
    "count_out = get_count_dict(label_out)\n",
    "\n",
    "print(full_info['label'].unique())\n",
    "\n",
    "len(count_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbc93ba3-3001-4267-9855-fa6e04adacb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01連接點數量 220\n",
      "02連接點數量 0\n",
      "12連接點數量 0\n",
      "o0連接點數量 18\n",
      "o1連接點數量 11\n",
      "o2連接點數量 15\n",
      "離群值數量 131\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_0 = rbind_data.loc[count_0.keys()]\n",
    "full_1 = rbind_data.loc[count_1.keys()]\n",
    "full_2 = rbind_data.loc[count_2.keys()]\n",
    "\n",
    "# full_0['weight'] = full_0.index.map(count_0)\n",
    "# full_1['weight'] = full_1.index.map(count_1)\n",
    "# full_2['weight'] = full_2.index.map(count_2)\n",
    "\n",
    "# 離群值不需要被處理\n",
    "full_out = rbind_data.loc[count_out.keys()]\n",
    "\n",
    "lst01 = list(count_0.keys() & count_1.keys())\n",
    "lst02 = list(count_0.keys() & count_2.keys())\n",
    "lst12 = list(count_1.keys() & count_2.keys())\n",
    "lsto0 = list(count_out.keys() & count_0.keys())\n",
    "lsto1 = list(count_out.keys() & count_1.keys())\n",
    "lsto2 = list(count_out.keys() & count_2.keys())\n",
    "\n",
    "# 將重複的key另外拉出進行分析，這裡drop是為了符合卡方的獨立性前提假設\n",
    "full_01 = full_0.loc[lst01]\n",
    "full_02 = full_0.loc[lst02]\n",
    "full_12 = full_1.loc[lst12]\n",
    "\n",
    "full_combine = pd.concat([full_01, full_02, full_12], axis=0) # full_out\n",
    "full_combine = full_combine.reset_index()\n",
    "full_combine = full_combine.drop_duplicates(subset='index', keep='first')\n",
    "full_combine = full_combine.drop('index', axis=1)\n",
    "# 去掉連接點，使分析更嚴謹\n",
    "full_0 = full_0.drop(lst01, errors='ignore')\n",
    "full_0 = full_0.drop(lst02, errors='ignore')\n",
    "full_0 = full_0.drop(lsto0, errors='ignore')\n",
    "\n",
    "full_1 = full_1.drop(lst01, errors='ignore')\n",
    "full_1 = full_1.drop(lst12, errors='ignore')\n",
    "full_1 = full_1.drop(lsto1, errors='ignore')\n",
    "\n",
    "full_2 = full_2.drop(lst02, errors='ignore')\n",
    "full_2 = full_2.drop(lst12, errors='ignore')\n",
    "full_2 = full_2.drop(lsto2, errors='ignore')\n",
    "\n",
    "print('01連接點數量', len(lst01))\n",
    "print('02連接點數量', len(lst02))\n",
    "print('12連接點數量', len(lst12))\n",
    "print('o0連接點數量', len(lsto0))\n",
    "print('o1連接點數量', len(lsto1))\n",
    "print('o2連接點數量', len(lsto2))\n",
    "print('離群值數量', full_out.shape[0])\n",
    "\n",
    "full_combine.shape[0] + full_0.shape[0] + full_1.shape[0] + full_2.shape[0] == rbind_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fcabbd40-4d5a-495a-b718-863ddecee51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_logit = [\n",
    "    '路面狀況-路面狀態名稱',\n",
    "    '當事者屬-性-別名稱', '當事者事故發生時年齡', \n",
    "    '車輛撞擊部位大類別名稱-最初',\n",
    "    '光線名稱',\n",
    "    '道路類別-第1當事者-名稱',\n",
    "    '速限-第1當事者',\n",
    "    '道路型態大類別名稱',\n",
    "    '事故位置大類別名稱', \n",
    "    '號誌-號誌種類名稱',\n",
    "    '車道劃分設施-分向設施大類別名稱', '車道劃分設施-分道設施-快車道或一般車道間名稱',\n",
    "    '車道劃分設施-分道設施-快慢車道間名稱', '車道劃分設施-分道設施-路面邊線名稱',\n",
    "    '事故類型及型態大類別名稱',\n",
    "    '事故位置子類別名稱', '事故類型及型態子類別名稱', \n",
    "    '當事者行動狀態子類別名稱',\n",
    "    '車輛撞擊部位子類別名稱-最初', '肇因研判子類別名稱-個別',\n",
    "    '當事者區分-類別-子類別名稱-車種',\n",
    "    '保護裝備名稱', '行動電話或電腦或其他相類功能裝置名稱', \n",
    "    '當事者行動狀態大類別名稱',\n",
    "    '車輛撞擊部位大類別名稱-其他', \n",
    "    '肇因研判大類別名稱-個別', '肇事逃逸類別名稱-是否肇逃',\n",
    "    '路面狀況-路面鋪裝名稱', \n",
    "    '車道劃分設施-分向設施子類別名稱',\n",
    "    '道路障礙-障礙物名稱', '車輛撞擊部位子類別名稱-其他'\n",
    "    \n",
    "    # '號誌-號誌動作名稱', '當事者區分-類別-大類別名稱-車種', '肇因研判大類別名稱-主要' # 降低預測值\n",
    "    # '道路障礙-視距名稱', '車道劃分設施-分道設施-快慢車道間名稱', '車輛撞擊部位大類別名稱-其他' # 降低預測值\n",
    "    # '道路型態子類別名稱', '路面狀況-路面缺陷名稱', '天候名稱' # 降低\n",
    "]\n",
    "\n",
    "def get_clusterN_logit(cluster_data, lst):\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    c0_for_lm = process_data(cluster_data)\n",
    "    c0_for_lm_X = pd.DataFrame(scaler.fit_transform(c0_for_lm), columns=c0_for_lm.columns).reset_index(drop=True, inplace=False)\n",
    "    # label設定\n",
    "    c0_for_lm_y = cluster_data.apply(lambda row: 1 if row['死亡'] != 0 else 2, axis=1)\n",
    "        \n",
    "    c0_for_lm_X = c0_for_lm_X[lst]\n",
    "    \n",
    "    return c0_for_lm_X, c0_for_lm_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "342f5a7b-55c9-4691-a750-099009b4bfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    214\n",
      "1      6\n",
      "dtype: int64\n",
      "2    112034\n",
      "1       440\n",
      "dtype: int64\n",
      "2    5659\n",
      "1      73\n",
      "dtype: int64\n",
      "2    2390\n",
      "1      65\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "full_combine_X, full_combine_y = get_clusterN_logit(full_combine, lst_logit)\n",
    "full_0_X, full_0_y = get_clusterN_logit(full_0, lst_logit)\n",
    "full_1_X, full_1_y = get_clusterN_logit(full_1, lst_logit)\n",
    "full_2_X, full_2_y = get_clusterN_logit(full_2, lst_logit)\n",
    "\n",
    "full_out_X, full_out_y = get_clusterN_logit(full_out, lst_logit) # 新增\n",
    "\n",
    "print(full_combine_y.value_counts())\n",
    "print(full_0_y.value_counts())\n",
    "print(full_1_y.value_counts())\n",
    "print(full_2_y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dffda236-d724-4dd0-9cb9-d25f21129fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7657657657657657 0.8055555555555556 0.6904761904761905\n"
     ]
    }
   ],
   "source": [
    "# 0.045 效果最好\n",
    "# matrix_combine, score_combine, cm_combine = logistic_cm_gridsearch(full_combine_X,  full_combine_y)\n",
    "matrix_0, score_0, cm_0 = logistic_cm_gridsearch(full_0_X, full_0_y)\n",
    "matrix_1, score_1, cm_1 = logistic_cm_gridsearch(full_1_X, full_1_y)\n",
    "matrix_2, score_2, cm_2 = logistic_cm_gridsearch(full_2_X, full_2_y)\n",
    "# print(score_combine, score_0, score_1, score_2)\n",
    "print(score_0, score_1, score_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "efb0511c-8423-49e5-8d28-f629b2db4e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7661241182387203\n"
     ]
    }
   ],
   "source": [
    "de = full_0_X.shape[0] + full_1_X.shape[0] + full_2_X.shape[0]\n",
    "logit_avg_score = (full_0_X.shape[0]/de)*score_0 + (full_1_X.shape[0]/de)*score_1 + (full_2_X.shape[0]/de)*score_2\n",
    "print(logit_avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eb563523-395a-494d-a7c1-06433717bff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7656396834921793\n"
     ]
    }
   ],
   "source": [
    "de = full_0_X.shape[0] + full_1_X.shape[0] + full_2_X.shape[0]\n",
    "logit_avg_score = (full_0_X.shape[0]/de)*score_0 + (full_1_X.shape[0]/de)*score_1 + (full_2_X.shape[0]/de)*score_2\n",
    "print(logit_avg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f430d01-4aa8-4bd7-935c-89315796b792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6892655367231638\n"
     ]
    }
   ],
   "source": [
    "origin_X, origin_y = get_clusterN_logit(rbind_data, lst_logit)\n",
    "\n",
    "matrix_origin, score_origin, cm_origin = logistic_cm_gridsearch(origin_X, origin_y)\n",
    "print(score_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c64c55b-3d79-4349-b972-b4b696c39a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    108994\n",
      "4     11752\n",
      "3       114\n",
      "2       113\n",
      "1        39\n",
      "Name: 路面狀況-路面狀態名稱, dtype: int64\n",
      "3    76427\n",
      "0    43244\n",
      "4      885\n",
      "2      455\n",
      "1        1\n",
      "Name: 當事者屬-性-別名稱, dtype: int64\n",
      " 3    35027\n",
      " 1    32637\n",
      " 2    30941\n",
      " 4    18055\n",
      " 0     3545\n",
      "-1      807\n",
      "Name: 當事者事故發生時年齡, dtype: int64\n",
      " 1    67227\n",
      " 2    42073\n",
      " 0    10458\n",
      "-1     1254\n",
      "Name: 車輛撞擊部位大類別名稱-最初, dtype: int64\n",
      "1    49983\n",
      "0    42216\n",
      "2    28813\n",
      "Name: 光線名稱, dtype: int64\n",
      "3    96101\n",
      "5    12223\n",
      "0     4043\n",
      "7     2932\n",
      "6     2380\n",
      "8     1911\n",
      "1      985\n",
      "2      344\n",
      "4       93\n",
      "Name: 道路類別-第1當事者-名稱, dtype: int64\n",
      "0    118484\n",
      "1      2528\n",
      "Name: 速限-第1當事者, dtype: int64\n",
      "0    72496\n",
      "2    47380\n",
      "3      693\n",
      "1      438\n",
      "4        5\n",
      "Name: 道路型態大類別名稱, dtype: int64\n",
      "0    68392\n",
      "3    50478\n",
      "2     1923\n",
      "1      219\n",
      "Name: 事故位置大類別名稱, dtype: int64\n",
      "0    71035\n",
      "1    31739\n",
      "2    12116\n",
      "3     6122\n",
      "Name: 號誌-號誌種類名稱, dtype: int64\n",
      "2    42605\n",
      "4    35524\n",
      "0    24515\n",
      "3    17604\n",
      "1      764\n",
      "Name: 車道劃分設施-分向設施大類別名稱, dtype: int64\n",
      "0    69254\n",
      "3    37561\n",
      "4     8381\n",
      "1     4296\n",
      "2     1520\n",
      "Name: 車道劃分設施-分道設施-快車道或一般車道間名稱, dtype: int64\n",
      "2    97613\n",
      "1    20033\n",
      "0     2558\n",
      "3      591\n",
      "4      217\n",
      "Name: 車道劃分設施-分道設施-快慢車道間名稱, dtype: int64\n",
      "0    65731\n",
      "1    55281\n",
      "Name: 車道劃分設施-分道設施-路面邊線名稱, dtype: int64\n",
      "2    102154\n",
      "3     12846\n",
      "0      6011\n",
      "1         1\n",
      "Name: 事故類型及型態大類別名稱, dtype: int64\n",
      "2     52052\n",
      "0     36146\n",
      "1     15544\n",
      "11     5108\n",
      "10     4664\n",
      "22     2106\n",
      "13     1299\n",
      "8      1072\n",
      "14      861\n",
      "12      682\n",
      "20      598\n",
      "4       162\n",
      "18      159\n",
      "3       132\n",
      "15      114\n",
      "19       80\n",
      "21       58\n",
      "23       52\n",
      "17       41\n",
      "7        30\n",
      "6        28\n",
      "16       11\n",
      "9         8\n",
      "5         5\n",
      "Name: 事故位置子類別名稱, dtype: int64\n",
      "3     29547\n",
      "2     27821\n",
      "28    17616\n",
      "4     12541\n",
      "27    12156\n",
      "26     7940\n",
      "23     3088\n",
      "8      3002\n",
      "10      987\n",
      "1       885\n",
      "5       838\n",
      "13      780\n",
      "18      686\n",
      "24      571\n",
      "20      539\n",
      "12      390\n",
      "9       344\n",
      "17      286\n",
      "21      178\n",
      "19      159\n",
      "0       143\n",
      "25      141\n",
      "15      140\n",
      "16       76\n",
      "14       56\n",
      "6        56\n",
      "11       25\n",
      "7        20\n",
      "22        1\n",
      "Name: 事故類型及型態子類別名稱, dtype: int64\n",
      " 6     58374\n",
      " 10    22994\n",
      " 5     12025\n",
      " 15     5382\n",
      " 17     5260\n",
      " 4      3621\n",
      " 7      2353\n",
      " 8      2191\n",
      " 16     1462\n",
      "-1      1225\n",
      " 2      1171\n",
      " 11     1093\n",
      " 14      933\n",
      " 13      851\n",
      " 18      630\n",
      " 1       563\n",
      " 12      313\n",
      " 3       304\n",
      " 9       227\n",
      " 19       30\n",
      " 0        10\n",
      "Name: 當事者行動狀態子類別名稱, dtype: int64\n",
      " 1     44594\n",
      " 2     22532\n",
      " 5     19046\n",
      " 3      7636\n",
      " 6      6194\n",
      " 9      5020\n",
      " 8      4821\n",
      " 0      4058\n",
      " 4      2988\n",
      " 7      1435\n",
      " 12     1380\n",
      "-1      1254\n",
      " 10       33\n",
      " 11       21\n",
      "Name: 車輛撞擊部位子類別名稱-最初, dtype: int64\n",
      "44    13837\n",
      "8     12555\n",
      "29     8471\n",
      "23     6579\n",
      "11     6442\n",
      "      ...  \n",
      "81        2\n",
      "98        2\n",
      "27        1\n",
      "28        1\n",
      "32        1\n",
      "Name: 肇因研判子類別名稱-個別, Length: 110, dtype: int64\n",
      " 21    67307\n",
      " 29    39546\n",
      " 28     2500\n",
      " 32     1969\n",
      " 16     1600\n",
      "-1      1340\n",
      " 27     1184\n",
      " 31     1175\n",
      " 20     1029\n",
      " 25      984\n",
      " 11      451\n",
      " 37      391\n",
      " 10      324\n",
      " 22      260\n",
      " 26      209\n",
      " 23      127\n",
      " 36      112\n",
      " 34       96\n",
      " 9        56\n",
      " 3        44\n",
      " 5        38\n",
      " 6        32\n",
      " 2        28\n",
      " 33       27\n",
      " 8        23\n",
      " 0        22\n",
      " 30       22\n",
      " 14       18\n",
      " 35       18\n",
      " 1        17\n",
      " 4        16\n",
      " 7        14\n",
      " 18       14\n",
      " 19        8\n",
      " 13        5\n",
      " 17        3\n",
      " 12        1\n",
      " 15        1\n",
      " 24        1\n",
      "Name: 當事者區分-類別-子類別名稱-車種, dtype: int64\n",
      " 2    38115\n",
      " 5    35987\n",
      " 3    22942\n",
      " 0    18506\n",
      " 1     2671\n",
      " 4     1451\n",
      "-1     1340\n",
      "Name: 保護裝備名稱, dtype: int64\n",
      " 3    99013\n",
      " 0    18980\n",
      "-1     1340\n",
      " 4     1330\n",
      " 2      256\n",
      " 1       93\n",
      "Name: 行動電話或電腦或其他相類功能裝置名稱, dtype: int64\n",
      " 2    117914\n",
      " 1      1311\n",
      "-1      1225\n",
      " 0       562\n",
      "Name: 當事者行動狀態大類別名稱, dtype: int64\n",
      "-1    109358\n",
      " 1      6669\n",
      " 2      3981\n",
      " 0      1004\n",
      "Name: 車輛撞擊部位大類別名稱-其他, dtype: int64\n",
      " 9    93981\n",
      " 1    17270\n",
      " 4     6401\n",
      " 8     1295\n",
      "-1      572\n",
      " 2      363\n",
      " 6      322\n",
      " 7      309\n",
      " 5      250\n",
      " 3      226\n",
      " 0       23\n",
      "Name: 肇因研判大類別名稱-個別, dtype: int64\n",
      "0    118846\n",
      "1      2166\n",
      "Name: 肇事逃逸類別名稱-是否肇逃, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for i in lst_logit:\n",
    "    print(dist_df[i].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
